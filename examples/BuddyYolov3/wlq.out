DetectMultiBackend(
  (model): DetectionModel(
    (model): Sequential(
      (0): Conv(
        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (act): SiLU(inplace=True)
      )
      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (2): Conv(
        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (act): SiLU(inplace=True)
      )
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv(
        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (act): SiLU(inplace=True)
      )
      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (6): Conv(
        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (act): SiLU(inplace=True)
      )
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv(
        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (act): SiLU(inplace=True)
      )
      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (10): Conv(
        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (act): SiLU(inplace=True)
      )
      (11): ZeroPad2d((0, 1, 0, 1))
      (12): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)
      (13): Conv(
        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (act): SiLU(inplace=True)
      )
      (14): Conv(
        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
        (act): SiLU(inplace=True)
      )
      (15): Conv(
        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (act): SiLU(inplace=True)
      )
      (16): Conv(
        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
        (act): SiLU(inplace=True)
      )
      (17): Upsample(scale_factor=2.0, mode='nearest')
      (18): Concat()
      (19): Conv(
        (conv): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (act): SiLU(inplace=True)
      )
      (20): Detect(
        (m): ModuleList(
          (0): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
)
class <lambda>(torch.nn.Module):
    def forward(self, arg0_1: f32[16, 3, 3, 3], arg1_1: f32[16], arg2_1: f32[32, 16, 3, 3], arg3_1: f32[32], arg4_1: f32[64, 32, 3, 3], arg5_1: f32[64], arg6_1: f32[128, 64, 3, 3], arg7_1: f32[128], arg8_1: f32[256, 128, 3, 3], arg9_1: f32[256], arg10_1: f32[512, 256, 3, 3], arg11_1: f32[512], arg12_1: f32[1024, 512, 3, 3], arg13_1: f32[1024], arg14_1: f32[256, 1024, 1, 1], arg15_1: f32[256], arg16_1: f32[512, 256, 3, 3], arg17_1: f32[512], arg18_1: f32[128, 256, 1, 1], arg19_1: f32[128], arg20_1: f32[256, 384, 3, 3], arg21_1: f32[256], arg22_1: f32[255, 256, 1, 1], arg23_1: f32[255], arg24_1: f32[255, 512, 1, 1], arg25_1: f32[255], arg26_1: f32[2, 3, 2], arg27_1: f32[2], arg28_1: f32[1, 3, 640, 480]):
        # File: /root/yolov3/models/common.py:59, code: return self.act(self.conv(x))
        convolution: f32[1, 16, 640, 480] = torch.ops.aten.convolution.default(arg28_1, arg0_1, arg1_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1);  arg28_1 = arg0_1 = arg1_1 = None
        silu: f32[1, 16, 640, 480] = torch.ops.aten.silu.default(convolution);  convolution = None
        
        # File: /root/yolov3/models/yolo.py:121, code: x = m(x)  # run
        max_pool2d_with_indices = torch.ops.aten.max_pool2d_with_indices.default(silu, [2, 2], [2, 2]);  silu = None
        getitem: f32[1, 16, 320, 240] = max_pool2d_with_indices[0];  max_pool2d_with_indices = None
        
        # File: /root/yolov3/models/common.py:59, code: return self.act(self.conv(x))
        convolution_1: f32[1, 32, 320, 240] = torch.ops.aten.convolution.default(getitem, arg2_1, arg3_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1);  getitem = arg2_1 = arg3_1 = None
        silu_1: f32[1, 32, 320, 240] = torch.ops.aten.silu.default(convolution_1);  convolution_1 = None
        
        # File: /root/yolov3/models/yolo.py:121, code: x = m(x)  # run
        max_pool2d_with_indices_1 = torch.ops.aten.max_pool2d_with_indices.default(silu_1, [2, 2], [2, 2]);  silu_1 = None
        getitem_2: f32[1, 32, 160, 120] = max_pool2d_with_indices_1[0];  max_pool2d_with_indices_1 = None
        
        # File: /root/yolov3/models/common.py:59, code: return self.act(self.conv(x))
        convolution_2: f32[1, 64, 160, 120] = torch.ops.aten.convolution.default(getitem_2, arg4_1, arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1);  getitem_2 = arg4_1 = arg5_1 = None
        silu_2: f32[1, 64, 160, 120] = torch.ops.aten.silu.default(convolution_2);  convolution_2 = None
        
        # File: /root/yolov3/models/yolo.py:121, code: x = m(x)  # run
        max_pool2d_with_indices_2 = torch.ops.aten.max_pool2d_with_indices.default(silu_2, [2, 2], [2, 2]);  silu_2 = None
        getitem_4: f32[1, 64, 80, 60] = max_pool2d_with_indices_2[0];  max_pool2d_with_indices_2 = None
        
        # File: /root/yolov3/models/common.py:59, code: return self.act(self.conv(x))
        convolution_3: f32[1, 128, 80, 60] = torch.ops.aten.convolution.default(getitem_4, arg6_1, arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1);  getitem_4 = arg6_1 = arg7_1 = None
        silu_3: f32[1, 128, 80, 60] = torch.ops.aten.silu.default(convolution_3);  convolution_3 = None
        
        # File: /root/yolov3/models/yolo.py:121, code: x = m(x)  # run
        max_pool2d_with_indices_3 = torch.ops.aten.max_pool2d_with_indices.default(silu_3, [2, 2], [2, 2]);  silu_3 = None
        getitem_6: f32[1, 128, 40, 30] = max_pool2d_with_indices_3[0];  max_pool2d_with_indices_3 = None
        
        # File: /root/yolov3/models/common.py:59, code: return self.act(self.conv(x))
        convolution_4: f32[1, 256, 40, 30] = torch.ops.aten.convolution.default(getitem_6, arg8_1, arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1);  getitem_6 = arg8_1 = arg9_1 = None
        silu_4: f32[1, 256, 40, 30] = torch.ops.aten.silu.default(convolution_4);  convolution_4 = None
        
        # File: /root/yolov3/models/yolo.py:121, code: x = m(x)  # run
        max_pool2d_with_indices_4 = torch.ops.aten.max_pool2d_with_indices.default(silu_4, [2, 2], [2, 2])
        getitem_8: f32[1, 256, 20, 15] = max_pool2d_with_indices_4[0];  max_pool2d_with_indices_4 = None
        
        # File: /root/yolov3/models/common.py:59, code: return self.act(self.conv(x))
        convolution_5: f32[1, 512, 20, 15] = torch.ops.aten.convolution.default(getitem_8, arg10_1, arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1);  getitem_8 = arg10_1 = arg11_1 = None
        silu_5: f32[1, 512, 20, 15] = torch.ops.aten.silu.default(convolution_5);  convolution_5 = None
        
        # File: /root/yolov3/models/yolo.py:121, code: x = m(x)  # run
        constant_pad_nd: f32[1, 512, 21, 16] = torch.ops.aten.constant_pad_nd.default(silu_5, [0, 1, 0, 1], 0.0);  silu_5 = None
        max_pool2d_with_indices_5 = torch.ops.aten.max_pool2d_with_indices.default(constant_pad_nd, [2, 2], [1, 1]);  constant_pad_nd = None
        getitem_10: f32[1, 512, 20, 15] = max_pool2d_with_indices_5[0];  max_pool2d_with_indices_5 = None
        
        # File: /root/yolov3/models/common.py:59, code: return self.act(self.conv(x))
        convolution_6: f32[1, 1024, 20, 15] = torch.ops.aten.convolution.default(getitem_10, arg12_1, arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1);  getitem_10 = arg12_1 = arg13_1 = None
        silu_6: f32[1, 1024, 20, 15] = torch.ops.aten.silu.default(convolution_6);  convolution_6 = None
        convolution_7: f32[1, 256, 20, 15] = torch.ops.aten.convolution.default(silu_6, arg14_1, arg15_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1);  silu_6 = arg14_1 = arg15_1 = None
        silu_7: f32[1, 256, 20, 15] = torch.ops.aten.silu.default(convolution_7);  convolution_7 = None
        convolution_8: f32[1, 512, 20, 15] = torch.ops.aten.convolution.default(silu_7, arg16_1, arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1);  arg16_1 = arg17_1 = None
        silu_8: f32[1, 512, 20, 15] = torch.ops.aten.silu.default(convolution_8);  convolution_8 = None
        convolution_9: f32[1, 128, 20, 15] = torch.ops.aten.convolution.default(silu_7, arg18_1, arg19_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1);  silu_7 = arg18_1 = arg19_1 = None
        silu_9: f32[1, 128, 20, 15] = torch.ops.aten.silu.default(convolution_9);  convolution_9 = None
        
        # File: /root/yolov3/models/yolo.py:121, code: x = m(x)  # run
        arange: f32[40] = torch.ops.aten.arange.default(40, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        mul: f32[40] = torch.ops.aten.mul.Tensor(arange, 0.5);  arange = None
        _to_copy: i64[40] = torch.ops.aten._to_copy.default(mul, dtype = torch.int64);  mul = None
        unsqueeze: i64[40, 1] = torch.ops.aten.unsqueeze.default(_to_copy, -1);  _to_copy = None
        arange_1: f32[30] = torch.ops.aten.arange.default(30, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        mul_1: f32[30] = torch.ops.aten.mul.Tensor(arange_1, 0.5);  arange_1 = None
        _to_copy_1: i64[30] = torch.ops.aten._to_copy.default(mul_1, dtype = torch.int64);  mul_1 = None
        _unsafe_index: f32[1, 128, 40, 30] = torch.ops.aten._unsafe_index.Tensor(silu_9, [None, None, unsqueeze, _to_copy_1]);  silu_9 = unsqueeze = _to_copy_1 = None
        
        # File: /root/yolov3/models/common.py:312, code: return torch.cat(x, self.d)
        cat: f32[1, 384, 40, 30] = torch.ops.aten.cat.default([_unsafe_index, silu_4], 1);  _unsafe_index = silu_4 = None
        
        # File: /root/yolov3/models/common.py:59, code: return self.act(self.conv(x))
        convolution_10: f32[1, 256, 40, 30] = torch.ops.aten.convolution.default(cat, arg20_1, arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1);  cat = arg20_1 = arg21_1 = None
        silu_10: f32[1, 256, 40, 30] = torch.ops.aten.silu.default(convolution_10);  convolution_10 = None
        
        # File: /root/yolov3/models/yolo.py:59, code: x[i] = self.m[i](x[i])  # conv
        convolution_11: f32[1, 255, 40, 30] = torch.ops.aten.convolution.default(silu_10, arg22_1, arg23_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1);  silu_10 = arg22_1 = arg23_1 = None
        
        # File: /root/yolov3/models/yolo.py:61, code: x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()
        view: f32[1, 3, 85, 40, 30] = torch.ops.aten.view.default(convolution_11, [1, 3, 85, 40, 30]);  convolution_11 = None
        permute: f32[1, 3, 40, 30, 85] = torch.ops.aten.permute.default(view, [0, 1, 3, 4, 2]);  view = None
        clone: f32[1, 3, 40, 30, 85] = torch.ops.aten.clone.default(permute, memory_format = torch.contiguous_format);  permute = None
        
        # File: /root/yolov3/models/yolo.py:85, code: y, x = torch.arange(ny, device=d, dtype=t), torch.arange(nx, device=d, dtype=t)
        arange_2: f32[40] = torch.ops.aten.arange.default(40, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        arange_3: f32[30] = torch.ops.aten.arange.default(30, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        
        # File: /root/yolov3/models/yolo.py:86, code: yv, xv = torch.meshgrid(y, x, indexing='ij') if torch_1_10 else torch.meshgrid(y, x)  # torch>=0.7 compatibility
        view_1: f32[40, 1] = torch.ops.aten.view.default(arange_2, [-1, 1]);  arange_2 = None
        expand: f32[40, 30] = torch.ops.aten.expand.default(view_1, [40, 30]);  view_1 = None
        view_2: f32[1, 30] = torch.ops.aten.view.default(arange_3, [1, -1]);  arange_3 = None
        expand_1: f32[40, 30] = torch.ops.aten.expand.default(view_2, [40, 30]);  view_2 = None
        
        # File: /root/yolov3/models/yolo.py:87, code: grid = torch.stack((xv, yv), 2).expand(shape) - 0.5  # add grid offset, i.e. y = 2.0 * x - 0.5
        stack: f32[40, 30, 2] = torch.ops.aten.stack.default([expand_1, expand], 2);  expand_1 = expand = None
        expand_2: f32[1, 3, 40, 30, 2] = torch.ops.aten.expand.default(stack, [1, 3, 40, 30, 2]);  stack = None
        sub: f32[1, 3, 40, 30, 2] = torch.ops.aten.sub.Tensor(expand_2, 0.5);  expand_2 = None
        
        # File: /root/yolov3/models/yolo.py:88, code: anchor_grid = (self.anchors[i] * self.stride[i]).view((1, self.na, 1, 1, 2)).expand(shape)
        select: f32[3, 2] = torch.ops.aten.select.int(arg26_1, 0, 0)
        select_1: f32[] = torch.ops.aten.select.int(arg27_1, 0, 0)
        mul_2: f32[3, 2] = torch.ops.aten.mul.Tensor(select, select_1);  select = select_1 = None
        view_3: f32[1, 3, 1, 1, 2] = torch.ops.aten.view.default(mul_2, [1, 3, 1, 1, 2]);  mul_2 = None
        expand_3: f32[1, 3, 40, 30, 2] = torch.ops.aten.expand.default(view_3, [1, 3, 40, 30, 2]);  view_3 = None
        
        # File: /root/yolov3/models/yolo.py:73, code: xy, wh, conf = x[i].sigmoid().split((2, 2, self.nc + 1), 4)
        sigmoid: f32[1, 3, 40, 30, 85] = torch.ops.aten.sigmoid.default(clone)
        split_with_sizes = torch.ops.aten.split_with_sizes.default(sigmoid, [2, 2, 81], 4);  sigmoid = None
        getitem_12: f32[1, 3, 40, 30, 2] = split_with_sizes[0]
        getitem_13: f32[1, 3, 40, 30, 2] = split_with_sizes[1]
        getitem_14: f32[1, 3, 40, 30, 81] = split_with_sizes[2];  split_with_sizes = None
        
        # File: /root/yolov3/models/yolo.py:74, code: xy = (xy * 2 + self.grid[i]) * self.stride[i]  # xy
        mul_3: f32[1, 3, 40, 30, 2] = torch.ops.aten.mul.Tensor(getitem_12, 2);  getitem_12 = None
        add: f32[1, 3, 40, 30, 2] = torch.ops.aten.add.Tensor(mul_3, sub);  mul_3 = None
        select_2: f32[] = torch.ops.aten.select.int(arg27_1, 0, 0)
        mul_4: f32[1, 3, 40, 30, 2] = torch.ops.aten.mul.Tensor(add, select_2);  add = select_2 = None
        
        # File: /root/yolov3/models/yolo.py:75, code: wh = (wh * 2) ** 2 * self.anchor_grid[i]  # wh
        mul_5: f32[1, 3, 40, 30, 2] = torch.ops.aten.mul.Tensor(getitem_13, 2);  getitem_13 = None
        pow_1: f32[1, 3, 40, 30, 2] = torch.ops.aten.pow.Tensor_Scalar(mul_5, 2);  mul_5 = None
        mul_6: f32[1, 3, 40, 30, 2] = torch.ops.aten.mul.Tensor(pow_1, expand_3);  pow_1 = None
        
        # File: /root/yolov3/models/yolo.py:76, code: y = torch.cat((xy, wh, conf), 4)
        cat_1: f32[1, 3, 40, 30, 85] = torch.ops.aten.cat.default([mul_4, mul_6, getitem_14], 4);  mul_4 = mul_6 = getitem_14 = None
        
        # File: /root/yolov3/models/yolo.py:77, code: z.append(y.view(bs, self.na * nx * ny, self.no))
        view_4: f32[1, 3600, 85] = torch.ops.aten.view.default(cat_1, [1, 3600, 85]);  cat_1 = None
        
        # File: /root/yolov3/models/yolo.py:59, code: x[i] = self.m[i](x[i])  # conv
        convolution_12: f32[1, 255, 20, 15] = torch.ops.aten.convolution.default(silu_8, arg24_1, arg25_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1);  silu_8 = arg24_1 = arg25_1 = None
        
        # File: /root/yolov3/models/yolo.py:61, code: x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()
        view_5: f32[1, 3, 85, 20, 15] = torch.ops.aten.view.default(convolution_12, [1, 3, 85, 20, 15]);  convolution_12 = None
        permute_1: f32[1, 3, 20, 15, 85] = torch.ops.aten.permute.default(view_5, [0, 1, 3, 4, 2]);  view_5 = None
        clone_1: f32[1, 3, 20, 15, 85] = torch.ops.aten.clone.default(permute_1, memory_format = torch.contiguous_format);  permute_1 = None
        
        # File: /root/yolov3/models/yolo.py:85, code: y, x = torch.arange(ny, device=d, dtype=t), torch.arange(nx, device=d, dtype=t)
        arange_4: f32[20] = torch.ops.aten.arange.default(20, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        arange_5: f32[15] = torch.ops.aten.arange.default(15, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        
        # File: /root/yolov3/models/yolo.py:86, code: yv, xv = torch.meshgrid(y, x, indexing='ij') if torch_1_10 else torch.meshgrid(y, x)  # torch>=0.7 compatibility
        view_6: f32[20, 1] = torch.ops.aten.view.default(arange_4, [-1, 1]);  arange_4 = None
        expand_4: f32[20, 15] = torch.ops.aten.expand.default(view_6, [20, 15]);  view_6 = None
        view_7: f32[1, 15] = torch.ops.aten.view.default(arange_5, [1, -1]);  arange_5 = None
        expand_5: f32[20, 15] = torch.ops.aten.expand.default(view_7, [20, 15]);  view_7 = None
        
        # File: /root/yolov3/models/yolo.py:87, code: grid = torch.stack((xv, yv), 2).expand(shape) - 0.5  # add grid offset, i.e. y = 2.0 * x - 0.5
        stack_1: f32[20, 15, 2] = torch.ops.aten.stack.default([expand_5, expand_4], 2);  expand_5 = expand_4 = None
        expand_6: f32[1, 3, 20, 15, 2] = torch.ops.aten.expand.default(stack_1, [1, 3, 20, 15, 2]);  stack_1 = None
        sub_1: f32[1, 3, 20, 15, 2] = torch.ops.aten.sub.Tensor(expand_6, 0.5);  expand_6 = None
        
        # File: /root/yolov3/models/yolo.py:88, code: anchor_grid = (self.anchors[i] * self.stride[i]).view((1, self.na, 1, 1, 2)).expand(shape)
        select_3: f32[3, 2] = torch.ops.aten.select.int(arg26_1, 0, 1);  arg26_1 = None
        select_4: f32[] = torch.ops.aten.select.int(arg27_1, 0, 1)
        mul_7: f32[3, 2] = torch.ops.aten.mul.Tensor(select_3, select_4);  select_3 = select_4 = None
        view_8: f32[1, 3, 1, 1, 2] = torch.ops.aten.view.default(mul_7, [1, 3, 1, 1, 2]);  mul_7 = None
        expand_7: f32[1, 3, 20, 15, 2] = torch.ops.aten.expand.default(view_8, [1, 3, 20, 15, 2]);  view_8 = None
        
        # File: /root/yolov3/models/yolo.py:73, code: xy, wh, conf = x[i].sigmoid().split((2, 2, self.nc + 1), 4)
        sigmoid_1: f32[1, 3, 20, 15, 85] = torch.ops.aten.sigmoid.default(clone_1)
        split_with_sizes_1 = torch.ops.aten.split_with_sizes.default(sigmoid_1, [2, 2, 81], 4);  sigmoid_1 = None
        getitem_15: f32[1, 3, 20, 15, 2] = split_with_sizes_1[0]
        getitem_16: f32[1, 3, 20, 15, 2] = split_with_sizes_1[1]
        getitem_17: f32[1, 3, 20, 15, 81] = split_with_sizes_1[2];  split_with_sizes_1 = None
        
        # File: /root/yolov3/models/yolo.py:74, code: xy = (xy * 2 + self.grid[i]) * self.stride[i]  # xy
        mul_8: f32[1, 3, 20, 15, 2] = torch.ops.aten.mul.Tensor(getitem_15, 2);  getitem_15 = None
        add_1: f32[1, 3, 20, 15, 2] = torch.ops.aten.add.Tensor(mul_8, sub_1);  mul_8 = None
        select_5: f32[] = torch.ops.aten.select.int(arg27_1, 0, 1);  arg27_1 = None
        mul_9: f32[1, 3, 20, 15, 2] = torch.ops.aten.mul.Tensor(add_1, select_5);  add_1 = select_5 = None
        
        # File: /root/yolov3/models/yolo.py:75, code: wh = (wh * 2) ** 2 * self.anchor_grid[i]  # wh
        mul_10: f32[1, 3, 20, 15, 2] = torch.ops.aten.mul.Tensor(getitem_16, 2);  getitem_16 = None
        pow_2: f32[1, 3, 20, 15, 2] = torch.ops.aten.pow.Tensor_Scalar(mul_10, 2);  mul_10 = None
        mul_11: f32[1, 3, 20, 15, 2] = torch.ops.aten.mul.Tensor(pow_2, expand_7);  pow_2 = None
        
        # File: /root/yolov3/models/yolo.py:76, code: y = torch.cat((xy, wh, conf), 4)
        cat_2: f32[1, 3, 20, 15, 85] = torch.ops.aten.cat.default([mul_9, mul_11, getitem_17], 4);  mul_9 = mul_11 = getitem_17 = None
        
        # File: /root/yolov3/models/yolo.py:77, code: z.append(y.view(bs, self.na * nx * ny, self.no))
        view_9: f32[1, 900, 85] = torch.ops.aten.view.default(cat_2, [1, 900, 85]);  cat_2 = None
        
        # File: /root/yolov3/models/yolo.py:79, code: return x if self.training else (torch.cat(z, 1), ) if self.export else (torch.cat(z, 1), x)
        cat_3: f32[1, 4500, 85] = torch.ops.aten.cat.default([view_4, view_9], 1);  view_4 = view_9 = None
        return (cat_3, clone, clone_1, sub, sub_1, expand_3, expand_7)
        
{'name': 'arg0_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg0_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution: None}, 'prev_node': '', 'next_node': 'arg1_1', 'meta': {'val': FakeTensor(..., size=(16, 3, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([16, 3, 3, 3]), dtype=torch.float32, requires_grad=False, stride=(27, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg1_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg1_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution: None}, 'prev_node': 'arg0_1', 'next_node': 'arg2_1', 'meta': {'val': FakeTensor(..., size=(16,)), 'tensor_meta': TensorMetadata(shape=torch.Size([16]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg2_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg2_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution_1: None}, 'prev_node': 'arg1_1', 'next_node': 'arg3_1', 'meta': {'val': FakeTensor(..., size=(32, 16, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([32, 16, 3, 3]), dtype=torch.float32, requires_grad=False, stride=(144, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg3_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg3_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution_1: None}, 'prev_node': 'arg2_1', 'next_node': 'arg4_1', 'meta': {'val': FakeTensor(..., size=(32,)), 'tensor_meta': TensorMetadata(shape=torch.Size([32]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg4_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg4_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution_2: None}, 'prev_node': 'arg3_1', 'next_node': 'arg5_1', 'meta': {'val': FakeTensor(..., size=(64, 32, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 32, 3, 3]), dtype=torch.float32, requires_grad=False, stride=(288, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg5_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg5_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution_2: None}, 'prev_node': 'arg4_1', 'next_node': 'arg6_1', 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg6_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg6_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution_3: None}, 'prev_node': 'arg5_1', 'next_node': 'arg7_1', 'meta': {'val': FakeTensor(..., size=(128, 64, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 64, 3, 3]), dtype=torch.float32, requires_grad=False, stride=(576, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg7_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg7_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution_3: None}, 'prev_node': 'arg6_1', 'next_node': 'arg8_1', 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg8_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg8_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution_4: None}, 'prev_node': 'arg7_1', 'next_node': 'arg9_1', 'meta': {'val': FakeTensor(..., size=(256, 128, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 128, 3, 3]), dtype=torch.float32, requires_grad=False, stride=(1152, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg9_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg9_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution_4: None}, 'prev_node': 'arg8_1', 'next_node': 'arg10_1', 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg10_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg10_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution_5: None}, 'prev_node': 'arg9_1', 'next_node': 'arg11_1', 'meta': {'val': FakeTensor(..., size=(512, 256, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 256, 3, 3]), dtype=torch.float32, requires_grad=False, stride=(2304, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg11_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg11_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution_5: None}, 'prev_node': 'arg10_1', 'next_node': 'arg12_1', 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg12_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg12_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution_6: None}, 'prev_node': 'arg11_1', 'next_node': 'arg13_1', 'meta': {'val': FakeTensor(..., size=(1024, 512, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([1024, 512, 3, 3]), dtype=torch.float32, requires_grad=False, stride=(4608, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg13_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg13_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution_6: None}, 'prev_node': 'arg12_1', 'next_node': 'arg14_1', 'meta': {'val': FakeTensor(..., size=(1024,)), 'tensor_meta': TensorMetadata(shape=torch.Size([1024]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg14_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg14_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution_7: None}, 'prev_node': 'arg13_1', 'next_node': 'arg15_1', 'meta': {'val': FakeTensor(..., size=(256, 1024, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1024, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1024, 1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg15_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg15_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution_7: None}, 'prev_node': 'arg14_1', 'next_node': 'arg16_1', 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg16_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg16_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution_8: None}, 'prev_node': 'arg15_1', 'next_node': 'arg17_1', 'meta': {'val': FakeTensor(..., size=(512, 256, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 256, 3, 3]), dtype=torch.float32, requires_grad=False, stride=(2304, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg17_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg17_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution_8: None}, 'prev_node': 'arg16_1', 'next_node': 'arg18_1', 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg18_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg18_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution_9: None}, 'prev_node': 'arg17_1', 'next_node': 'arg19_1', 'meta': {'val': FakeTensor(..., size=(128, 256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 256, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(256, 1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg19_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg19_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution_9: None}, 'prev_node': 'arg18_1', 'next_node': 'arg20_1', 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg20_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg20_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution_10: None}, 'prev_node': 'arg19_1', 'next_node': 'arg21_1', 'meta': {'val': FakeTensor(..., size=(256, 384, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 384, 3, 3]), dtype=torch.float32, requires_grad=False, stride=(3456, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg21_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg21_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution_10: None}, 'prev_node': 'arg20_1', 'next_node': 'arg22_1', 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg22_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg22_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution_11: None}, 'prev_node': 'arg21_1', 'next_node': 'arg23_1', 'meta': {'val': FakeTensor(..., size=(255, 256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([255, 256, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(256, 1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg23_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg23_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution_11: None}, 'prev_node': 'arg22_1', 'next_node': 'arg24_1', 'meta': {'val': FakeTensor(..., size=(255,)), 'tensor_meta': TensorMetadata(shape=torch.Size([255]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg24_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg24_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution_12: None}, 'prev_node': 'arg23_1', 'next_node': 'arg25_1', 'meta': {'val': FakeTensor(..., size=(255, 512, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([255, 512, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(512, 1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg25_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg25_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution_12: None}, 'prev_node': 'arg24_1', 'next_node': 'arg26_1', 'meta': {'val': FakeTensor(..., size=(255,)), 'tensor_meta': TensorMetadata(shape=torch.Size([255]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg26_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg26_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {select: None, select_3: None}, 'prev_node': 'arg25_1', 'next_node': 'arg27_1', 'meta': {'val': FakeTensor(..., size=(2, 3, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([2, 3, 2]), dtype=torch.float32, requires_grad=False, stride=(6, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg27_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg27_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {select_1: None, select_2: None, select_4: None, select_5: None}, 'prev_node': 'arg26_1', 'next_node': 'arg28_1', 'meta': {'val': FakeTensor(..., size=(2,)), 'tensor_meta': TensorMetadata(shape=torch.Size([2]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arg28_1', 'op': 'placeholder', 'op_name': None, 'target': 'arg28_1', '_input_nodes': {}, 'args': (), 'kwargs': {}, 'users': {convolution: None}, 'prev_node': 'arg27_1', 'next_node': 'convolution', 'meta': {'val': FakeTensor(..., size=(1, 3, 640, 480)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 640, 480]), dtype=torch.float32, requires_grad=False, stride=(921600, 307200, 480, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'convolution', 'op': 'call_function', 'op_name': 'convolution.default', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {arg28_1: None, arg0_1: None, arg1_1: None}, 'args': (arg28_1, arg0_1, arg1_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), 'kwargs': {}, 'users': {silu: None}, 'prev_node': 'arg28_1', 'next_node': 'silu', 'meta': {'val': FakeTensor(..., size=(1, 16, 640, 480)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 16, 640, 480]), dtype=torch.float32, requires_grad=False, stride=(4915200, 307200, 480, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'silu', 'op': 'call_function', 'op_name': 'silu.default', 'target': <OpOverload(op='aten.silu', overload='default')>, '_input_nodes': {convolution: None}, 'args': (convolution,), 'kwargs': {}, 'users': {max_pool2d_with_indices: None}, 'prev_node': 'convolution', 'next_node': 'getitem', 'meta': {'val': FakeTensor(..., size=(1, 16, 640, 480)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 16, 640, 480]), dtype=torch.float32, requires_grad=False, stride=(4915200, 307200, 480, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'getitem', 'op': 'call_function', 'op_name': 'maxpool2d.tosa_default', 'target': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, '_input_nodes': {silu: None}, 'args': (silu, [2, 2], [2, 2]), 'kwargs': {}, 'users': {convolution_1: None}, 'prev_node': 'silu', 'next_node': 'convolution_1', 'meta': {'val': FakeTensor(..., size=(1, 16, 320, 240)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 16, 320, 240]), dtype=torch.float32, requires_grad=False, stride=(1228800, 76800, 240, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'convolution_1', 'op': 'call_function', 'op_name': 'convolution.default', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {getitem: None, arg2_1: None, arg3_1: None}, 'args': (getitem, arg2_1, arg3_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), 'kwargs': {}, 'users': {silu_1: None}, 'prev_node': 'getitem', 'next_node': 'silu_1', 'meta': {'val': FakeTensor(..., size=(1, 32, 320, 240)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 32, 320, 240]), dtype=torch.float32, requires_grad=False, stride=(2457600, 76800, 240, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'silu_1', 'op': 'call_function', 'op_name': 'silu.default', 'target': <OpOverload(op='aten.silu', overload='default')>, '_input_nodes': {convolution_1: None}, 'args': (convolution_1,), 'kwargs': {}, 'users': {max_pool2d_with_indices_1: None}, 'prev_node': 'convolution_1', 'next_node': 'getitem_2', 'meta': {'val': FakeTensor(..., size=(1, 32, 320, 240)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 32, 320, 240]), dtype=torch.float32, requires_grad=False, stride=(2457600, 76800, 240, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'getitem_2', 'op': 'call_function', 'op_name': 'maxpool2d.tosa_default', 'target': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, '_input_nodes': {silu_1: None}, 'args': (silu_1, [2, 2], [2, 2]), 'kwargs': {}, 'users': {convolution_2: None}, 'prev_node': 'silu_1', 'next_node': 'convolution_2', 'meta': {'val': FakeTensor(..., size=(1, 32, 160, 120)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 32, 160, 120]), dtype=torch.float32, requires_grad=False, stride=(614400, 19200, 120, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'convolution_2', 'op': 'call_function', 'op_name': 'convolution.default', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {getitem_2: None, arg4_1: None, arg5_1: None}, 'args': (getitem_2, arg4_1, arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), 'kwargs': {}, 'users': {silu_2: None}, 'prev_node': 'getitem_2', 'next_node': 'silu_2', 'meta': {'val': FakeTensor(..., size=(1, 64, 160, 120)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 160, 120]), dtype=torch.float32, requires_grad=False, stride=(1228800, 19200, 120, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'silu_2', 'op': 'call_function', 'op_name': 'silu.default', 'target': <OpOverload(op='aten.silu', overload='default')>, '_input_nodes': {convolution_2: None}, 'args': (convolution_2,), 'kwargs': {}, 'users': {max_pool2d_with_indices_2: None}, 'prev_node': 'convolution_2', 'next_node': 'getitem_4', 'meta': {'val': FakeTensor(..., size=(1, 64, 160, 120)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 160, 120]), dtype=torch.float32, requires_grad=False, stride=(1228800, 19200, 120, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'getitem_4', 'op': 'call_function', 'op_name': 'maxpool2d.tosa_default', 'target': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, '_input_nodes': {silu_2: None}, 'args': (silu_2, [2, 2], [2, 2]), 'kwargs': {}, 'users': {convolution_3: None}, 'prev_node': 'silu_2', 'next_node': 'convolution_3', 'meta': {'val': FakeTensor(..., size=(1, 64, 80, 60)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 80, 60]), dtype=torch.float32, requires_grad=False, stride=(307200, 4800, 60, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'convolution_3', 'op': 'call_function', 'op_name': 'convolution.default', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {getitem_4: None, arg6_1: None, arg7_1: None}, 'args': (getitem_4, arg6_1, arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), 'kwargs': {}, 'users': {silu_3: None}, 'prev_node': 'getitem_4', 'next_node': 'silu_3', 'meta': {'val': FakeTensor(..., size=(1, 128, 80, 60)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 80, 60]), dtype=torch.float32, requires_grad=False, stride=(614400, 4800, 60, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'silu_3', 'op': 'call_function', 'op_name': 'silu.default', 'target': <OpOverload(op='aten.silu', overload='default')>, '_input_nodes': {convolution_3: None}, 'args': (convolution_3,), 'kwargs': {}, 'users': {max_pool2d_with_indices_3: None}, 'prev_node': 'convolution_3', 'next_node': 'getitem_6', 'meta': {'val': FakeTensor(..., size=(1, 128, 80, 60)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 80, 60]), dtype=torch.float32, requires_grad=False, stride=(614400, 4800, 60, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'getitem_6', 'op': 'call_function', 'op_name': 'maxpool2d.tosa_default', 'target': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, '_input_nodes': {silu_3: None}, 'args': (silu_3, [2, 2], [2, 2]), 'kwargs': {}, 'users': {convolution_4: None}, 'prev_node': 'silu_3', 'next_node': 'convolution_4', 'meta': {'val': FakeTensor(..., size=(1, 128, 40, 30)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 40, 30]), dtype=torch.float32, requires_grad=False, stride=(153600, 1200, 30, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'convolution_4', 'op': 'call_function', 'op_name': 'convolution.default', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {getitem_6: None, arg8_1: None, arg9_1: None}, 'args': (getitem_6, arg8_1, arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), 'kwargs': {}, 'users': {silu_4: None}, 'prev_node': 'getitem_6', 'next_node': 'silu_4', 'meta': {'val': FakeTensor(..., size=(1, 256, 40, 30)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 40, 30]), dtype=torch.float32, requires_grad=False, stride=(307200, 1200, 30, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'silu_4', 'op': 'call_function', 'op_name': 'silu.default', 'target': <OpOverload(op='aten.silu', overload='default')>, '_input_nodes': {convolution_4: None}, 'args': (convolution_4,), 'kwargs': {}, 'users': {max_pool2d_with_indices_4: None, cat: None}, 'prev_node': 'convolution_4', 'next_node': 'getitem_8', 'meta': {'val': FakeTensor(..., size=(1, 256, 40, 30)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 40, 30]), dtype=torch.float32, requires_grad=False, stride=(307200, 1200, 30, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'getitem_8', 'op': 'call_function', 'op_name': 'maxpool2d.tosa_default', 'target': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, '_input_nodes': {silu_4: None}, 'args': (silu_4, [2, 2], [2, 2]), 'kwargs': {}, 'users': {convolution_5: None}, 'prev_node': 'silu_4', 'next_node': 'convolution_5', 'meta': {'val': FakeTensor(..., size=(1, 256, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(76800, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'convolution_5', 'op': 'call_function', 'op_name': 'convolution.default', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {getitem_8: None, arg10_1: None, arg11_1: None}, 'args': (getitem_8, arg10_1, arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), 'kwargs': {}, 'users': {silu_5: None}, 'prev_node': 'getitem_8', 'next_node': 'silu_5', 'meta': {'val': FakeTensor(..., size=(1, 512, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(153600, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'silu_5', 'op': 'call_function', 'op_name': 'silu.default', 'target': <OpOverload(op='aten.silu', overload='default')>, '_input_nodes': {convolution_5: None}, 'args': (convolution_5,), 'kwargs': {}, 'users': {constant_pad_nd: None}, 'prev_node': 'convolution_5', 'next_node': 'constant_pad_nd', 'meta': {'val': FakeTensor(..., size=(1, 512, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(153600, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'constant_pad_nd', 'op': 'call_function', 'op_name': 'constant_pad_nd.default', 'target': <OpOverload(op='aten.constant_pad_nd', overload='default')>, '_input_nodes': {silu_5: None}, 'args': (silu_5, [0, 1, 0, 1], 0.0), 'kwargs': {}, 'users': {max_pool2d_with_indices_5: None}, 'prev_node': 'silu_5', 'next_node': 'getitem_10', 'meta': {'val': FakeTensor(..., size=(1, 512, 21, 16)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 21, 16]), dtype=torch.float32, requires_grad=False, stride=(172032, 336, 16, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'getitem_10', 'op': 'call_function', 'op_name': 'maxpool2d.tosa_default', 'target': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, '_input_nodes': {constant_pad_nd: None}, 'args': (constant_pad_nd, [2, 2], [1, 1]), 'kwargs': {}, 'users': {convolution_6: None}, 'prev_node': 'constant_pad_nd', 'next_node': 'convolution_6', 'meta': {'val': FakeTensor(..., size=(1, 512, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(153600, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'convolution_6', 'op': 'call_function', 'op_name': 'convolution.default', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {getitem_10: None, arg12_1: None, arg13_1: None}, 'args': (getitem_10, arg12_1, arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), 'kwargs': {}, 'users': {silu_6: None}, 'prev_node': 'getitem_10', 'next_node': 'silu_6', 'meta': {'val': FakeTensor(..., size=(1, 1024, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 1024, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(307200, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'silu_6', 'op': 'call_function', 'op_name': 'silu.default', 'target': <OpOverload(op='aten.silu', overload='default')>, '_input_nodes': {convolution_6: None}, 'args': (convolution_6,), 'kwargs': {}, 'users': {convolution_7: None}, 'prev_node': 'convolution_6', 'next_node': 'convolution_7', 'meta': {'val': FakeTensor(..., size=(1, 1024, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 1024, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(307200, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'convolution_7', 'op': 'call_function', 'op_name': 'convolution.default', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {silu_6: None, arg14_1: None, arg15_1: None}, 'args': (silu_6, arg14_1, arg15_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), 'kwargs': {}, 'users': {silu_7: None}, 'prev_node': 'silu_6', 'next_node': 'silu_7', 'meta': {'val': FakeTensor(..., size=(1, 256, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(76800, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'silu_7', 'op': 'call_function', 'op_name': 'silu.default', 'target': <OpOverload(op='aten.silu', overload='default')>, '_input_nodes': {convolution_7: None}, 'args': (convolution_7,), 'kwargs': {}, 'users': {convolution_8: None, convolution_9: None}, 'prev_node': 'convolution_7', 'next_node': 'convolution_8', 'meta': {'val': FakeTensor(..., size=(1, 256, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(76800, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'convolution_8', 'op': 'call_function', 'op_name': 'convolution.default', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {silu_7: None, arg16_1: None, arg17_1: None}, 'args': (silu_7, arg16_1, arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), 'kwargs': {}, 'users': {silu_8: None}, 'prev_node': 'silu_7', 'next_node': 'silu_8', 'meta': {'val': FakeTensor(..., size=(1, 512, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(153600, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'silu_8', 'op': 'call_function', 'op_name': 'silu.default', 'target': <OpOverload(op='aten.silu', overload='default')>, '_input_nodes': {convolution_8: None}, 'args': (convolution_8,), 'kwargs': {}, 'users': {convolution_12: None}, 'prev_node': 'convolution_8', 'next_node': 'convolution_9', 'meta': {'val': FakeTensor(..., size=(1, 512, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(153600, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'convolution_9', 'op': 'call_function', 'op_name': 'convolution.default', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {silu_7: None, arg18_1: None, arg19_1: None}, 'args': (silu_7, arg18_1, arg19_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), 'kwargs': {}, 'users': {silu_9: None}, 'prev_node': 'silu_8', 'next_node': 'silu_9', 'meta': {'val': FakeTensor(..., size=(1, 128, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(38400, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'silu_9', 'op': 'call_function', 'op_name': 'silu.default', 'target': <OpOverload(op='aten.silu', overload='default')>, '_input_nodes': {convolution_9: None}, 'args': (convolution_9,), 'kwargs': {}, 'users': {_unsafe_index: None}, 'prev_node': 'convolution_9', 'next_node': 'arange', 'meta': {'val': FakeTensor(..., size=(1, 128, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(38400, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arange', 'op': 'call_function', 'op_name': 'arange.default', 'target': <OpOverload(op='aten.arange', overload='default')>, '_input_nodes': {}, 'args': (40,), 'kwargs': {'dtype': torch.float32, 'device': device(type='cpu'), 'pin_memory': False}, 'users': {mul: None}, 'prev_node': 'silu_9', 'next_node': 'mul', 'meta': {'val': FakeTensor(..., size=(40,)), 'tensor_meta': TensorMetadata(shape=torch.Size([40]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'mul', 'op': 'call_function', 'op_name': 'mul.Tensor', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {arange: None}, 'args': (arange, 0.5), 'kwargs': {}, 'users': {_to_copy: None}, 'prev_node': 'arange', 'next_node': '_to_copy', 'meta': {'val': FakeTensor(..., size=(40,)), 'tensor_meta': TensorMetadata(shape=torch.Size([40]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': '_to_copy', 'op': 'call_function', 'op_name': '_to_copy.default', 'target': <OpOverload(op='aten._to_copy', overload='default')>, '_input_nodes': {mul: None}, 'args': (mul,), 'kwargs': {'dtype': torch.int64}, 'users': {unsqueeze: None}, 'prev_node': 'mul', 'next_node': 'unsqueeze', 'meta': {'val': FakeTensor(..., size=(40,), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([40]), dtype=torch.int64, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'unsqueeze', 'op': 'call_function', 'op_name': 'unsqueeze.default', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {_to_copy: None}, 'args': (_to_copy, -1), 'kwargs': {}, 'users': {_unsafe_index: None}, 'prev_node': '_to_copy', 'next_node': 'arange_1', 'meta': {'val': FakeTensor(..., size=(40, 1), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([40, 1]), dtype=torch.int64, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arange_1', 'op': 'call_function', 'op_name': 'arange.default', 'target': <OpOverload(op='aten.arange', overload='default')>, '_input_nodes': {}, 'args': (30,), 'kwargs': {'dtype': torch.float32, 'device': device(type='cpu'), 'pin_memory': False}, 'users': {mul_1: None}, 'prev_node': 'unsqueeze', 'next_node': 'mul_1', 'meta': {'val': FakeTensor(..., size=(30,)), 'tensor_meta': TensorMetadata(shape=torch.Size([30]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'mul_1', 'op': 'call_function', 'op_name': 'mul.Tensor', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {arange_1: None}, 'args': (arange_1, 0.5), 'kwargs': {}, 'users': {_to_copy_1: None}, 'prev_node': 'arange_1', 'next_node': '_to_copy_1', 'meta': {'val': FakeTensor(..., size=(30,)), 'tensor_meta': TensorMetadata(shape=torch.Size([30]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': '_to_copy_1', 'op': 'call_function', 'op_name': '_to_copy.default', 'target': <OpOverload(op='aten._to_copy', overload='default')>, '_input_nodes': {mul_1: None}, 'args': (mul_1,), 'kwargs': {'dtype': torch.int64}, 'users': {_unsafe_index: None}, 'prev_node': 'mul_1', 'next_node': '_unsafe_index', 'meta': {'val': FakeTensor(..., size=(30,), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([30]), dtype=torch.int64, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': '_unsafe_index', 'op': 'call_function', 'op_name': '_unsafe_index.Tensor', 'target': <OpOverload(op='aten._unsafe_index', overload='Tensor')>, '_input_nodes': {silu_9: None, unsqueeze: None, _to_copy_1: None}, 'args': (silu_9, [None, None, unsqueeze, _to_copy_1]), 'kwargs': {}, 'users': {cat: None}, 'prev_node': '_to_copy_1', 'next_node': 'cat', 'meta': {'val': FakeTensor(..., size=(1, 128, 40, 30)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 40, 30]), dtype=torch.float32, requires_grad=False, stride=(153600, 1200, 30, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'cat', 'op': 'call_function', 'op_name': 'cat.default', 'target': <OpOverload(op='aten.cat', overload='default')>, '_input_nodes': {_unsafe_index: None, silu_4: None}, 'args': ([_unsafe_index, silu_4], 1), 'kwargs': {}, 'users': {convolution_10: None}, 'prev_node': '_unsafe_index', 'next_node': 'convolution_10', 'meta': {'val': FakeTensor(..., size=(1, 384, 40, 30)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 384, 40, 30]), dtype=torch.float32, requires_grad=False, stride=(460800, 1200, 30, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'convolution_10', 'op': 'call_function', 'op_name': 'convolution.default', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {cat: None, arg20_1: None, arg21_1: None}, 'args': (cat, arg20_1, arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), 'kwargs': {}, 'users': {silu_10: None}, 'prev_node': 'cat', 'next_node': 'silu_10', 'meta': {'val': FakeTensor(..., size=(1, 256, 40, 30)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 40, 30]), dtype=torch.float32, requires_grad=False, stride=(307200, 1200, 30, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'silu_10', 'op': 'call_function', 'op_name': 'silu.default', 'target': <OpOverload(op='aten.silu', overload='default')>, '_input_nodes': {convolution_10: None}, 'args': (convolution_10,), 'kwargs': {}, 'users': {convolution_11: None}, 'prev_node': 'convolution_10', 'next_node': 'convolution_11', 'meta': {'val': FakeTensor(..., size=(1, 256, 40, 30)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 40, 30]), dtype=torch.float32, requires_grad=False, stride=(307200, 1200, 30, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'convolution_11', 'op': 'call_function', 'op_name': 'convolution.default', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {silu_10: None, arg22_1: None, arg23_1: None}, 'args': (silu_10, arg22_1, arg23_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), 'kwargs': {}, 'users': {view: None}, 'prev_node': 'silu_10', 'next_node': 'view', 'meta': {'val': FakeTensor(..., size=(1, 255, 40, 30)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 255, 40, 30]), dtype=torch.float32, requires_grad=False, stride=(306000, 1200, 30, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'view', 'op': 'call_function', 'op_name': 'view.default', 'target': <OpOverload(op='aten.view', overload='default')>, '_input_nodes': {convolution_11: None}, 'args': (convolution_11, [1, 3, 85, 40, 30]), 'kwargs': {}, 'users': {permute: None}, 'prev_node': 'convolution_11', 'next_node': 'permute', 'meta': {'val': FakeTensor(..., size=(1, 3, 85, 40, 30)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 85, 40, 30]), dtype=torch.float32, requires_grad=False, stride=(306000, 102000, 1200, 30, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'permute', 'op': 'call_function', 'op_name': 'permute.default', 'target': <OpOverload(op='aten.permute', overload='default')>, '_input_nodes': {view: None}, 'args': (view, [0, 1, 3, 4, 2]), 'kwargs': {}, 'users': {clone: None}, 'prev_node': 'view', 'next_node': 'clone', 'meta': {'val': FakeTensor(..., size=(1, 3, 40, 30, 85)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 85]), dtype=torch.float32, requires_grad=False, stride=(306000, 102000, 30, 1, 1200), memory_format=None, is_quantized=False, qparams={})}}
{'name': 'clone', 'op': 'call_function', 'op_name': 'clone.default', 'target': <OpOverload(op='aten.clone', overload='default')>, '_input_nodes': {permute: None}, 'args': (permute,), 'kwargs': {'memory_format': torch.contiguous_format}, 'users': {sigmoid: None, output: None}, 'prev_node': 'permute', 'next_node': 'arange_2', 'meta': {'val': FakeTensor(..., size=(1, 3, 40, 30, 85)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 85]), dtype=torch.float32, requires_grad=False, stride=(306000, 102000, 2550, 85, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arange_2', 'op': 'call_function', 'op_name': 'arange.default', 'target': <OpOverload(op='aten.arange', overload='default')>, '_input_nodes': {}, 'args': (40,), 'kwargs': {'dtype': torch.float32, 'device': device(type='cpu'), 'pin_memory': False}, 'users': {view_1: None}, 'prev_node': 'clone', 'next_node': 'arange_3', 'meta': {'val': FakeTensor(..., size=(40,)), 'tensor_meta': TensorMetadata(shape=torch.Size([40]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arange_3', 'op': 'call_function', 'op_name': 'arange.default', 'target': <OpOverload(op='aten.arange', overload='default')>, '_input_nodes': {}, 'args': (30,), 'kwargs': {'dtype': torch.float32, 'device': device(type='cpu'), 'pin_memory': False}, 'users': {view_2: None}, 'prev_node': 'arange_2', 'next_node': 'view_1', 'meta': {'val': FakeTensor(..., size=(30,)), 'tensor_meta': TensorMetadata(shape=torch.Size([30]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'view_1', 'op': 'call_function', 'op_name': 'view.default', 'target': <OpOverload(op='aten.view', overload='default')>, '_input_nodes': {arange_2: None}, 'args': (arange_2, [-1, 1]), 'kwargs': {}, 'users': {expand: None}, 'prev_node': 'arange_3', 'next_node': 'expand', 'meta': {'val': FakeTensor(..., size=(40, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([40, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'expand', 'op': 'call_function', 'op_name': 'expand.default', 'target': <OpOverload(op='aten.expand', overload='default')>, '_input_nodes': {view_1: None}, 'args': (view_1, [40, 30]), 'kwargs': {}, 'users': {stack: None}, 'prev_node': 'view_1', 'next_node': 'view_2', 'meta': {'val': FakeTensor(..., size=(40, 30)), 'tensor_meta': TensorMetadata(shape=torch.Size([40, 30]), dtype=torch.float32, requires_grad=False, stride=(1, 0), memory_format=None, is_quantized=False, qparams={})}}
{'name': 'view_2', 'op': 'call_function', 'op_name': 'view.default', 'target': <OpOverload(op='aten.view', overload='default')>, '_input_nodes': {arange_3: None}, 'args': (arange_3, [1, -1]), 'kwargs': {}, 'users': {expand_1: None}, 'prev_node': 'expand', 'next_node': 'expand_1', 'meta': {'val': FakeTensor(..., size=(1, 30)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 30]), dtype=torch.float32, requires_grad=False, stride=(30, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'expand_1', 'op': 'call_function', 'op_name': 'expand.default', 'target': <OpOverload(op='aten.expand', overload='default')>, '_input_nodes': {view_2: None}, 'args': (view_2, [40, 30]), 'kwargs': {}, 'users': {stack: None}, 'prev_node': 'view_2', 'next_node': 'stack', 'meta': {'val': FakeTensor(..., size=(40, 30)), 'tensor_meta': TensorMetadata(shape=torch.Size([40, 30]), dtype=torch.float32, requires_grad=False, stride=(0, 1), memory_format=None, is_quantized=False, qparams={})}}
{'name': 'stack', 'op': 'call_function', 'op_name': 'stack.default', 'target': <OpOverload(op='aten.stack', overload='default')>, '_input_nodes': {expand_1: None, expand: None}, 'args': ([expand_1, expand], 2), 'kwargs': {}, 'users': {expand_2: None}, 'prev_node': 'expand_1', 'next_node': 'expand_2', 'meta': {'val': FakeTensor(..., size=(40, 30, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([40, 30, 2]), dtype=torch.float32, requires_grad=False, stride=(60, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'expand_2', 'op': 'call_function', 'op_name': 'expand.default', 'target': <OpOverload(op='aten.expand', overload='default')>, '_input_nodes': {stack: None}, 'args': (stack, [1, 3, 40, 30, 2]), 'kwargs': {}, 'users': {sub: None}, 'prev_node': 'stack', 'next_node': 'sub', 'meta': {'val': FakeTensor(..., size=(1, 3, 40, 30, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 2]), dtype=torch.float32, requires_grad=False, stride=(2400, 0, 60, 2, 1), memory_format=None, is_quantized=False, qparams={})}}
{'name': 'sub', 'op': 'call_function', 'op_name': 'sub.Tensor', 'target': <OpOverload(op='aten.sub', overload='Tensor')>, '_input_nodes': {expand_2: None}, 'args': (expand_2, 0.5), 'kwargs': {}, 'users': {add: None, output: None}, 'prev_node': 'expand_2', 'next_node': 'select', 'meta': {'val': FakeTensor(..., size=(1, 3, 40, 30, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 2]), dtype=torch.float32, requires_grad=False, stride=(7200, 2400, 60, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'select', 'op': 'call_function', 'op_name': 'select.int', 'target': <OpOverload(op='aten.select', overload='int')>, '_input_nodes': {arg26_1: None}, 'args': (arg26_1, 0, 0), 'kwargs': {}, 'users': {mul_2: None}, 'prev_node': 'sub', 'next_node': 'select_1', 'meta': {'val': FakeTensor(..., size=(3, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([3, 2]), dtype=torch.float32, requires_grad=False, stride=(2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'select_1', 'op': 'call_function', 'op_name': 'select.int', 'target': <OpOverload(op='aten.select', overload='int')>, '_input_nodes': {arg27_1: None}, 'args': (arg27_1, 0, 0), 'kwargs': {}, 'users': {mul_2: None}, 'prev_node': 'select', 'next_node': 'mul_2', 'meta': {'val': FakeTensor(..., size=()), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.float32, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'mul_2', 'op': 'call_function', 'op_name': 'mul.Tensor', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {select: None, select_1: None}, 'args': (select, select_1), 'kwargs': {}, 'users': {view_3: None}, 'prev_node': 'select_1', 'next_node': 'view_3', 'meta': {'val': FakeTensor(..., size=(3, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([3, 2]), dtype=torch.float32, requires_grad=False, stride=(2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'view_3', 'op': 'call_function', 'op_name': 'view.default', 'target': <OpOverload(op='aten.view', overload='default')>, '_input_nodes': {mul_2: None}, 'args': (mul_2, [1, 3, 1, 1, 2]), 'kwargs': {}, 'users': {expand_3: None}, 'prev_node': 'mul_2', 'next_node': 'expand_3', 'meta': {'val': FakeTensor(..., size=(1, 3, 1, 1, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 1, 1, 2]), dtype=torch.float32, requires_grad=False, stride=(6, 2, 2, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'expand_3', 'op': 'call_function', 'op_name': 'expand.default', 'target': <OpOverload(op='aten.expand', overload='default')>, '_input_nodes': {view_3: None}, 'args': (view_3, [1, 3, 40, 30, 2]), 'kwargs': {}, 'users': {mul_6: None, output: None}, 'prev_node': 'view_3', 'next_node': 'sigmoid', 'meta': {'val': FakeTensor(..., size=(1, 3, 40, 30, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 2]), dtype=torch.float32, requires_grad=False, stride=(6, 2, 0, 0, 1), memory_format=None, is_quantized=False, qparams={})}}
{'name': 'sigmoid', 'op': 'call_function', 'op_name': 'sigmoid.default', 'target': <OpOverload(op='aten.sigmoid', overload='default')>, '_input_nodes': {clone: None}, 'args': (clone,), 'kwargs': {}, 'users': {split_with_sizes: None}, 'prev_node': 'expand_3', 'next_node': 'split_with_sizes', 'meta': {'val': FakeTensor(..., size=(1, 3, 40, 30, 85)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 85]), dtype=torch.float32, requires_grad=False, stride=(306000, 102000, 2550, 85, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'split_with_sizes', 'op': 'call_function', 'op_name': 'split_with_sizes.default', 'target': <OpOverload(op='aten.split_with_sizes', overload='default')>, '_input_nodes': {sigmoid: None}, 'args': (sigmoid, [2, 2, 81], 4), 'kwargs': {}, 'users': {getitem_12: None, getitem_13: None, getitem_14: None}, 'prev_node': 'sigmoid', 'next_node': 'getitem_12', 'meta': {'val': [FakeTensor(..., size=(1, 3, 40, 30, 2)), FakeTensor(..., size=(1, 3, 40, 30, 2)), FakeTensor(..., size=(1, 3, 40, 30, 81))], 'tensor_meta': None}}
{'name': 'getitem_12', 'op': 'call_function', 'op_name': 'getitem', 'target': <built-in function getitem>, '_input_nodes': {split_with_sizes: None}, 'args': (split_with_sizes, 0), 'kwargs': {}, 'users': {mul_3: None}, 'prev_node': 'split_with_sizes', 'next_node': 'getitem_13', 'meta': {'val': FakeTensor(..., size=(1, 3, 40, 30, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 2]), dtype=torch.float32, requires_grad=False, stride=(306000, 102000, 2550, 85, 1), memory_format=None, is_quantized=False, qparams={})}}
{'name': 'getitem_13', 'op': 'call_function', 'op_name': 'getitem', 'target': <built-in function getitem>, '_input_nodes': {split_with_sizes: None}, 'args': (split_with_sizes, 1), 'kwargs': {}, 'users': {mul_5: None}, 'prev_node': 'getitem_12', 'next_node': 'getitem_14', 'meta': {'val': FakeTensor(..., size=(1, 3, 40, 30, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 2]), dtype=torch.float32, requires_grad=False, stride=(306000, 102000, 2550, 85, 1), memory_format=None, is_quantized=False, qparams={})}}
{'name': 'getitem_14', 'op': 'call_function', 'op_name': 'getitem', 'target': <built-in function getitem>, '_input_nodes': {split_with_sizes: None}, 'args': (split_with_sizes, 2), 'kwargs': {}, 'users': {cat_1: None}, 'prev_node': 'getitem_13', 'next_node': 'mul_3', 'meta': {'val': FakeTensor(..., size=(1, 3, 40, 30, 81)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 81]), dtype=torch.float32, requires_grad=False, stride=(306000, 102000, 2550, 85, 1), memory_format=None, is_quantized=False, qparams={})}}
{'name': 'mul_3', 'op': 'call_function', 'op_name': 'mul.Tensor', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {getitem_12: None}, 'args': (getitem_12, 2), 'kwargs': {}, 'users': {add: None}, 'prev_node': 'getitem_14', 'next_node': 'add', 'meta': {'val': FakeTensor(..., size=(1, 3, 40, 30, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 2]), dtype=torch.float32, requires_grad=False, stride=(7200, 2400, 60, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'add', 'op': 'call_function', 'op_name': 'add.Tensor', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {mul_3: None, sub: None}, 'args': (mul_3, sub), 'kwargs': {}, 'users': {mul_4: None}, 'prev_node': 'mul_3', 'next_node': 'select_2', 'meta': {'val': FakeTensor(..., size=(1, 3, 40, 30, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 2]), dtype=torch.float32, requires_grad=False, stride=(7200, 2400, 60, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'select_2', 'op': 'call_function', 'op_name': 'select.int', 'target': <OpOverload(op='aten.select', overload='int')>, '_input_nodes': {arg27_1: None}, 'args': (arg27_1, 0, 0), 'kwargs': {}, 'users': {mul_4: None}, 'prev_node': 'add', 'next_node': 'mul_4', 'meta': {'val': FakeTensor(..., size=()), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.float32, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'mul_4', 'op': 'call_function', 'op_name': 'mul.Tensor', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {add: None, select_2: None}, 'args': (add, select_2), 'kwargs': {}, 'users': {cat_1: None}, 'prev_node': 'select_2', 'next_node': 'mul_5', 'meta': {'val': FakeTensor(..., size=(1, 3, 40, 30, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 2]), dtype=torch.float32, requires_grad=False, stride=(7200, 2400, 60, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'mul_5', 'op': 'call_function', 'op_name': 'mul.Tensor', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {getitem_13: None}, 'args': (getitem_13, 2), 'kwargs': {}, 'users': {pow_1: None}, 'prev_node': 'mul_4', 'next_node': 'pow_1', 'meta': {'val': FakeTensor(..., size=(1, 3, 40, 30, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 2]), dtype=torch.float32, requires_grad=False, stride=(7200, 2400, 60, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'pow_1', 'op': 'call_function', 'op_name': 'pow.Tensor_Scalar', 'target': <OpOverload(op='aten.pow', overload='Tensor_Scalar')>, '_input_nodes': {mul_5: None}, 'args': (mul_5, 2), 'kwargs': {}, 'users': {mul_6: None}, 'prev_node': 'mul_5', 'next_node': 'mul_6', 'meta': {'val': FakeTensor(..., size=(1, 3, 40, 30, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 2]), dtype=torch.float32, requires_grad=False, stride=(7200, 2400, 60, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'mul_6', 'op': 'call_function', 'op_name': 'mul.Tensor', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {pow_1: None, expand_3: None}, 'args': (pow_1, expand_3), 'kwargs': {}, 'users': {cat_1: None}, 'prev_node': 'pow_1', 'next_node': 'cat_1', 'meta': {'val': FakeTensor(..., size=(1, 3, 40, 30, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 2]), dtype=torch.float32, requires_grad=False, stride=(7200, 2400, 60, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'cat_1', 'op': 'call_function', 'op_name': 'cat.default', 'target': <OpOverload(op='aten.cat', overload='default')>, '_input_nodes': {mul_4: None, mul_6: None, getitem_14: None}, 'args': ([mul_4, mul_6, getitem_14], 4), 'kwargs': {}, 'users': {view_4: None}, 'prev_node': 'mul_6', 'next_node': 'view_4', 'meta': {'val': FakeTensor(..., size=(1, 3, 40, 30, 85)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 85]), dtype=torch.float32, requires_grad=False, stride=(306000, 102000, 2550, 85, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'view_4', 'op': 'call_function', 'op_name': 'view.default', 'target': <OpOverload(op='aten.view', overload='default')>, '_input_nodes': {cat_1: None}, 'args': (cat_1, [1, 3600, 85]), 'kwargs': {}, 'users': {cat_3: None}, 'prev_node': 'cat_1', 'next_node': 'convolution_12', 'meta': {'val': FakeTensor(..., size=(1, 3600, 85)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3600, 85]), dtype=torch.float32, requires_grad=False, stride=(306000, 85, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'convolution_12', 'op': 'call_function', 'op_name': 'convolution.default', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {silu_8: None, arg24_1: None, arg25_1: None}, 'args': (silu_8, arg24_1, arg25_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), 'kwargs': {}, 'users': {view_5: None}, 'prev_node': 'view_4', 'next_node': 'view_5', 'meta': {'val': FakeTensor(..., size=(1, 255, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 255, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(76500, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'view_5', 'op': 'call_function', 'op_name': 'view.default', 'target': <OpOverload(op='aten.view', overload='default')>, '_input_nodes': {convolution_12: None}, 'args': (convolution_12, [1, 3, 85, 20, 15]), 'kwargs': {}, 'users': {permute_1: None}, 'prev_node': 'convolution_12', 'next_node': 'permute_1', 'meta': {'val': FakeTensor(..., size=(1, 3, 85, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 85, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(76500, 25500, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'permute_1', 'op': 'call_function', 'op_name': 'permute.default', 'target': <OpOverload(op='aten.permute', overload='default')>, '_input_nodes': {view_5: None}, 'args': (view_5, [0, 1, 3, 4, 2]), 'kwargs': {}, 'users': {clone_1: None}, 'prev_node': 'view_5', 'next_node': 'clone_1', 'meta': {'val': FakeTensor(..., size=(1, 3, 20, 15, 85)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 85]), dtype=torch.float32, requires_grad=False, stride=(76500, 25500, 15, 1, 300), memory_format=None, is_quantized=False, qparams={})}}
{'name': 'clone_1', 'op': 'call_function', 'op_name': 'clone.default', 'target': <OpOverload(op='aten.clone', overload='default')>, '_input_nodes': {permute_1: None}, 'args': (permute_1,), 'kwargs': {'memory_format': torch.contiguous_format}, 'users': {sigmoid_1: None, output: None}, 'prev_node': 'permute_1', 'next_node': 'arange_4', 'meta': {'val': FakeTensor(..., size=(1, 3, 20, 15, 85)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 85]), dtype=torch.float32, requires_grad=False, stride=(76500, 25500, 1275, 85, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arange_4', 'op': 'call_function', 'op_name': 'arange.default', 'target': <OpOverload(op='aten.arange', overload='default')>, '_input_nodes': {}, 'args': (20,), 'kwargs': {'dtype': torch.float32, 'device': device(type='cpu'), 'pin_memory': False}, 'users': {view_6: None}, 'prev_node': 'clone_1', 'next_node': 'arange_5', 'meta': {'val': FakeTensor(..., size=(20,)), 'tensor_meta': TensorMetadata(shape=torch.Size([20]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'arange_5', 'op': 'call_function', 'op_name': 'arange.default', 'target': <OpOverload(op='aten.arange', overload='default')>, '_input_nodes': {}, 'args': (15,), 'kwargs': {'dtype': torch.float32, 'device': device(type='cpu'), 'pin_memory': False}, 'users': {view_7: None}, 'prev_node': 'arange_4', 'next_node': 'view_6', 'meta': {'val': FakeTensor(..., size=(15,)), 'tensor_meta': TensorMetadata(shape=torch.Size([15]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'view_6', 'op': 'call_function', 'op_name': 'view.default', 'target': <OpOverload(op='aten.view', overload='default')>, '_input_nodes': {arange_4: None}, 'args': (arange_4, [-1, 1]), 'kwargs': {}, 'users': {expand_4: None}, 'prev_node': 'arange_5', 'next_node': 'expand_4', 'meta': {'val': FakeTensor(..., size=(20, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([20, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'expand_4', 'op': 'call_function', 'op_name': 'expand.default', 'target': <OpOverload(op='aten.expand', overload='default')>, '_input_nodes': {view_6: None}, 'args': (view_6, [20, 15]), 'kwargs': {}, 'users': {stack_1: None}, 'prev_node': 'view_6', 'next_node': 'view_7', 'meta': {'val': FakeTensor(..., size=(20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([20, 15]), dtype=torch.float32, requires_grad=False, stride=(1, 0), memory_format=None, is_quantized=False, qparams={})}}
{'name': 'view_7', 'op': 'call_function', 'op_name': 'view.default', 'target': <OpOverload(op='aten.view', overload='default')>, '_input_nodes': {arange_5: None}, 'args': (arange_5, [1, -1]), 'kwargs': {}, 'users': {expand_5: None}, 'prev_node': 'expand_4', 'next_node': 'expand_5', 'meta': {'val': FakeTensor(..., size=(1, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 15]), dtype=torch.float32, requires_grad=False, stride=(15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'expand_5', 'op': 'call_function', 'op_name': 'expand.default', 'target': <OpOverload(op='aten.expand', overload='default')>, '_input_nodes': {view_7: None}, 'args': (view_7, [20, 15]), 'kwargs': {}, 'users': {stack_1: None}, 'prev_node': 'view_7', 'next_node': 'stack_1', 'meta': {'val': FakeTensor(..., size=(20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([20, 15]), dtype=torch.float32, requires_grad=False, stride=(0, 1), memory_format=None, is_quantized=False, qparams={})}}
{'name': 'stack_1', 'op': 'call_function', 'op_name': 'stack.default', 'target': <OpOverload(op='aten.stack', overload='default')>, '_input_nodes': {expand_5: None, expand_4: None}, 'args': ([expand_5, expand_4], 2), 'kwargs': {}, 'users': {expand_6: None}, 'prev_node': 'expand_5', 'next_node': 'expand_6', 'meta': {'val': FakeTensor(..., size=(20, 15, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([20, 15, 2]), dtype=torch.float32, requires_grad=False, stride=(30, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'expand_6', 'op': 'call_function', 'op_name': 'expand.default', 'target': <OpOverload(op='aten.expand', overload='default')>, '_input_nodes': {stack_1: None}, 'args': (stack_1, [1, 3, 20, 15, 2]), 'kwargs': {}, 'users': {sub_1: None}, 'prev_node': 'stack_1', 'next_node': 'sub_1', 'meta': {'val': FakeTensor(..., size=(1, 3, 20, 15, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 2]), dtype=torch.float32, requires_grad=False, stride=(600, 0, 30, 2, 1), memory_format=None, is_quantized=False, qparams={})}}
{'name': 'sub_1', 'op': 'call_function', 'op_name': 'sub.Tensor', 'target': <OpOverload(op='aten.sub', overload='Tensor')>, '_input_nodes': {expand_6: None}, 'args': (expand_6, 0.5), 'kwargs': {}, 'users': {add_1: None, output: None}, 'prev_node': 'expand_6', 'next_node': 'select_3', 'meta': {'val': FakeTensor(..., size=(1, 3, 20, 15, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 2]), dtype=torch.float32, requires_grad=False, stride=(1800, 600, 30, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'select_3', 'op': 'call_function', 'op_name': 'select.int', 'target': <OpOverload(op='aten.select', overload='int')>, '_input_nodes': {arg26_1: None}, 'args': (arg26_1, 0, 1), 'kwargs': {}, 'users': {mul_7: None}, 'prev_node': 'sub_1', 'next_node': 'select_4', 'meta': {'val': FakeTensor(..., size=(3, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([3, 2]), dtype=torch.float32, requires_grad=False, stride=(2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'select_4', 'op': 'call_function', 'op_name': 'select.int', 'target': <OpOverload(op='aten.select', overload='int')>, '_input_nodes': {arg27_1: None}, 'args': (arg27_1, 0, 1), 'kwargs': {}, 'users': {mul_7: None}, 'prev_node': 'select_3', 'next_node': 'mul_7', 'meta': {'val': FakeTensor(..., size=()), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.float32, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'mul_7', 'op': 'call_function', 'op_name': 'mul.Tensor', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {select_3: None, select_4: None}, 'args': (select_3, select_4), 'kwargs': {}, 'users': {view_8: None}, 'prev_node': 'select_4', 'next_node': 'view_8', 'meta': {'val': FakeTensor(..., size=(3, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([3, 2]), dtype=torch.float32, requires_grad=False, stride=(2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'view_8', 'op': 'call_function', 'op_name': 'view.default', 'target': <OpOverload(op='aten.view', overload='default')>, '_input_nodes': {mul_7: None}, 'args': (mul_7, [1, 3, 1, 1, 2]), 'kwargs': {}, 'users': {expand_7: None}, 'prev_node': 'mul_7', 'next_node': 'expand_7', 'meta': {'val': FakeTensor(..., size=(1, 3, 1, 1, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 1, 1, 2]), dtype=torch.float32, requires_grad=False, stride=(6, 2, 2, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'expand_7', 'op': 'call_function', 'op_name': 'expand.default', 'target': <OpOverload(op='aten.expand', overload='default')>, '_input_nodes': {view_8: None}, 'args': (view_8, [1, 3, 20, 15, 2]), 'kwargs': {}, 'users': {mul_11: None, output: None}, 'prev_node': 'view_8', 'next_node': 'sigmoid_1', 'meta': {'val': FakeTensor(..., size=(1, 3, 20, 15, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 2]), dtype=torch.float32, requires_grad=False, stride=(6, 2, 0, 0, 1), memory_format=None, is_quantized=False, qparams={})}}
{'name': 'sigmoid_1', 'op': 'call_function', 'op_name': 'sigmoid.default', 'target': <OpOverload(op='aten.sigmoid', overload='default')>, '_input_nodes': {clone_1: None}, 'args': (clone_1,), 'kwargs': {}, 'users': {split_with_sizes_1: None}, 'prev_node': 'expand_7', 'next_node': 'split_with_sizes_1', 'meta': {'val': FakeTensor(..., size=(1, 3, 20, 15, 85)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 85]), dtype=torch.float32, requires_grad=False, stride=(76500, 25500, 1275, 85, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'split_with_sizes_1', 'op': 'call_function', 'op_name': 'split_with_sizes.default', 'target': <OpOverload(op='aten.split_with_sizes', overload='default')>, '_input_nodes': {sigmoid_1: None}, 'args': (sigmoid_1, [2, 2, 81], 4), 'kwargs': {}, 'users': {getitem_15: None, getitem_16: None, getitem_17: None}, 'prev_node': 'sigmoid_1', 'next_node': 'getitem_15', 'meta': {'val': [FakeTensor(..., size=(1, 3, 20, 15, 2)), FakeTensor(..., size=(1, 3, 20, 15, 2)), FakeTensor(..., size=(1, 3, 20, 15, 81))], 'tensor_meta': None}}
{'name': 'getitem_15', 'op': 'call_function', 'op_name': 'getitem', 'target': <built-in function getitem>, '_input_nodes': {split_with_sizes_1: None}, 'args': (split_with_sizes_1, 0), 'kwargs': {}, 'users': {mul_8: None}, 'prev_node': 'split_with_sizes_1', 'next_node': 'getitem_16', 'meta': {'val': FakeTensor(..., size=(1, 3, 20, 15, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 2]), dtype=torch.float32, requires_grad=False, stride=(76500, 25500, 1275, 85, 1), memory_format=None, is_quantized=False, qparams={})}}
{'name': 'getitem_16', 'op': 'call_function', 'op_name': 'getitem', 'target': <built-in function getitem>, '_input_nodes': {split_with_sizes_1: None}, 'args': (split_with_sizes_1, 1), 'kwargs': {}, 'users': {mul_10: None}, 'prev_node': 'getitem_15', 'next_node': 'getitem_17', 'meta': {'val': FakeTensor(..., size=(1, 3, 20, 15, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 2]), dtype=torch.float32, requires_grad=False, stride=(76500, 25500, 1275, 85, 1), memory_format=None, is_quantized=False, qparams={})}}
{'name': 'getitem_17', 'op': 'call_function', 'op_name': 'getitem', 'target': <built-in function getitem>, '_input_nodes': {split_with_sizes_1: None}, 'args': (split_with_sizes_1, 2), 'kwargs': {}, 'users': {cat_2: None}, 'prev_node': 'getitem_16', 'next_node': 'mul_8', 'meta': {'val': FakeTensor(..., size=(1, 3, 20, 15, 81)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 81]), dtype=torch.float32, requires_grad=False, stride=(76500, 25500, 1275, 85, 1), memory_format=None, is_quantized=False, qparams={})}}
{'name': 'mul_8', 'op': 'call_function', 'op_name': 'mul.Tensor', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {getitem_15: None}, 'args': (getitem_15, 2), 'kwargs': {}, 'users': {add_1: None}, 'prev_node': 'getitem_17', 'next_node': 'add_1', 'meta': {'val': FakeTensor(..., size=(1, 3, 20, 15, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 2]), dtype=torch.float32, requires_grad=False, stride=(1800, 600, 30, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'add_1', 'op': 'call_function', 'op_name': 'add.Tensor', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {mul_8: None, sub_1: None}, 'args': (mul_8, sub_1), 'kwargs': {}, 'users': {mul_9: None}, 'prev_node': 'mul_8', 'next_node': 'select_5', 'meta': {'val': FakeTensor(..., size=(1, 3, 20, 15, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 2]), dtype=torch.float32, requires_grad=False, stride=(1800, 600, 30, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'select_5', 'op': 'call_function', 'op_name': 'select.int', 'target': <OpOverload(op='aten.select', overload='int')>, '_input_nodes': {arg27_1: None}, 'args': (arg27_1, 0, 1), 'kwargs': {}, 'users': {mul_9: None}, 'prev_node': 'add_1', 'next_node': 'mul_9', 'meta': {'val': FakeTensor(..., size=()), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.float32, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'mul_9', 'op': 'call_function', 'op_name': 'mul.Tensor', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {add_1: None, select_5: None}, 'args': (add_1, select_5), 'kwargs': {}, 'users': {cat_2: None}, 'prev_node': 'select_5', 'next_node': 'mul_10', 'meta': {'val': FakeTensor(..., size=(1, 3, 20, 15, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 2]), dtype=torch.float32, requires_grad=False, stride=(1800, 600, 30, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'mul_10', 'op': 'call_function', 'op_name': 'mul.Tensor', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {getitem_16: None}, 'args': (getitem_16, 2), 'kwargs': {}, 'users': {pow_2: None}, 'prev_node': 'mul_9', 'next_node': 'pow_2', 'meta': {'val': FakeTensor(..., size=(1, 3, 20, 15, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 2]), dtype=torch.float32, requires_grad=False, stride=(1800, 600, 30, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'pow_2', 'op': 'call_function', 'op_name': 'pow.Tensor_Scalar', 'target': <OpOverload(op='aten.pow', overload='Tensor_Scalar')>, '_input_nodes': {mul_10: None}, 'args': (mul_10, 2), 'kwargs': {}, 'users': {mul_11: None}, 'prev_node': 'mul_10', 'next_node': 'mul_11', 'meta': {'val': FakeTensor(..., size=(1, 3, 20, 15, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 2]), dtype=torch.float32, requires_grad=False, stride=(1800, 600, 30, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'mul_11', 'op': 'call_function', 'op_name': 'mul.Tensor', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {pow_2: None, expand_7: None}, 'args': (pow_2, expand_7), 'kwargs': {}, 'users': {cat_2: None}, 'prev_node': 'pow_2', 'next_node': 'cat_2', 'meta': {'val': FakeTensor(..., size=(1, 3, 20, 15, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 2]), dtype=torch.float32, requires_grad=False, stride=(1800, 600, 30, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'cat_2', 'op': 'call_function', 'op_name': 'cat.default', 'target': <OpOverload(op='aten.cat', overload='default')>, '_input_nodes': {mul_9: None, mul_11: None, getitem_17: None}, 'args': ([mul_9, mul_11, getitem_17], 4), 'kwargs': {}, 'users': {view_9: None}, 'prev_node': 'mul_11', 'next_node': 'view_9', 'meta': {'val': FakeTensor(..., size=(1, 3, 20, 15, 85)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 85]), dtype=torch.float32, requires_grad=False, stride=(76500, 25500, 1275, 85, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'view_9', 'op': 'call_function', 'op_name': 'view.default', 'target': <OpOverload(op='aten.view', overload='default')>, '_input_nodes': {cat_2: None}, 'args': (cat_2, [1, 900, 85]), 'kwargs': {}, 'users': {cat_3: None}, 'prev_node': 'cat_2', 'next_node': 'cat_3', 'meta': {'val': FakeTensor(..., size=(1, 900, 85)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 900, 85]), dtype=torch.float32, requires_grad=False, stride=(76500, 85, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'cat_3', 'op': 'call_function', 'op_name': 'cat.default', 'target': <OpOverload(op='aten.cat', overload='default')>, '_input_nodes': {view_4: None, view_9: None}, 'args': ([view_4, view_9], 1), 'kwargs': {}, 'users': {output: None}, 'prev_node': 'view_9', 'next_node': 'output', 'meta': {'val': FakeTensor(..., size=(1, 4500, 85)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 4500, 85]), dtype=torch.float32, requires_grad=False, stride=(382500, 85, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'name': 'output', 'op': 'output', 'op_name': None, 'target': 'output', '_input_nodes': {cat_3: None, clone: None, clone_1: None, sub: None, sub_1: None, expand_3: None, expand_7: None}, 'args': ((cat_3, clone, clone_1, sub, sub_1, expand_3, expand_7),), 'kwargs': {}, 'users': {}, 'prev_node': 'cat_3', 'next_node': '', 'meta': {'val': None, 'tensor_meta': None}}
--------------------------------
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg0_1', 'op': 'placeholder', 'target': 'arg0_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution: None}, 'type': None, '_prev': , '_next': arg1_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(16, 3, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([16, 3, 3, 3]), dtype=torch.float32, requires_grad=False, stride=(27, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg1_1', 'op': 'placeholder', 'target': 'arg1_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution: None}, 'type': None, '_prev': arg0_1, '_next': arg2_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(16,)), 'tensor_meta': TensorMetadata(shape=torch.Size([16]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg2_1', 'op': 'placeholder', 'target': 'arg2_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_1: None}, 'type': None, '_prev': arg1_1, '_next': arg3_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(32, 16, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([32, 16, 3, 3]), dtype=torch.float32, requires_grad=False, stride=(144, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg3_1', 'op': 'placeholder', 'target': 'arg3_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_1: None}, 'type': None, '_prev': arg2_1, '_next': arg4_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(32,)), 'tensor_meta': TensorMetadata(shape=torch.Size([32]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg4_1', 'op': 'placeholder', 'target': 'arg4_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_2: None}, 'type': None, '_prev': arg3_1, '_next': arg5_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64, 32, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 32, 3, 3]), dtype=torch.float32, requires_grad=False, stride=(288, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg5_1', 'op': 'placeholder', 'target': 'arg5_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_2: None}, 'type': None, '_prev': arg4_1, '_next': arg6_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg6_1', 'op': 'placeholder', 'target': 'arg6_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_3: None}, 'type': None, '_prev': arg5_1, '_next': arg7_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128, 64, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 64, 3, 3]), dtype=torch.float32, requires_grad=False, stride=(576, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg7_1', 'op': 'placeholder', 'target': 'arg7_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_3: None}, 'type': None, '_prev': arg6_1, '_next': arg8_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg8_1', 'op': 'placeholder', 'target': 'arg8_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_4: None}, 'type': None, '_prev': arg7_1, '_next': arg9_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256, 128, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 128, 3, 3]), dtype=torch.float32, requires_grad=False, stride=(1152, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg9_1', 'op': 'placeholder', 'target': 'arg9_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_4: None}, 'type': None, '_prev': arg8_1, '_next': arg10_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg10_1', 'op': 'placeholder', 'target': 'arg10_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_5: None}, 'type': None, '_prev': arg9_1, '_next': arg11_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512, 256, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 256, 3, 3]), dtype=torch.float32, requires_grad=False, stride=(2304, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg11_1', 'op': 'placeholder', 'target': 'arg11_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_5: None}, 'type': None, '_prev': arg10_1, '_next': arg12_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg12_1', 'op': 'placeholder', 'target': 'arg12_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_6: None}, 'type': None, '_prev': arg11_1, '_next': arg13_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(1024, 512, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([1024, 512, 3, 3]), dtype=torch.float32, requires_grad=False, stride=(4608, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg13_1', 'op': 'placeholder', 'target': 'arg13_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_6: None}, 'type': None, '_prev': arg12_1, '_next': arg14_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(1024,)), 'tensor_meta': TensorMetadata(shape=torch.Size([1024]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg14_1', 'op': 'placeholder', 'target': 'arg14_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_7: None}, 'type': None, '_prev': arg13_1, '_next': arg15_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256, 1024, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1024, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1024, 1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg15_1', 'op': 'placeholder', 'target': 'arg15_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_7: None}, 'type': None, '_prev': arg14_1, '_next': arg16_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg16_1', 'op': 'placeholder', 'target': 'arg16_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_8: None}, 'type': None, '_prev': arg15_1, '_next': arg17_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512, 256, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 256, 3, 3]), dtype=torch.float32, requires_grad=False, stride=(2304, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg17_1', 'op': 'placeholder', 'target': 'arg17_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_8: None}, 'type': None, '_prev': arg16_1, '_next': arg18_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg18_1', 'op': 'placeholder', 'target': 'arg18_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_9: None}, 'type': None, '_prev': arg17_1, '_next': arg19_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128, 256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 256, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(256, 1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg19_1', 'op': 'placeholder', 'target': 'arg19_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_9: None}, 'type': None, '_prev': arg18_1, '_next': arg20_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg20_1', 'op': 'placeholder', 'target': 'arg20_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_10: None}, 'type': None, '_prev': arg19_1, '_next': arg21_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256, 384, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 384, 3, 3]), dtype=torch.float32, requires_grad=False, stride=(3456, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg21_1', 'op': 'placeholder', 'target': 'arg21_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_10: None}, 'type': None, '_prev': arg20_1, '_next': arg22_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg22_1', 'op': 'placeholder', 'target': 'arg22_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_11: None}, 'type': None, '_prev': arg21_1, '_next': arg23_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(255, 256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([255, 256, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(256, 1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg23_1', 'op': 'placeholder', 'target': 'arg23_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_11: None}, 'type': None, '_prev': arg22_1, '_next': arg24_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(255,)), 'tensor_meta': TensorMetadata(shape=torch.Size([255]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg24_1', 'op': 'placeholder', 'target': 'arg24_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_12: None}, 'type': None, '_prev': arg23_1, '_next': arg25_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(255, 512, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([255, 512, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(512, 1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg25_1', 'op': 'placeholder', 'target': 'arg25_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_12: None}, 'type': None, '_prev': arg24_1, '_next': arg26_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(255,)), 'tensor_meta': TensorMetadata(shape=torch.Size([255]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg26_1', 'op': 'placeholder', 'target': 'arg26_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {select: None, select_3: None}, 'type': None, '_prev': arg25_1, '_next': arg27_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(2, 3, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([2, 3, 2]), dtype=torch.float32, requires_grad=False, stride=(6, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg27_1', 'op': 'placeholder', 'target': 'arg27_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {select_1: None, select_2: None, select_4: None, select_5: None}, 'type': None, '_prev': arg26_1, '_next': arg28_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(2,)), 'tensor_meta': TensorMetadata(shape=torch.Size([2]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arg28_1', 'op': 'placeholder', 'target': 'arg28_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution: None}, 'type': None, '_prev': arg27_1, '_next': convolution, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(1, 3, 640, 480)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 640, 480]), dtype=torch.float32, requires_grad=False, stride=(921600, 307200, 480, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'convolution', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {arg28_1: None, arg0_1: None, arg1_1: None}, '_args': (arg28_1, arg0_1, arg1_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {silu: None}, 'type': None, '_prev': arg28_1, '_next': silu, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/common.py", line 59, in forward_fuse\n    return self.act(self.conv(x))\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_0_conv': ("L['self'].model.model[0].conv", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('l__self___model_model_0_conv', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('l__self___model_model_0_conv', 'L__self___model_model_0_conv')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 16, 640, 480)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 16, 640, 480]), dtype=torch.float32, requires_grad=False, stride=(4915200, 307200, 480, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'silu', 'op': 'call_function', 'target': <OpOverload(op='aten.silu', overload='default')>, '_input_nodes': {convolution: None}, '_args': (convolution,), '_kwargs': {}, 'users': {max_pool2d_with_indices: None}, 'type': None, '_prev': convolution, '_next': max_pool2d_with_indices, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/common.py", line 59, in forward_fuse\n    return self.act(self.conv(x))\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_0_act': ("L['self'].model.model[0].act", <class 'torch.nn.modules.activation.SiLU'>)}, 'source_fn': ('l__self___model_model_0_act', <class 'torch.nn.modules.activation.SiLU'>), 'original_aten': <OpOverload(op='aten.silu', overload='default')>, 'from_node': [('l__self___model_model_0_act', 'L__self___model_model_0_act')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 16, 640, 480)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 16, 640, 480]), dtype=torch.float32, requires_grad=False, stride=(4915200, 307200, 480, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'max_pool2d_with_indices', 'op': 'call_function', 'target': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, '_input_nodes': {silu: None}, '_args': (silu, [2, 2], [2, 2]), '_kwargs': {}, 'users': {getitem: None}, 'type': None, '_prev': silu, '_next': getitem, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_1': ("L['self'].model.model[1]", <class 'torch.nn.modules.pooling.MaxPool2d'>)}, 'source_fn': ('l__self___model_model_1', <class 'torch.nn.modules.pooling.MaxPool2d'>), 'original_aten': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, 'from_node': [('l__self___model_model_1', 'L__self___model_model_1')], 'seq_nr': -1, 'val': (FakeTensor(..., size=(1, 16, 320, 240)), FakeTensor(..., size=(1, 16, 320, 240), dtype=torch.int64)), 'tensor_meta': None}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'getitem', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {max_pool2d_with_indices: None}, '_args': (max_pool2d_with_indices, 0), '_kwargs': {}, 'users': {convolution_1: None}, 'type': None, '_prev': max_pool2d_with_indices, '_next': convolution_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_1': ("L['self'].model.model[1]", <class 'torch.nn.modules.pooling.MaxPool2d'>)}, 'source_fn': ('l__self___model_model_1', <class 'torch.nn.modules.pooling.MaxPool2d'>), 'original_aten': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, 'from_node': [('l__self___model_model_1', 'L__self___model_model_1')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 16, 320, 240)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 16, 320, 240]), dtype=torch.float32, requires_grad=False, stride=(1228800, 76800, 240, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'convolution_1', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {getitem: None, arg2_1: None, arg3_1: None}, '_args': (getitem, arg2_1, arg3_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {silu_1: None}, 'type': None, '_prev': getitem, '_next': silu_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/common.py", line 59, in forward_fuse\n    return self.act(self.conv(x))\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_2_conv': ("L['self'].model.model[2].conv", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('l__self___model_model_2_conv', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('l__self___model_model_2_conv', 'L__self___model_model_2_conv')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 32, 320, 240)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 32, 320, 240]), dtype=torch.float32, requires_grad=False, stride=(2457600, 76800, 240, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'silu_1', 'op': 'call_function', 'target': <OpOverload(op='aten.silu', overload='default')>, '_input_nodes': {convolution_1: None}, '_args': (convolution_1,), '_kwargs': {}, 'users': {max_pool2d_with_indices_1: None}, 'type': None, '_prev': convolution_1, '_next': max_pool2d_with_indices_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/common.py", line 59, in forward_fuse\n    return self.act(self.conv(x))\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_2_act': ("L['self'].model.model[2].act", <class 'torch.nn.modules.activation.SiLU'>)}, 'source_fn': ('l__self___model_model_2_act', <class 'torch.nn.modules.activation.SiLU'>), 'original_aten': <OpOverload(op='aten.silu', overload='default')>, 'from_node': [('l__self___model_model_2_act', 'L__self___model_model_2_act')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 32, 320, 240)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 32, 320, 240]), dtype=torch.float32, requires_grad=False, stride=(2457600, 76800, 240, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'max_pool2d_with_indices_1', 'op': 'call_function', 'target': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, '_input_nodes': {silu_1: None}, '_args': (silu_1, [2, 2], [2, 2]), '_kwargs': {}, 'users': {getitem_2: None}, 'type': None, '_prev': silu_1, '_next': getitem_2, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_3': ("L['self'].model.model[3]", <class 'torch.nn.modules.pooling.MaxPool2d'>)}, 'source_fn': ('l__self___model_model_3', <class 'torch.nn.modules.pooling.MaxPool2d'>), 'original_aten': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, 'from_node': [('l__self___model_model_3', 'L__self___model_model_3')], 'seq_nr': -1, 'val': (FakeTensor(..., size=(1, 32, 160, 120)), FakeTensor(..., size=(1, 32, 160, 120), dtype=torch.int64)), 'tensor_meta': None}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'getitem_2', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {max_pool2d_with_indices_1: None}, '_args': (max_pool2d_with_indices_1, 0), '_kwargs': {}, 'users': {convolution_2: None}, 'type': None, '_prev': max_pool2d_with_indices_1, '_next': convolution_2, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_3': ("L['self'].model.model[3]", <class 'torch.nn.modules.pooling.MaxPool2d'>)}, 'source_fn': ('l__self___model_model_3', <class 'torch.nn.modules.pooling.MaxPool2d'>), 'original_aten': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, 'from_node': [('l__self___model_model_3', 'L__self___model_model_3')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 32, 160, 120)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 32, 160, 120]), dtype=torch.float32, requires_grad=False, stride=(614400, 19200, 120, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'convolution_2', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {getitem_2: None, arg4_1: None, arg5_1: None}, '_args': (getitem_2, arg4_1, arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {silu_2: None}, 'type': None, '_prev': getitem_2, '_next': silu_2, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/common.py", line 59, in forward_fuse\n    return self.act(self.conv(x))\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_4_conv': ("L['self'].model.model[4].conv", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('l__self___model_model_4_conv', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('l__self___model_model_4_conv', 'L__self___model_model_4_conv')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 64, 160, 120)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 160, 120]), dtype=torch.float32, requires_grad=False, stride=(1228800, 19200, 120, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'silu_2', 'op': 'call_function', 'target': <OpOverload(op='aten.silu', overload='default')>, '_input_nodes': {convolution_2: None}, '_args': (convolution_2,), '_kwargs': {}, 'users': {max_pool2d_with_indices_2: None}, 'type': None, '_prev': convolution_2, '_next': max_pool2d_with_indices_2, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/common.py", line 59, in forward_fuse\n    return self.act(self.conv(x))\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_4_act': ("L['self'].model.model[4].act", <class 'torch.nn.modules.activation.SiLU'>)}, 'source_fn': ('l__self___model_model_4_act', <class 'torch.nn.modules.activation.SiLU'>), 'original_aten': <OpOverload(op='aten.silu', overload='default')>, 'from_node': [('l__self___model_model_4_act', 'L__self___model_model_4_act')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 64, 160, 120)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 160, 120]), dtype=torch.float32, requires_grad=False, stride=(1228800, 19200, 120, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'max_pool2d_with_indices_2', 'op': 'call_function', 'target': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, '_input_nodes': {silu_2: None}, '_args': (silu_2, [2, 2], [2, 2]), '_kwargs': {}, 'users': {getitem_4: None}, 'type': None, '_prev': silu_2, '_next': getitem_4, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_5': ("L['self'].model.model[5]", <class 'torch.nn.modules.pooling.MaxPool2d'>)}, 'source_fn': ('l__self___model_model_5', <class 'torch.nn.modules.pooling.MaxPool2d'>), 'original_aten': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, 'from_node': [('l__self___model_model_5', 'L__self___model_model_5')], 'seq_nr': -1, 'val': (FakeTensor(..., size=(1, 64, 80, 60)), FakeTensor(..., size=(1, 64, 80, 60), dtype=torch.int64)), 'tensor_meta': None}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'getitem_4', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {max_pool2d_with_indices_2: None}, '_args': (max_pool2d_with_indices_2, 0), '_kwargs': {}, 'users': {convolution_3: None}, 'type': None, '_prev': max_pool2d_with_indices_2, '_next': convolution_3, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_5': ("L['self'].model.model[5]", <class 'torch.nn.modules.pooling.MaxPool2d'>)}, 'source_fn': ('l__self___model_model_5', <class 'torch.nn.modules.pooling.MaxPool2d'>), 'original_aten': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, 'from_node': [('l__self___model_model_5', 'L__self___model_model_5')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 64, 80, 60)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 80, 60]), dtype=torch.float32, requires_grad=False, stride=(307200, 4800, 60, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'convolution_3', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {getitem_4: None, arg6_1: None, arg7_1: None}, '_args': (getitem_4, arg6_1, arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {silu_3: None}, 'type': None, '_prev': getitem_4, '_next': silu_3, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/common.py", line 59, in forward_fuse\n    return self.act(self.conv(x))\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_6_conv': ("L['self'].model.model[6].conv", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('l__self___model_model_6_conv', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('l__self___model_model_6_conv', 'L__self___model_model_6_conv')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 128, 80, 60)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 80, 60]), dtype=torch.float32, requires_grad=False, stride=(614400, 4800, 60, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'silu_3', 'op': 'call_function', 'target': <OpOverload(op='aten.silu', overload='default')>, '_input_nodes': {convolution_3: None}, '_args': (convolution_3,), '_kwargs': {}, 'users': {max_pool2d_with_indices_3: None}, 'type': None, '_prev': convolution_3, '_next': max_pool2d_with_indices_3, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/common.py", line 59, in forward_fuse\n    return self.act(self.conv(x))\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_6_act': ("L['self'].model.model[6].act", <class 'torch.nn.modules.activation.SiLU'>)}, 'source_fn': ('l__self___model_model_6_act', <class 'torch.nn.modules.activation.SiLU'>), 'original_aten': <OpOverload(op='aten.silu', overload='default')>, 'from_node': [('l__self___model_model_6_act', 'L__self___model_model_6_act')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 128, 80, 60)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 80, 60]), dtype=torch.float32, requires_grad=False, stride=(614400, 4800, 60, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'max_pool2d_with_indices_3', 'op': 'call_function', 'target': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, '_input_nodes': {silu_3: None}, '_args': (silu_3, [2, 2], [2, 2]), '_kwargs': {}, 'users': {getitem_6: None}, 'type': None, '_prev': silu_3, '_next': getitem_6, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_7': ("L['self'].model.model[7]", <class 'torch.nn.modules.pooling.MaxPool2d'>)}, 'source_fn': ('l__self___model_model_7', <class 'torch.nn.modules.pooling.MaxPool2d'>), 'original_aten': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, 'from_node': [('l__self___model_model_7', 'L__self___model_model_7')], 'seq_nr': -1, 'val': (FakeTensor(..., size=(1, 128, 40, 30)), FakeTensor(..., size=(1, 128, 40, 30), dtype=torch.int64)), 'tensor_meta': None}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'getitem_6', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {max_pool2d_with_indices_3: None}, '_args': (max_pool2d_with_indices_3, 0), '_kwargs': {}, 'users': {convolution_4: None}, 'type': None, '_prev': max_pool2d_with_indices_3, '_next': convolution_4, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_7': ("L['self'].model.model[7]", <class 'torch.nn.modules.pooling.MaxPool2d'>)}, 'source_fn': ('l__self___model_model_7', <class 'torch.nn.modules.pooling.MaxPool2d'>), 'original_aten': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, 'from_node': [('l__self___model_model_7', 'L__self___model_model_7')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 128, 40, 30)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 40, 30]), dtype=torch.float32, requires_grad=False, stride=(153600, 1200, 30, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'convolution_4', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {getitem_6: None, arg8_1: None, arg9_1: None}, '_args': (getitem_6, arg8_1, arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {silu_4: None}, 'type': None, '_prev': getitem_6, '_next': silu_4, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/common.py", line 59, in forward_fuse\n    return self.act(self.conv(x))\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_8_conv': ("L['self'].model.model[8].conv", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('l__self___model_model_8_conv', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('l__self___model_model_8_conv', 'L__self___model_model_8_conv')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 256, 40, 30)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 40, 30]), dtype=torch.float32, requires_grad=False, stride=(307200, 1200, 30, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'silu_4', 'op': 'call_function', 'target': <OpOverload(op='aten.silu', overload='default')>, '_input_nodes': {convolution_4: None}, '_args': (convolution_4,), '_kwargs': {}, 'users': {max_pool2d_with_indices_4: None, cat: None}, 'type': None, '_prev': convolution_4, '_next': max_pool2d_with_indices_4, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/common.py", line 59, in forward_fuse\n    return self.act(self.conv(x))\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_8_act': ("L['self'].model.model[8].act", <class 'torch.nn.modules.activation.SiLU'>)}, 'source_fn': ('l__self___model_model_8_act', <class 'torch.nn.modules.activation.SiLU'>), 'original_aten': <OpOverload(op='aten.silu', overload='default')>, 'from_node': [('l__self___model_model_8_act', 'L__self___model_model_8_act')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 256, 40, 30)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 40, 30]), dtype=torch.float32, requires_grad=False, stride=(307200, 1200, 30, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'max_pool2d_with_indices_4', 'op': 'call_function', 'target': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, '_input_nodes': {silu_4: None}, '_args': (silu_4, [2, 2], [2, 2]), '_kwargs': {}, 'users': {getitem_8: None}, 'type': None, '_prev': silu_4, '_next': getitem_8, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_9': ("L['self'].model.model[9]", <class 'torch.nn.modules.pooling.MaxPool2d'>)}, 'source_fn': ('l__self___model_model_9', <class 'torch.nn.modules.pooling.MaxPool2d'>), 'original_aten': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, 'from_node': [('l__self___model_model_9', 'L__self___model_model_9')], 'seq_nr': -1, 'val': (FakeTensor(..., size=(1, 256, 20, 15)), FakeTensor(..., size=(1, 256, 20, 15), dtype=torch.int64)), 'tensor_meta': None}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'getitem_8', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {max_pool2d_with_indices_4: None}, '_args': (max_pool2d_with_indices_4, 0), '_kwargs': {}, 'users': {convolution_5: None}, 'type': None, '_prev': max_pool2d_with_indices_4, '_next': convolution_5, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_9': ("L['self'].model.model[9]", <class 'torch.nn.modules.pooling.MaxPool2d'>)}, 'source_fn': ('l__self___model_model_9', <class 'torch.nn.modules.pooling.MaxPool2d'>), 'original_aten': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, 'from_node': [('l__self___model_model_9', 'L__self___model_model_9')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 256, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(76800, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'convolution_5', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {getitem_8: None, arg10_1: None, arg11_1: None}, '_args': (getitem_8, arg10_1, arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {silu_5: None}, 'type': None, '_prev': getitem_8, '_next': silu_5, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/common.py", line 59, in forward_fuse\n    return self.act(self.conv(x))\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_10_conv': ("L['self'].model.model[10].conv", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('l__self___model_model_10_conv', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('l__self___model_model_10_conv', 'L__self___model_model_10_conv')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 512, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(153600, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'silu_5', 'op': 'call_function', 'target': <OpOverload(op='aten.silu', overload='default')>, '_input_nodes': {convolution_5: None}, '_args': (convolution_5,), '_kwargs': {}, 'users': {constant_pad_nd: None}, 'type': None, '_prev': convolution_5, '_next': constant_pad_nd, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/common.py", line 59, in forward_fuse\n    return self.act(self.conv(x))\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_10_act': ("L['self'].model.model[10].act", <class 'torch.nn.modules.activation.SiLU'>)}, 'source_fn': ('l__self___model_model_10_act', <class 'torch.nn.modules.activation.SiLU'>), 'original_aten': <OpOverload(op='aten.silu', overload='default')>, 'from_node': [('l__self___model_model_10_act', 'L__self___model_model_10_act')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 512, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(153600, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'constant_pad_nd', 'op': 'call_function', 'target': <OpOverload(op='aten.constant_pad_nd', overload='default')>, '_input_nodes': {silu_5: None}, '_args': (silu_5, [0, 1, 0, 1], 0.0), '_kwargs': {}, 'users': {max_pool2d_with_indices_5: None}, 'type': None, '_prev': silu_5, '_next': max_pool2d_with_indices_5, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_11': ("L['self'].model.model[11]", <class 'torch.nn.modules.padding.ZeroPad2d'>)}, 'source_fn': ('l__self___model_model_11', <class 'torch.nn.modules.padding.ZeroPad2d'>), 'original_aten': <OpOverload(op='aten.constant_pad_nd', overload='default')>, 'from_node': [('l__self___model_model_11', 'L__self___model_model_11')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 512, 21, 16)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 21, 16]), dtype=torch.float32, requires_grad=False, stride=(172032, 336, 16, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'max_pool2d_with_indices_5', 'op': 'call_function', 'target': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, '_input_nodes': {constant_pad_nd: None}, '_args': (constant_pad_nd, [2, 2], [1, 1]), '_kwargs': {}, 'users': {getitem_10: None}, 'type': None, '_prev': constant_pad_nd, '_next': getitem_10, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_12': ("L['self'].model.model[12]", <class 'torch.nn.modules.pooling.MaxPool2d'>)}, 'source_fn': ('l__self___model_model_12', <class 'torch.nn.modules.pooling.MaxPool2d'>), 'original_aten': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, 'from_node': [('l__self___model_model_12', 'L__self___model_model_12')], 'seq_nr': -1, 'val': (FakeTensor(..., size=(1, 512, 20, 15)), FakeTensor(..., size=(1, 512, 20, 15), dtype=torch.int64)), 'tensor_meta': None}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'getitem_10', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {max_pool2d_with_indices_5: None}, '_args': (max_pool2d_with_indices_5, 0), '_kwargs': {}, 'users': {convolution_6: None}, 'type': None, '_prev': max_pool2d_with_indices_5, '_next': convolution_6, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_12': ("L['self'].model.model[12]", <class 'torch.nn.modules.pooling.MaxPool2d'>)}, 'source_fn': ('l__self___model_model_12', <class 'torch.nn.modules.pooling.MaxPool2d'>), 'original_aten': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, 'from_node': [('l__self___model_model_12', 'L__self___model_model_12')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 512, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(153600, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'convolution_6', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {getitem_10: None, arg12_1: None, arg13_1: None}, '_args': (getitem_10, arg12_1, arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {silu_6: None}, 'type': None, '_prev': getitem_10, '_next': silu_6, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/common.py", line 59, in forward_fuse\n    return self.act(self.conv(x))\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_13_conv': ("L['self'].model.model[13].conv", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('l__self___model_model_13_conv', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('l__self___model_model_13_conv', 'L__self___model_model_13_conv')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 1024, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 1024, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(307200, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'silu_6', 'op': 'call_function', 'target': <OpOverload(op='aten.silu', overload='default')>, '_input_nodes': {convolution_6: None}, '_args': (convolution_6,), '_kwargs': {}, 'users': {convolution_7: None}, 'type': None, '_prev': convolution_6, '_next': convolution_7, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/common.py", line 59, in forward_fuse\n    return self.act(self.conv(x))\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_13_act': ("L['self'].model.model[13].act", <class 'torch.nn.modules.activation.SiLU'>)}, 'source_fn': ('l__self___model_model_13_act', <class 'torch.nn.modules.activation.SiLU'>), 'original_aten': <OpOverload(op='aten.silu', overload='default')>, 'from_node': [('l__self___model_model_13_act', 'L__self___model_model_13_act')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 1024, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 1024, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(307200, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'convolution_7', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {silu_6: None, arg14_1: None, arg15_1: None}, '_args': (silu_6, arg14_1, arg15_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {silu_7: None}, 'type': None, '_prev': silu_6, '_next': silu_7, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/common.py", line 59, in forward_fuse\n    return self.act(self.conv(x))\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_14_conv': ("L['self'].model.model[14].conv", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('l__self___model_model_14_conv', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('l__self___model_model_14_conv', 'L__self___model_model_14_conv')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 256, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(76800, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'silu_7', 'op': 'call_function', 'target': <OpOverload(op='aten.silu', overload='default')>, '_input_nodes': {convolution_7: None}, '_args': (convolution_7,), '_kwargs': {}, 'users': {convolution_8: None, convolution_9: None}, 'type': None, '_prev': convolution_7, '_next': convolution_8, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/common.py", line 59, in forward_fuse\n    return self.act(self.conv(x))\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_14_act': ("L['self'].model.model[14].act", <class 'torch.nn.modules.activation.SiLU'>)}, 'source_fn': ('l__self___model_model_14_act', <class 'torch.nn.modules.activation.SiLU'>), 'original_aten': <OpOverload(op='aten.silu', overload='default')>, 'from_node': [('l__self___model_model_14_act', 'L__self___model_model_14_act')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 256, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(76800, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'convolution_8', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {silu_7: None, arg16_1: None, arg17_1: None}, '_args': (silu_7, arg16_1, arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {silu_8: None}, 'type': None, '_prev': silu_7, '_next': silu_8, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/common.py", line 59, in forward_fuse\n    return self.act(self.conv(x))\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_15_conv': ("L['self'].model.model[15].conv", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('l__self___model_model_15_conv', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('l__self___model_model_15_conv', 'L__self___model_model_15_conv')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 512, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(153600, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'silu_8', 'op': 'call_function', 'target': <OpOverload(op='aten.silu', overload='default')>, '_input_nodes': {convolution_8: None}, '_args': (convolution_8,), '_kwargs': {}, 'users': {convolution_12: None}, 'type': None, '_prev': convolution_8, '_next': convolution_9, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/common.py", line 59, in forward_fuse\n    return self.act(self.conv(x))\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_15_act': ("L['self'].model.model[15].act", <class 'torch.nn.modules.activation.SiLU'>)}, 'source_fn': ('l__self___model_model_15_act', <class 'torch.nn.modules.activation.SiLU'>), 'original_aten': <OpOverload(op='aten.silu', overload='default')>, 'from_node': [('l__self___model_model_15_act', 'L__self___model_model_15_act')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 512, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(153600, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'convolution_9', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {silu_7: None, arg18_1: None, arg19_1: None}, '_args': (silu_7, arg18_1, arg19_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {silu_9: None}, 'type': None, '_prev': silu_8, '_next': silu_9, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/common.py", line 59, in forward_fuse\n    return self.act(self.conv(x))\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_16_conv': ("L['self'].model.model[16].conv", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('l__self___model_model_16_conv', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('l__self___model_model_16_conv', 'L__self___model_model_16_conv')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 128, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(38400, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'silu_9', 'op': 'call_function', 'target': <OpOverload(op='aten.silu', overload='default')>, '_input_nodes': {convolution_9: None}, '_args': (convolution_9,), '_kwargs': {}, 'users': {_unsafe_index: None}, 'type': None, '_prev': convolution_9, '_next': arange, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/common.py", line 59, in forward_fuse\n    return self.act(self.conv(x))\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_16_act': ("L['self'].model.model[16].act", <class 'torch.nn.modules.activation.SiLU'>)}, 'source_fn': ('l__self___model_model_16_act', <class 'torch.nn.modules.activation.SiLU'>), 'original_aten': <OpOverload(op='aten.silu', overload='default')>, 'from_node': [('l__self___model_model_16_act', 'L__self___model_model_16_act')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 128, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(38400, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arange', 'op': 'call_function', 'target': <OpOverload(op='aten.arange', overload='default')>, '_input_nodes': {}, '_args': (40,), '_kwargs': {'dtype': torch.float32, 'device': device(type='cpu'), 'pin_memory': False}, 'users': {mul: None}, 'type': None, '_prev': silu_9, '_next': mul, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_17': ("L['self'].model.model[17]", <class 'torch.nn.modules.upsampling.Upsample'>)}, 'source_fn': ('l__self___model_model_17', <class 'torch.nn.modules.upsampling.Upsample'>), 'original_aten': <OpOverload(op='aten.arange', overload='default')>, 'from_node': [('l__self___model_model_17', 'L__self___model_model_17')], 'seq_nr': -1, 'val': FakeTensor(..., size=(40,)), 'tensor_meta': TensorMetadata(shape=torch.Size([40]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'mul', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {arange: None}, '_args': (arange, 0.5), '_kwargs': {}, 'users': {_to_copy: None}, 'type': None, '_prev': arange, '_next': _to_copy, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_17': ("L['self'].model.model[17]", <class 'torch.nn.modules.upsampling.Upsample'>)}, 'source_fn': ('l__self___model_model_17', <class 'torch.nn.modules.upsampling.Upsample'>), 'original_aten': <OpOverload(op='aten.mul', overload='Tensor')>, 'from_node': [('l__self___model_model_17', 'L__self___model_model_17')], 'seq_nr': -1, 'val': FakeTensor(..., size=(40,)), 'tensor_meta': TensorMetadata(shape=torch.Size([40]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': '_to_copy', 'op': 'call_function', 'target': <OpOverload(op='aten._to_copy', overload='default')>, '_input_nodes': {mul: None}, '_args': (mul,), '_kwargs': {'dtype': torch.int64}, 'users': {unsqueeze: None}, 'type': None, '_prev': mul, '_next': unsqueeze, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_17': ("L['self'].model.model[17]", <class 'torch.nn.modules.upsampling.Upsample'>)}, 'source_fn': ('l__self___model_model_17', <class 'torch.nn.modules.upsampling.Upsample'>), 'original_aten': <OpOverload(op='aten._to_copy', overload='default')>, 'from_node': [('l__self___model_model_17', 'L__self___model_model_17')], 'seq_nr': -1, 'val': FakeTensor(..., size=(40,), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([40]), dtype=torch.int64, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'unsqueeze', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {_to_copy: None}, '_args': (_to_copy, -1), '_kwargs': {}, 'users': {_unsafe_index: None}, 'type': None, '_prev': _to_copy, '_next': arange_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_17': ("L['self'].model.model[17]", <class 'torch.nn.modules.upsampling.Upsample'>)}, 'source_fn': ('l__self___model_model_17', <class 'torch.nn.modules.upsampling.Upsample'>), 'original_aten': <OpOverload(op='aten.unsqueeze', overload='default')>, 'from_node': [('l__self___model_model_17', 'L__self___model_model_17')], 'seq_nr': -1, 'val': FakeTensor(..., size=(40, 1), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([40, 1]), dtype=torch.int64, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arange_1', 'op': 'call_function', 'target': <OpOverload(op='aten.arange', overload='default')>, '_input_nodes': {}, '_args': (30,), '_kwargs': {'dtype': torch.float32, 'device': device(type='cpu'), 'pin_memory': False}, 'users': {mul_1: None}, 'type': None, '_prev': unsqueeze, '_next': mul_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_17': ("L['self'].model.model[17]", <class 'torch.nn.modules.upsampling.Upsample'>)}, 'source_fn': ('l__self___model_model_17', <class 'torch.nn.modules.upsampling.Upsample'>), 'original_aten': <OpOverload(op='aten.arange', overload='default')>, 'from_node': [('l__self___model_model_17', 'L__self___model_model_17')], 'seq_nr': -1, 'val': FakeTensor(..., size=(30,)), 'tensor_meta': TensorMetadata(shape=torch.Size([30]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'mul_1', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {arange_1: None}, '_args': (arange_1, 0.5), '_kwargs': {}, 'users': {_to_copy_1: None}, 'type': None, '_prev': arange_1, '_next': _to_copy_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_17': ("L['self'].model.model[17]", <class 'torch.nn.modules.upsampling.Upsample'>)}, 'source_fn': ('l__self___model_model_17', <class 'torch.nn.modules.upsampling.Upsample'>), 'original_aten': <OpOverload(op='aten.mul', overload='Tensor')>, 'from_node': [('l__self___model_model_17', 'L__self___model_model_17')], 'seq_nr': -1, 'val': FakeTensor(..., size=(30,)), 'tensor_meta': TensorMetadata(shape=torch.Size([30]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': '_to_copy_1', 'op': 'call_function', 'target': <OpOverload(op='aten._to_copy', overload='default')>, '_input_nodes': {mul_1: None}, '_args': (mul_1,), '_kwargs': {'dtype': torch.int64}, 'users': {_unsafe_index: None}, 'type': None, '_prev': mul_1, '_next': _unsafe_index, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_17': ("L['self'].model.model[17]", <class 'torch.nn.modules.upsampling.Upsample'>)}, 'source_fn': ('l__self___model_model_17', <class 'torch.nn.modules.upsampling.Upsample'>), 'original_aten': <OpOverload(op='aten._to_copy', overload='default')>, 'from_node': [('l__self___model_model_17', 'L__self___model_model_17')], 'seq_nr': -1, 'val': FakeTensor(..., size=(30,), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([30]), dtype=torch.int64, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': '_unsafe_index', 'op': 'call_function', 'target': <OpOverload(op='aten._unsafe_index', overload='Tensor')>, '_input_nodes': {silu_9: None, unsqueeze: None, _to_copy_1: None}, '_args': (silu_9, [None, None, unsqueeze, _to_copy_1]), '_kwargs': {}, 'users': {cat: None}, 'type': None, '_prev': _to_copy_1, '_next': cat, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_17': ("L['self'].model.model[17]", <class 'torch.nn.modules.upsampling.Upsample'>)}, 'source_fn': ('l__self___model_model_17', <class 'torch.nn.modules.upsampling.Upsample'>), 'original_aten': <OpOverload(op='aten._unsafe_index', overload='Tensor')>, 'from_node': [('l__self___model_model_17', 'L__self___model_model_17')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 128, 40, 30)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 40, 30]), dtype=torch.float32, requires_grad=False, stride=(153600, 1200, 30, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'cat', 'op': 'call_function', 'target': <OpOverload(op='aten.cat', overload='default')>, '_input_nodes': {_unsafe_index: None, silu_4: None}, '_args': ([_unsafe_index, silu_4], 1), '_kwargs': {}, 'users': {convolution_10: None}, 'type': None, '_prev': _unsafe_index, '_next': convolution_10, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/common.py", line 312, in forward\n    return torch.cat(x, self.d)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_18': ("L['self'].model.model[18]", <class 'models.common.Concat'>)}, 'source_fn': ('cat', <built-in method cat of type object at 0x7f5a951b0aa0>), 'original_aten': <OpOverload(op='aten.cat', overload='default')>, 'from_node': [('cat', <built-in method cat of type object at 0x7f5a951b0aa0>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 384, 40, 30)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 384, 40, 30]), dtype=torch.float32, requires_grad=False, stride=(460800, 1200, 30, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'convolution_10', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {cat: None, arg20_1: None, arg21_1: None}, '_args': (cat, arg20_1, arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {silu_10: None}, 'type': None, '_prev': cat, '_next': silu_10, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/common.py", line 59, in forward_fuse\n    return self.act(self.conv(x))\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_19_conv': ("L['self'].model.model[19].conv", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('l__self___model_model_19_conv', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('l__self___model_model_19_conv', 'L__self___model_model_19_conv')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 256, 40, 30)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 40, 30]), dtype=torch.float32, requires_grad=False, stride=(307200, 1200, 30, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'silu_10', 'op': 'call_function', 'target': <OpOverload(op='aten.silu', overload='default')>, '_input_nodes': {convolution_10: None}, '_args': (convolution_10,), '_kwargs': {}, 'users': {convolution_11: None}, 'type': None, '_prev': convolution_10, '_next': convolution_11, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/common.py", line 59, in forward_fuse\n    return self.act(self.conv(x))\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_19_act': ("L['self'].model.model[19].act", <class 'torch.nn.modules.activation.SiLU'>)}, 'source_fn': ('l__self___model_model_19_act', <class 'torch.nn.modules.activation.SiLU'>), 'original_aten': <OpOverload(op='aten.silu', overload='default')>, 'from_node': [('l__self___model_model_19_act', 'L__self___model_model_19_act')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 256, 40, 30)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 40, 30]), dtype=torch.float32, requires_grad=False, stride=(307200, 1200, 30, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'convolution_11', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {silu_10: None, arg22_1: None, arg23_1: None}, '_args': (silu_10, arg22_1, arg23_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {view: None}, 'type': None, '_prev': silu_10, '_next': view, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 59, in forward\n    x[i] = self.m[i](x[i])  # conv\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>), 'sub0_0': ("L['self'].model.model[20].m[0]", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('sub0_0', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('sub0_0', 'sub0_0')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 255, 40, 30)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 255, 40, 30]), dtype=torch.float32, requires_grad=False, stride=(306000, 1200, 30, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'view', 'op': 'call_function', 'target': <OpOverload(op='aten.view', overload='default')>, '_input_nodes': {convolution_11: None}, '_args': (convolution_11, [1, 3, 85, 40, 30]), '_kwargs': {}, 'users': {permute: None}, 'type': None, '_prev': convolution_11, '_next': permute, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 61, in forward\n    x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('view', 'view'), 'original_aten': <OpOverload(op='aten.view', overload='default')>, 'from_node': [('view', 'view')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 85, 40, 30)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 85, 40, 30]), dtype=torch.float32, requires_grad=False, stride=(306000, 102000, 1200, 30, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'permute', 'op': 'call_function', 'target': <OpOverload(op='aten.permute', overload='default')>, '_input_nodes': {view: None}, '_args': (view, [0, 1, 3, 4, 2]), '_kwargs': {}, 'users': {clone: None}, 'type': None, '_prev': view, '_next': clone, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 61, in forward\n    x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('permute', 'permute'), 'original_aten': <OpOverload(op='aten.permute', overload='default')>, 'from_node': [('permute', 'permute')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 40, 30, 85)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 85]), dtype=torch.float32, requires_grad=False, stride=(306000, 102000, 30, 1, 1200), memory_format=None, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'clone', 'op': 'call_function', 'target': <OpOverload(op='aten.clone', overload='default')>, '_input_nodes': {permute: None}, '_args': (permute,), '_kwargs': {'memory_format': torch.contiguous_format}, 'users': {sigmoid: None, output: None}, 'type': None, '_prev': permute, '_next': arange_2, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 61, in forward\n    x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('contiguous', 'contiguous'), 'original_aten': <OpOverload(op='aten.clone', overload='default')>, 'from_node': [('contiguous', 'contiguous')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 40, 30, 85)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 85]), dtype=torch.float32, requires_grad=False, stride=(306000, 102000, 2550, 85, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arange_2', 'op': 'call_function', 'target': <OpOverload(op='aten.arange', overload='default')>, '_input_nodes': {}, '_args': (40,), '_kwargs': {'dtype': torch.float32, 'device': device(type='cpu'), 'pin_memory': False}, 'users': {view_1: None}, 'type': None, '_prev': clone, '_next': arange_3, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 85, in _make_grid\n    y, x = torch.arange(ny, device=d, dtype=t), torch.arange(nx, device=d, dtype=t)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('arange', <built-in method arange of type object at 0x7f5a951b0aa0>), 'original_aten': <OpOverload(op='aten.arange', overload='default')>, 'from_node': [('arange', <built-in method arange of type object at 0x7f5a951b0aa0>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(40,)), 'tensor_meta': TensorMetadata(shape=torch.Size([40]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arange_3', 'op': 'call_function', 'target': <OpOverload(op='aten.arange', overload='default')>, '_input_nodes': {}, '_args': (30,), '_kwargs': {'dtype': torch.float32, 'device': device(type='cpu'), 'pin_memory': False}, 'users': {view_2: None}, 'type': None, '_prev': arange_2, '_next': view_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 85, in _make_grid\n    y, x = torch.arange(ny, device=d, dtype=t), torch.arange(nx, device=d, dtype=t)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('arange_1', <built-in method arange of type object at 0x7f5a951b0aa0>), 'original_aten': <OpOverload(op='aten.arange', overload='default')>, 'from_node': [('arange_1', <built-in method arange of type object at 0x7f5a951b0aa0>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(30,)), 'tensor_meta': TensorMetadata(shape=torch.Size([30]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'view_1', 'op': 'call_function', 'target': <OpOverload(op='aten.view', overload='default')>, '_input_nodes': {arange_2: None}, '_args': (arange_2, [-1, 1]), '_kwargs': {}, 'users': {expand: None}, 'type': None, '_prev': arange_3, '_next': expand, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 86, in _make_grid\n    yv, xv = torch.meshgrid(y, x, indexing=\'ij\') if torch_1_10 else torch.meshgrid(y, x)  # torch>=0.7 compatibility\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('meshgrid', <function meshgrid at 0x7f5a1b64e520>), 'original_aten': <OpOverload(op='aten.view', overload='default')>, 'from_node': [('meshgrid', <function meshgrid at 0x7f5a1b64e520>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(40, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([40, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'expand', 'op': 'call_function', 'target': <OpOverload(op='aten.expand', overload='default')>, '_input_nodes': {view_1: None}, '_args': (view_1, [40, 30]), '_kwargs': {}, 'users': {stack: None}, 'type': None, '_prev': view_1, '_next': view_2, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 86, in _make_grid\n    yv, xv = torch.meshgrid(y, x, indexing=\'ij\') if torch_1_10 else torch.meshgrid(y, x)  # torch>=0.7 compatibility\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('meshgrid', <function meshgrid at 0x7f5a1b64e520>), 'original_aten': <OpOverload(op='aten.expand', overload='default')>, 'from_node': [('meshgrid', <function meshgrid at 0x7f5a1b64e520>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(40, 30)), 'tensor_meta': TensorMetadata(shape=torch.Size([40, 30]), dtype=torch.float32, requires_grad=False, stride=(1, 0), memory_format=None, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'view_2', 'op': 'call_function', 'target': <OpOverload(op='aten.view', overload='default')>, '_input_nodes': {arange_3: None}, '_args': (arange_3, [1, -1]), '_kwargs': {}, 'users': {expand_1: None}, 'type': None, '_prev': expand, '_next': expand_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 86, in _make_grid\n    yv, xv = torch.meshgrid(y, x, indexing=\'ij\') if torch_1_10 else torch.meshgrid(y, x)  # torch>=0.7 compatibility\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('meshgrid', <function meshgrid at 0x7f5a1b64e520>), 'original_aten': <OpOverload(op='aten.view', overload='default')>, 'from_node': [('meshgrid', <function meshgrid at 0x7f5a1b64e520>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 30)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 30]), dtype=torch.float32, requires_grad=False, stride=(30, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'expand_1', 'op': 'call_function', 'target': <OpOverload(op='aten.expand', overload='default')>, '_input_nodes': {view_2: None}, '_args': (view_2, [40, 30]), '_kwargs': {}, 'users': {stack: None}, 'type': None, '_prev': view_2, '_next': stack, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 86, in _make_grid\n    yv, xv = torch.meshgrid(y, x, indexing=\'ij\') if torch_1_10 else torch.meshgrid(y, x)  # torch>=0.7 compatibility\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('meshgrid', <function meshgrid at 0x7f5a1b64e520>), 'original_aten': <OpOverload(op='aten.expand', overload='default')>, 'from_node': [('meshgrid', <function meshgrid at 0x7f5a1b64e520>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(40, 30)), 'tensor_meta': TensorMetadata(shape=torch.Size([40, 30]), dtype=torch.float32, requires_grad=False, stride=(0, 1), memory_format=None, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'stack', 'op': 'call_function', 'target': <OpOverload(op='aten.stack', overload='default')>, '_input_nodes': {expand_1: None, expand: None}, '_args': ([expand_1, expand], 2), '_kwargs': {}, 'users': {expand_2: None}, 'type': None, '_prev': expand_1, '_next': expand_2, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 87, in _make_grid\n    grid = torch.stack((xv, yv), 2).expand(shape) - 0.5  # add grid offset, i.e. y = 2.0 * x - 0.5\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('stack', <built-in method stack of type object at 0x7f5a951b0aa0>), 'original_aten': <OpOverload(op='aten.stack', overload='default')>, 'from_node': [('stack', <built-in method stack of type object at 0x7f5a951b0aa0>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(40, 30, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([40, 30, 2]), dtype=torch.float32, requires_grad=False, stride=(60, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'expand_2', 'op': 'call_function', 'target': <OpOverload(op='aten.expand', overload='default')>, '_input_nodes': {stack: None}, '_args': (stack, [1, 3, 40, 30, 2]), '_kwargs': {}, 'users': {sub: None}, 'type': None, '_prev': stack, '_next': sub, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 87, in _make_grid\n    grid = torch.stack((xv, yv), 2).expand(shape) - 0.5  # add grid offset, i.e. y = 2.0 * x - 0.5\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('expand', 'expand'), 'original_aten': <OpOverload(op='aten.expand', overload='default')>, 'from_node': [('expand', 'expand')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 40, 30, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 2]), dtype=torch.float32, requires_grad=False, stride=(2400, 0, 60, 2, 1), memory_format=None, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'sub', 'op': 'call_function', 'target': <OpOverload(op='aten.sub', overload='Tensor')>, '_input_nodes': {expand_2: None}, '_args': (expand_2, 0.5), '_kwargs': {}, 'users': {add: None, output: None}, 'type': None, '_prev': expand_2, '_next': select, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 87, in _make_grid\n    grid = torch.stack((xv, yv), 2).expand(shape) - 0.5  # add grid offset, i.e. y = 2.0 * x - 0.5\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('sub', <built-in function sub>), 'original_aten': <OpOverload(op='aten.sub', overload='Tensor')>, 'from_node': [('sub', <built-in function sub>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 40, 30, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 2]), dtype=torch.float32, requires_grad=False, stride=(7200, 2400, 60, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'select', 'op': 'call_function', 'target': <OpOverload(op='aten.select', overload='int')>, '_input_nodes': {arg26_1: None}, '_args': (arg26_1, 0, 0), '_kwargs': {}, 'users': {mul_2: None}, 'type': None, '_prev': sub, '_next': select_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 88, in _make_grid\n    anchor_grid = (self.anchors[i] * self.stride[i]).view((1, self.na, 1, 1, 2)).expand(shape)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('getitem_4', <built-in function getitem>), 'original_aten': <OpOverload(op='aten.select', overload='int')>, 'from_node': [('getitem_4', <built-in function getitem>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(3, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([3, 2]), dtype=torch.float32, requires_grad=False, stride=(2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'select_1', 'op': 'call_function', 'target': <OpOverload(op='aten.select', overload='int')>, '_input_nodes': {arg27_1: None}, '_args': (arg27_1, 0, 0), '_kwargs': {}, 'users': {mul_2: None}, 'type': None, '_prev': select, '_next': mul_2, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 88, in _make_grid\n    anchor_grid = (self.anchors[i] * self.stride[i]).view((1, self.na, 1, 1, 2)).expand(shape)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('getitem_5', <built-in function getitem>), 'original_aten': <OpOverload(op='aten.select', overload='int')>, 'from_node': [('getitem_5', <built-in function getitem>)], 'seq_nr': -1, 'val': FakeTensor(..., size=()), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.float32, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'mul_2', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {select: None, select_1: None}, '_args': (select, select_1), '_kwargs': {}, 'users': {view_3: None}, 'type': None, '_prev': select_1, '_next': view_3, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 88, in _make_grid\n    anchor_grid = (self.anchors[i] * self.stride[i]).view((1, self.na, 1, 1, 2)).expand(shape)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('mul', <built-in function mul>), 'original_aten': <OpOverload(op='aten.mul', overload='Tensor')>, 'from_node': [('mul', <built-in function mul>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(3, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([3, 2]), dtype=torch.float32, requires_grad=False, stride=(2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'view_3', 'op': 'call_function', 'target': <OpOverload(op='aten.view', overload='default')>, '_input_nodes': {mul_2: None}, '_args': (mul_2, [1, 3, 1, 1, 2]), '_kwargs': {}, 'users': {expand_3: None}, 'type': None, '_prev': mul_2, '_next': expand_3, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 88, in _make_grid\n    anchor_grid = (self.anchors[i] * self.stride[i]).view((1, self.na, 1, 1, 2)).expand(shape)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('view_1', 'view'), 'original_aten': <OpOverload(op='aten.view', overload='default')>, 'from_node': [('view_1', 'view')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 1, 1, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 1, 1, 2]), dtype=torch.float32, requires_grad=False, stride=(6, 2, 2, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'expand_3', 'op': 'call_function', 'target': <OpOverload(op='aten.expand', overload='default')>, '_input_nodes': {view_3: None}, '_args': (view_3, [1, 3, 40, 30, 2]), '_kwargs': {}, 'users': {mul_6: None, output: None}, 'type': None, '_prev': view_3, '_next': sigmoid, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 88, in _make_grid\n    anchor_grid = (self.anchors[i] * self.stride[i]).view((1, self.na, 1, 1, 2)).expand(shape)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('expand_1', 'expand'), 'original_aten': <OpOverload(op='aten.expand', overload='default')>, 'from_node': [('expand_1', 'expand')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 40, 30, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 2]), dtype=torch.float32, requires_grad=False, stride=(6, 2, 0, 0, 1), memory_format=None, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'sigmoid', 'op': 'call_function', 'target': <OpOverload(op='aten.sigmoid', overload='default')>, '_input_nodes': {clone: None}, '_args': (clone,), '_kwargs': {}, 'users': {split_with_sizes: None}, 'type': None, '_prev': expand_3, '_next': split_with_sizes, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 73, in forward\n    xy, wh, conf = x[i].sigmoid().split((2, 2, self.nc + 1), 4)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('sigmoid', 'sigmoid'), 'original_aten': <OpOverload(op='aten.sigmoid', overload='default')>, 'from_node': [('sigmoid', 'sigmoid')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 40, 30, 85)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 85]), dtype=torch.float32, requires_grad=False, stride=(306000, 102000, 2550, 85, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'split_with_sizes', 'op': 'call_function', 'target': <OpOverload(op='aten.split_with_sizes', overload='default')>, '_input_nodes': {sigmoid: None}, '_args': (sigmoid, [2, 2, 81], 4), '_kwargs': {}, 'users': {getitem_12: None, getitem_13: None, getitem_14: None}, 'type': None, '_prev': sigmoid, '_next': getitem_12, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 73, in forward\n    xy, wh, conf = x[i].sigmoid().split((2, 2, self.nc + 1), 4)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('split', 'split'), 'original_aten': <OpOverload(op='aten.split_with_sizes', overload='default')>, 'from_node': [('split', 'split')], 'seq_nr': -1, 'val': [FakeTensor(..., size=(1, 3, 40, 30, 2)), FakeTensor(..., size=(1, 3, 40, 30, 2)), FakeTensor(..., size=(1, 3, 40, 30, 81))], 'tensor_meta': None}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'getitem_12', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {split_with_sizes: None}, '_args': (split_with_sizes, 0), '_kwargs': {}, 'users': {mul_3: None}, 'type': None, '_prev': split_with_sizes, '_next': getitem_13, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 73, in forward\n    xy, wh, conf = x[i].sigmoid().split((2, 2, self.nc + 1), 4)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('split', 'split'), 'original_aten': <OpOverload(op='aten.split_with_sizes', overload='default')>, 'from_node': [('split', 'split')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 40, 30, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 2]), dtype=torch.float32, requires_grad=False, stride=(306000, 102000, 2550, 85, 1), memory_format=None, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'getitem_13', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {split_with_sizes: None}, '_args': (split_with_sizes, 1), '_kwargs': {}, 'users': {mul_5: None}, 'type': None, '_prev': getitem_12, '_next': getitem_14, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 73, in forward\n    xy, wh, conf = x[i].sigmoid().split((2, 2, self.nc + 1), 4)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('split', 'split'), 'original_aten': <OpOverload(op='aten.split_with_sizes', overload='default')>, 'from_node': [('split', 'split')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 40, 30, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 2]), dtype=torch.float32, requires_grad=False, stride=(306000, 102000, 2550, 85, 1), memory_format=None, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'getitem_14', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {split_with_sizes: None}, '_args': (split_with_sizes, 2), '_kwargs': {}, 'users': {cat_1: None}, 'type': None, '_prev': getitem_13, '_next': mul_3, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 73, in forward\n    xy, wh, conf = x[i].sigmoid().split((2, 2, self.nc + 1), 4)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('split', 'split'), 'original_aten': <OpOverload(op='aten.split_with_sizes', overload='default')>, 'from_node': [('split', 'split')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 40, 30, 81)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 81]), dtype=torch.float32, requires_grad=False, stride=(306000, 102000, 2550, 85, 1), memory_format=None, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'mul_3', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {getitem_12: None}, '_args': (getitem_12, 2), '_kwargs': {}, 'users': {add: None}, 'type': None, '_prev': getitem_14, '_next': add, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 74, in forward\n    xy = (xy * 2 + self.grid[i]) * self.stride[i]  # xy\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('mul_1', <built-in function mul>), 'original_aten': <OpOverload(op='aten.mul', overload='Tensor')>, 'from_node': [('mul_1', <built-in function mul>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 40, 30, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 2]), dtype=torch.float32, requires_grad=False, stride=(7200, 2400, 60, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'add', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {mul_3: None, sub: None}, '_args': (mul_3, sub), '_kwargs': {}, 'users': {mul_4: None}, 'type': None, '_prev': mul_3, '_next': select_2, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 74, in forward\n    xy = (xy * 2 + self.grid[i]) * self.stride[i]  # xy\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('add', <built-in function add>), 'original_aten': <OpOverload(op='aten.add', overload='Tensor')>, 'from_node': [('add', <built-in function add>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 40, 30, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 2]), dtype=torch.float32, requires_grad=False, stride=(7200, 2400, 60, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'select_2', 'op': 'call_function', 'target': <OpOverload(op='aten.select', overload='int')>, '_input_nodes': {arg27_1: None}, '_args': (arg27_1, 0, 0), '_kwargs': {}, 'users': {mul_4: None}, 'type': None, '_prev': add, '_next': mul_4, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 74, in forward\n    xy = (xy * 2 + self.grid[i]) * self.stride[i]  # xy\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('getitem_9', <built-in function getitem>), 'original_aten': <OpOverload(op='aten.select', overload='int')>, 'from_node': [('getitem_9', <built-in function getitem>)], 'seq_nr': -1, 'val': FakeTensor(..., size=()), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.float32, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'mul_4', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {add: None, select_2: None}, '_args': (add, select_2), '_kwargs': {}, 'users': {cat_1: None}, 'type': None, '_prev': select_2, '_next': mul_5, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 74, in forward\n    xy = (xy * 2 + self.grid[i]) * self.stride[i]  # xy\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('mul_2', <built-in function mul>), 'original_aten': <OpOverload(op='aten.mul', overload='Tensor')>, 'from_node': [('mul_2', <built-in function mul>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 40, 30, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 2]), dtype=torch.float32, requires_grad=False, stride=(7200, 2400, 60, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'mul_5', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {getitem_13: None}, '_args': (getitem_13, 2), '_kwargs': {}, 'users': {pow_1: None}, 'type': None, '_prev': mul_4, '_next': pow_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 75, in forward\n    wh = (wh * 2) ** 2 * self.anchor_grid[i]  # wh\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('mul_3', <built-in function mul>), 'original_aten': <OpOverload(op='aten.mul', overload='Tensor')>, 'from_node': [('mul_3', <built-in function mul>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 40, 30, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 2]), dtype=torch.float32, requires_grad=False, stride=(7200, 2400, 60, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'pow_1', 'op': 'call_function', 'target': <OpOverload(op='aten.pow', overload='Tensor_Scalar')>, '_input_nodes': {mul_5: None}, '_args': (mul_5, 2), '_kwargs': {}, 'users': {mul_6: None}, 'type': None, '_prev': mul_5, '_next': mul_6, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 75, in forward\n    wh = (wh * 2) ** 2 * self.anchor_grid[i]  # wh\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('pow_1', <built-in function pow>), 'original_aten': <OpOverload(op='aten.pow', overload='Tensor_Scalar')>, 'from_node': [('pow_1', <built-in function pow>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 40, 30, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 2]), dtype=torch.float32, requires_grad=False, stride=(7200, 2400, 60, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'mul_6', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {pow_1: None, expand_3: None}, '_args': (pow_1, expand_3), '_kwargs': {}, 'users': {cat_1: None}, 'type': None, '_prev': pow_1, '_next': cat_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 75, in forward\n    wh = (wh * 2) ** 2 * self.anchor_grid[i]  # wh\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('mul_4', <built-in function mul>), 'original_aten': <OpOverload(op='aten.mul', overload='Tensor')>, 'from_node': [('mul_4', <built-in function mul>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 40, 30, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 2]), dtype=torch.float32, requires_grad=False, stride=(7200, 2400, 60, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'cat_1', 'op': 'call_function', 'target': <OpOverload(op='aten.cat', overload='default')>, '_input_nodes': {mul_4: None, mul_6: None, getitem_14: None}, '_args': ([mul_4, mul_6, getitem_14], 4), '_kwargs': {}, 'users': {view_4: None}, 'type': None, '_prev': mul_6, '_next': view_4, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 76, in forward\n    y = torch.cat((xy, wh, conf), 4)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('cat_1', <built-in method cat of type object at 0x7f5a951b0aa0>), 'original_aten': <OpOverload(op='aten.cat', overload='default')>, 'from_node': [('cat_1', <built-in method cat of type object at 0x7f5a951b0aa0>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 40, 30, 85)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 40, 30, 85]), dtype=torch.float32, requires_grad=False, stride=(306000, 102000, 2550, 85, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'view_4', 'op': 'call_function', 'target': <OpOverload(op='aten.view', overload='default')>, '_input_nodes': {cat_1: None}, '_args': (cat_1, [1, 3600, 85]), '_kwargs': {}, 'users': {cat_3: None}, 'type': None, '_prev': cat_1, '_next': convolution_12, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 77, in forward\n    z.append(y.view(bs, self.na * nx * ny, self.no))\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('view_2', 'view'), 'original_aten': <OpOverload(op='aten.view', overload='default')>, 'from_node': [('view_2', 'view')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3600, 85)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3600, 85]), dtype=torch.float32, requires_grad=False, stride=(306000, 85, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'convolution_12', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {silu_8: None, arg24_1: None, arg25_1: None}, '_args': (silu_8, arg24_1, arg25_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {view_5: None}, 'type': None, '_prev': view_4, '_next': view_5, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 59, in forward\n    x[i] = self.m[i](x[i])  # conv\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>), 'sub1_1': ("L['self'].model.model[20].m[1]", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('sub1_1', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('sub1_1', 'sub1_1')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 255, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 255, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(76500, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'view_5', 'op': 'call_function', 'target': <OpOverload(op='aten.view', overload='default')>, '_input_nodes': {convolution_12: None}, '_args': (convolution_12, [1, 3, 85, 20, 15]), '_kwargs': {}, 'users': {permute_1: None}, 'type': None, '_prev': convolution_12, '_next': permute_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 61, in forward\n    x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('view_3', 'view'), 'original_aten': <OpOverload(op='aten.view', overload='default')>, 'from_node': [('view_3', 'view')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 85, 20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 85, 20, 15]), dtype=torch.float32, requires_grad=False, stride=(76500, 25500, 300, 15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'permute_1', 'op': 'call_function', 'target': <OpOverload(op='aten.permute', overload='default')>, '_input_nodes': {view_5: None}, '_args': (view_5, [0, 1, 3, 4, 2]), '_kwargs': {}, 'users': {clone_1: None}, 'type': None, '_prev': view_5, '_next': clone_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 61, in forward\n    x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('permute_1', 'permute'), 'original_aten': <OpOverload(op='aten.permute', overload='default')>, 'from_node': [('permute_1', 'permute')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 20, 15, 85)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 85]), dtype=torch.float32, requires_grad=False, stride=(76500, 25500, 15, 1, 300), memory_format=None, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'clone_1', 'op': 'call_function', 'target': <OpOverload(op='aten.clone', overload='default')>, '_input_nodes': {permute_1: None}, '_args': (permute_1,), '_kwargs': {'memory_format': torch.contiguous_format}, 'users': {sigmoid_1: None, output: None}, 'type': None, '_prev': permute_1, '_next': arange_4, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 61, in forward\n    x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('contiguous_1', 'contiguous'), 'original_aten': <OpOverload(op='aten.clone', overload='default')>, 'from_node': [('contiguous_1', 'contiguous')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 20, 15, 85)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 85]), dtype=torch.float32, requires_grad=False, stride=(76500, 25500, 1275, 85, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arange_4', 'op': 'call_function', 'target': <OpOverload(op='aten.arange', overload='default')>, '_input_nodes': {}, '_args': (20,), '_kwargs': {'dtype': torch.float32, 'device': device(type='cpu'), 'pin_memory': False}, 'users': {view_6: None}, 'type': None, '_prev': clone_1, '_next': arange_5, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 85, in _make_grid\n    y, x = torch.arange(ny, device=d, dtype=t), torch.arange(nx, device=d, dtype=t)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('arange_2', <built-in method arange of type object at 0x7f5a951b0aa0>), 'original_aten': <OpOverload(op='aten.arange', overload='default')>, 'from_node': [('arange_2', <built-in method arange of type object at 0x7f5a951b0aa0>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(20,)), 'tensor_meta': TensorMetadata(shape=torch.Size([20]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'arange_5', 'op': 'call_function', 'target': <OpOverload(op='aten.arange', overload='default')>, '_input_nodes': {}, '_args': (15,), '_kwargs': {'dtype': torch.float32, 'device': device(type='cpu'), 'pin_memory': False}, 'users': {view_7: None}, 'type': None, '_prev': arange_4, '_next': view_6, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 85, in _make_grid\n    y, x = torch.arange(ny, device=d, dtype=t), torch.arange(nx, device=d, dtype=t)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('arange_3', <built-in method arange of type object at 0x7f5a951b0aa0>), 'original_aten': <OpOverload(op='aten.arange', overload='default')>, 'from_node': [('arange_3', <built-in method arange of type object at 0x7f5a951b0aa0>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(15,)), 'tensor_meta': TensorMetadata(shape=torch.Size([15]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'view_6', 'op': 'call_function', 'target': <OpOverload(op='aten.view', overload='default')>, '_input_nodes': {arange_4: None}, '_args': (arange_4, [-1, 1]), '_kwargs': {}, 'users': {expand_4: None}, 'type': None, '_prev': arange_5, '_next': expand_4, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 86, in _make_grid\n    yv, xv = torch.meshgrid(y, x, indexing=\'ij\') if torch_1_10 else torch.meshgrid(y, x)  # torch>=0.7 compatibility\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('meshgrid_1', <function meshgrid at 0x7f5a1b64e520>), 'original_aten': <OpOverload(op='aten.view', overload='default')>, 'from_node': [('meshgrid_1', <function meshgrid at 0x7f5a1b64e520>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(20, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([20, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'expand_4', 'op': 'call_function', 'target': <OpOverload(op='aten.expand', overload='default')>, '_input_nodes': {view_6: None}, '_args': (view_6, [20, 15]), '_kwargs': {}, 'users': {stack_1: None}, 'type': None, '_prev': view_6, '_next': view_7, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 86, in _make_grid\n    yv, xv = torch.meshgrid(y, x, indexing=\'ij\') if torch_1_10 else torch.meshgrid(y, x)  # torch>=0.7 compatibility\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('meshgrid_1', <function meshgrid at 0x7f5a1b64e520>), 'original_aten': <OpOverload(op='aten.expand', overload='default')>, 'from_node': [('meshgrid_1', <function meshgrid at 0x7f5a1b64e520>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([20, 15]), dtype=torch.float32, requires_grad=False, stride=(1, 0), memory_format=None, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'view_7', 'op': 'call_function', 'target': <OpOverload(op='aten.view', overload='default')>, '_input_nodes': {arange_5: None}, '_args': (arange_5, [1, -1]), '_kwargs': {}, 'users': {expand_5: None}, 'type': None, '_prev': expand_4, '_next': expand_5, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 86, in _make_grid\n    yv, xv = torch.meshgrid(y, x, indexing=\'ij\') if torch_1_10 else torch.meshgrid(y, x)  # torch>=0.7 compatibility\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('meshgrid_1', <function meshgrid at 0x7f5a1b64e520>), 'original_aten': <OpOverload(op='aten.view', overload='default')>, 'from_node': [('meshgrid_1', <function meshgrid at 0x7f5a1b64e520>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 15]), dtype=torch.float32, requires_grad=False, stride=(15, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'expand_5', 'op': 'call_function', 'target': <OpOverload(op='aten.expand', overload='default')>, '_input_nodes': {view_7: None}, '_args': (view_7, [20, 15]), '_kwargs': {}, 'users': {stack_1: None}, 'type': None, '_prev': view_7, '_next': stack_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 86, in _make_grid\n    yv, xv = torch.meshgrid(y, x, indexing=\'ij\') if torch_1_10 else torch.meshgrid(y, x)  # torch>=0.7 compatibility\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('meshgrid_1', <function meshgrid at 0x7f5a1b64e520>), 'original_aten': <OpOverload(op='aten.expand', overload='default')>, 'from_node': [('meshgrid_1', <function meshgrid at 0x7f5a1b64e520>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(20, 15)), 'tensor_meta': TensorMetadata(shape=torch.Size([20, 15]), dtype=torch.float32, requires_grad=False, stride=(0, 1), memory_format=None, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'stack_1', 'op': 'call_function', 'target': <OpOverload(op='aten.stack', overload='default')>, '_input_nodes': {expand_5: None, expand_4: None}, '_args': ([expand_5, expand_4], 2), '_kwargs': {}, 'users': {expand_6: None}, 'type': None, '_prev': expand_5, '_next': expand_6, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 87, in _make_grid\n    grid = torch.stack((xv, yv), 2).expand(shape) - 0.5  # add grid offset, i.e. y = 2.0 * x - 0.5\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('stack_1', <built-in method stack of type object at 0x7f5a951b0aa0>), 'original_aten': <OpOverload(op='aten.stack', overload='default')>, 'from_node': [('stack_1', <built-in method stack of type object at 0x7f5a951b0aa0>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(20, 15, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([20, 15, 2]), dtype=torch.float32, requires_grad=False, stride=(30, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'expand_6', 'op': 'call_function', 'target': <OpOverload(op='aten.expand', overload='default')>, '_input_nodes': {stack_1: None}, '_args': (stack_1, [1, 3, 20, 15, 2]), '_kwargs': {}, 'users': {sub_1: None}, 'type': None, '_prev': stack_1, '_next': sub_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 87, in _make_grid\n    grid = torch.stack((xv, yv), 2).expand(shape) - 0.5  # add grid offset, i.e. y = 2.0 * x - 0.5\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('expand_2', 'expand'), 'original_aten': <OpOverload(op='aten.expand', overload='default')>, 'from_node': [('expand_2', 'expand')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 20, 15, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 2]), dtype=torch.float32, requires_grad=False, stride=(600, 0, 30, 2, 1), memory_format=None, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'sub_1', 'op': 'call_function', 'target': <OpOverload(op='aten.sub', overload='Tensor')>, '_input_nodes': {expand_6: None}, '_args': (expand_6, 0.5), '_kwargs': {}, 'users': {add_1: None, output: None}, 'type': None, '_prev': expand_6, '_next': select_3, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 87, in _make_grid\n    grid = torch.stack((xv, yv), 2).expand(shape) - 0.5  # add grid offset, i.e. y = 2.0 * x - 0.5\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('sub_1', <built-in function sub>), 'original_aten': <OpOverload(op='aten.sub', overload='Tensor')>, 'from_node': [('sub_1', <built-in function sub>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 20, 15, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 2]), dtype=torch.float32, requires_grad=False, stride=(1800, 600, 30, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'select_3', 'op': 'call_function', 'target': <OpOverload(op='aten.select', overload='int')>, '_input_nodes': {arg26_1: None}, '_args': (arg26_1, 0, 1), '_kwargs': {}, 'users': {mul_7: None}, 'type': None, '_prev': sub_1, '_next': select_4, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 88, in _make_grid\n    anchor_grid = (self.anchors[i] * self.stride[i]).view((1, self.na, 1, 1, 2)).expand(shape)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('getitem_14', <built-in function getitem>), 'original_aten': <OpOverload(op='aten.select', overload='int')>, 'from_node': [('getitem_14', <built-in function getitem>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(3, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([3, 2]), dtype=torch.float32, requires_grad=False, stride=(2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'select_4', 'op': 'call_function', 'target': <OpOverload(op='aten.select', overload='int')>, '_input_nodes': {arg27_1: None}, '_args': (arg27_1, 0, 1), '_kwargs': {}, 'users': {mul_7: None}, 'type': None, '_prev': select_3, '_next': mul_7, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 88, in _make_grid\n    anchor_grid = (self.anchors[i] * self.stride[i]).view((1, self.na, 1, 1, 2)).expand(shape)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('getitem_15', <built-in function getitem>), 'original_aten': <OpOverload(op='aten.select', overload='int')>, 'from_node': [('getitem_15', <built-in function getitem>)], 'seq_nr': -1, 'val': FakeTensor(..., size=()), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.float32, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'mul_7', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {select_3: None, select_4: None}, '_args': (select_3, select_4), '_kwargs': {}, 'users': {view_8: None}, 'type': None, '_prev': select_4, '_next': view_8, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 88, in _make_grid\n    anchor_grid = (self.anchors[i] * self.stride[i]).view((1, self.na, 1, 1, 2)).expand(shape)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('mul_5', <built-in function mul>), 'original_aten': <OpOverload(op='aten.mul', overload='Tensor')>, 'from_node': [('mul_5', <built-in function mul>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(3, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([3, 2]), dtype=torch.float32, requires_grad=False, stride=(2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'view_8', 'op': 'call_function', 'target': <OpOverload(op='aten.view', overload='default')>, '_input_nodes': {mul_7: None}, '_args': (mul_7, [1, 3, 1, 1, 2]), '_kwargs': {}, 'users': {expand_7: None}, 'type': None, '_prev': mul_7, '_next': expand_7, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 88, in _make_grid\n    anchor_grid = (self.anchors[i] * self.stride[i]).view((1, self.na, 1, 1, 2)).expand(shape)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('view_4', 'view'), 'original_aten': <OpOverload(op='aten.view', overload='default')>, 'from_node': [('view_4', 'view')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 1, 1, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 1, 1, 2]), dtype=torch.float32, requires_grad=False, stride=(6, 2, 2, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'expand_7', 'op': 'call_function', 'target': <OpOverload(op='aten.expand', overload='default')>, '_input_nodes': {view_8: None}, '_args': (view_8, [1, 3, 20, 15, 2]), '_kwargs': {}, 'users': {mul_11: None, output: None}, 'type': None, '_prev': view_8, '_next': sigmoid_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 65, in forward\n    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n  File "/root/yolov3/models/yolo.py", line 88, in _make_grid\n    anchor_grid = (self.anchors[i] * self.stride[i]).view((1, self.na, 1, 1, 2)).expand(shape)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('expand_3', 'expand'), 'original_aten': <OpOverload(op='aten.expand', overload='default')>, 'from_node': [('expand_3', 'expand')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 20, 15, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 2]), dtype=torch.float32, requires_grad=False, stride=(6, 2, 0, 0, 1), memory_format=None, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'sigmoid_1', 'op': 'call_function', 'target': <OpOverload(op='aten.sigmoid', overload='default')>, '_input_nodes': {clone_1: None}, '_args': (clone_1,), '_kwargs': {}, 'users': {split_with_sizes_1: None}, 'type': None, '_prev': expand_7, '_next': split_with_sizes_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 73, in forward\n    xy, wh, conf = x[i].sigmoid().split((2, 2, self.nc + 1), 4)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('sigmoid_1', 'sigmoid'), 'original_aten': <OpOverload(op='aten.sigmoid', overload='default')>, 'from_node': [('sigmoid_1', 'sigmoid')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 20, 15, 85)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 85]), dtype=torch.float32, requires_grad=False, stride=(76500, 25500, 1275, 85, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'split_with_sizes_1', 'op': 'call_function', 'target': <OpOverload(op='aten.split_with_sizes', overload='default')>, '_input_nodes': {sigmoid_1: None}, '_args': (sigmoid_1, [2, 2, 81], 4), '_kwargs': {}, 'users': {getitem_15: None, getitem_16: None, getitem_17: None}, 'type': None, '_prev': sigmoid_1, '_next': getitem_15, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 73, in forward\n    xy, wh, conf = x[i].sigmoid().split((2, 2, self.nc + 1), 4)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('split_1', 'split'), 'original_aten': <OpOverload(op='aten.split_with_sizes', overload='default')>, 'from_node': [('split_1', 'split')], 'seq_nr': -1, 'val': [FakeTensor(..., size=(1, 3, 20, 15, 2)), FakeTensor(..., size=(1, 3, 20, 15, 2)), FakeTensor(..., size=(1, 3, 20, 15, 81))], 'tensor_meta': None}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'getitem_15', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {split_with_sizes_1: None}, '_args': (split_with_sizes_1, 0), '_kwargs': {}, 'users': {mul_8: None}, 'type': None, '_prev': split_with_sizes_1, '_next': getitem_16, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 73, in forward\n    xy, wh, conf = x[i].sigmoid().split((2, 2, self.nc + 1), 4)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('split_1', 'split'), 'original_aten': <OpOverload(op='aten.split_with_sizes', overload='default')>, 'from_node': [('split_1', 'split')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 20, 15, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 2]), dtype=torch.float32, requires_grad=False, stride=(76500, 25500, 1275, 85, 1), memory_format=None, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'getitem_16', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {split_with_sizes_1: None}, '_args': (split_with_sizes_1, 1), '_kwargs': {}, 'users': {mul_10: None}, 'type': None, '_prev': getitem_15, '_next': getitem_17, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 73, in forward\n    xy, wh, conf = x[i].sigmoid().split((2, 2, self.nc + 1), 4)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('split_1', 'split'), 'original_aten': <OpOverload(op='aten.split_with_sizes', overload='default')>, 'from_node': [('split_1', 'split')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 20, 15, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 2]), dtype=torch.float32, requires_grad=False, stride=(76500, 25500, 1275, 85, 1), memory_format=None, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'getitem_17', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {split_with_sizes_1: None}, '_args': (split_with_sizes_1, 2), '_kwargs': {}, 'users': {cat_2: None}, 'type': None, '_prev': getitem_16, '_next': mul_8, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 73, in forward\n    xy, wh, conf = x[i].sigmoid().split((2, 2, self.nc + 1), 4)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('split_1', 'split'), 'original_aten': <OpOverload(op='aten.split_with_sizes', overload='default')>, 'from_node': [('split_1', 'split')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 20, 15, 81)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 81]), dtype=torch.float32, requires_grad=False, stride=(76500, 25500, 1275, 85, 1), memory_format=None, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'mul_8', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {getitem_15: None}, '_args': (getitem_15, 2), '_kwargs': {}, 'users': {add_1: None}, 'type': None, '_prev': getitem_17, '_next': add_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 74, in forward\n    xy = (xy * 2 + self.grid[i]) * self.stride[i]  # xy\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('mul_6', <built-in function mul>), 'original_aten': <OpOverload(op='aten.mul', overload='Tensor')>, 'from_node': [('mul_6', <built-in function mul>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 20, 15, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 2]), dtype=torch.float32, requires_grad=False, stride=(1800, 600, 30, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'add_1', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {mul_8: None, sub_1: None}, '_args': (mul_8, sub_1), '_kwargs': {}, 'users': {mul_9: None}, 'type': None, '_prev': mul_8, '_next': select_5, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 74, in forward\n    xy = (xy * 2 + self.grid[i]) * self.stride[i]  # xy\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('add_1', <built-in function add>), 'original_aten': <OpOverload(op='aten.add', overload='Tensor')>, 'from_node': [('add_1', <built-in function add>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 20, 15, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 2]), dtype=torch.float32, requires_grad=False, stride=(1800, 600, 30, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'select_5', 'op': 'call_function', 'target': <OpOverload(op='aten.select', overload='int')>, '_input_nodes': {arg27_1: None}, '_args': (arg27_1, 0, 1), '_kwargs': {}, 'users': {mul_9: None}, 'type': None, '_prev': add_1, '_next': mul_9, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 74, in forward\n    xy = (xy * 2 + self.grid[i]) * self.stride[i]  # xy\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('getitem_19', <built-in function getitem>), 'original_aten': <OpOverload(op='aten.select', overload='int')>, 'from_node': [('getitem_19', <built-in function getitem>)], 'seq_nr': -1, 'val': FakeTensor(..., size=()), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.float32, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'mul_9', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {add_1: None, select_5: None}, '_args': (add_1, select_5), '_kwargs': {}, 'users': {cat_2: None}, 'type': None, '_prev': select_5, '_next': mul_10, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 74, in forward\n    xy = (xy * 2 + self.grid[i]) * self.stride[i]  # xy\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('mul_7', <built-in function mul>), 'original_aten': <OpOverload(op='aten.mul', overload='Tensor')>, 'from_node': [('mul_7', <built-in function mul>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 20, 15, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 2]), dtype=torch.float32, requires_grad=False, stride=(1800, 600, 30, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'mul_10', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {getitem_16: None}, '_args': (getitem_16, 2), '_kwargs': {}, 'users': {pow_2: None}, 'type': None, '_prev': mul_9, '_next': pow_2, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 75, in forward\n    wh = (wh * 2) ** 2 * self.anchor_grid[i]  # wh\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('mul_8', <built-in function mul>), 'original_aten': <OpOverload(op='aten.mul', overload='Tensor')>, 'from_node': [('mul_8', <built-in function mul>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 20, 15, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 2]), dtype=torch.float32, requires_grad=False, stride=(1800, 600, 30, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'pow_2', 'op': 'call_function', 'target': <OpOverload(op='aten.pow', overload='Tensor_Scalar')>, '_input_nodes': {mul_10: None}, '_args': (mul_10, 2), '_kwargs': {}, 'users': {mul_11: None}, 'type': None, '_prev': mul_10, '_next': mul_11, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 75, in forward\n    wh = (wh * 2) ** 2 * self.anchor_grid[i]  # wh\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('pow_2', <built-in function pow>), 'original_aten': <OpOverload(op='aten.pow', overload='Tensor_Scalar')>, 'from_node': [('pow_2', <built-in function pow>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 20, 15, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 2]), dtype=torch.float32, requires_grad=False, stride=(1800, 600, 30, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'mul_11', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {pow_2: None, expand_7: None}, '_args': (pow_2, expand_7), '_kwargs': {}, 'users': {cat_2: None}, 'type': None, '_prev': pow_2, '_next': cat_2, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 75, in forward\n    wh = (wh * 2) ** 2 * self.anchor_grid[i]  # wh\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('mul_9', <built-in function mul>), 'original_aten': <OpOverload(op='aten.mul', overload='Tensor')>, 'from_node': [('mul_9', <built-in function mul>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 20, 15, 2)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 2]), dtype=torch.float32, requires_grad=False, stride=(1800, 600, 30, 2, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'cat_2', 'op': 'call_function', 'target': <OpOverload(op='aten.cat', overload='default')>, '_input_nodes': {mul_9: None, mul_11: None, getitem_17: None}, '_args': ([mul_9, mul_11, getitem_17], 4), '_kwargs': {}, 'users': {view_9: None}, 'type': None, '_prev': mul_11, '_next': view_9, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 76, in forward\n    y = torch.cat((xy, wh, conf), 4)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('cat_2', <built-in method cat of type object at 0x7f5a951b0aa0>), 'original_aten': <OpOverload(op='aten.cat', overload='default')>, 'from_node': [('cat_2', <built-in method cat of type object at 0x7f5a951b0aa0>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 3, 20, 15, 85)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 20, 15, 85]), dtype=torch.float32, requires_grad=False, stride=(76500, 25500, 1275, 85, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'view_9', 'op': 'call_function', 'target': <OpOverload(op='aten.view', overload='default')>, '_input_nodes': {cat_2: None}, '_args': (cat_2, [1, 900, 85]), '_kwargs': {}, 'users': {cat_3: None}, 'type': None, '_prev': cat_2, '_next': cat_3, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 77, in forward\n    z.append(y.view(bs, self.na * nx * ny, self.no))\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('view_5', 'view'), 'original_aten': <OpOverload(op='aten.view', overload='default')>, 'from_node': [('view_5', 'view')], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 900, 85)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 900, 85]), dtype=torch.float32, requires_grad=False, stride=(76500, 85, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'cat_3', 'op': 'call_function', 'target': <OpOverload(op='aten.cat', overload='default')>, '_input_nodes': {view_4: None, view_9: None}, '_args': ([view_4, view_9], 1), '_kwargs': {}, 'users': {output: None}, 'type': None, '_prev': view_9, '_next': output, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/root/yolov3/models/common.py", line 514, in forward\n    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 209, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File "/root/yolov3/models/yolo.py", line 121, in _forward_once\n    x = m(x)  # run\n  File "/root/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/root/yolov3/models/yolo.py", line 79, in forward\n    return x if self.training else (torch.cat(z, 1), ) if self.export else (torch.cat(z, 1), x)\n', 'nn_module_stack': {'L__self___model': ("L['self'].model", <class 'models.yolo.DetectionModel'>), 'L__self___model_model_20': ("L['self'].model.model[20]", <class 'models.yolo.Detect'>)}, 'source_fn': ('cat_3', <built-in method cat of type object at 0x7f5a951b0aa0>), 'original_aten': <OpOverload(op='aten.cat', overload='default')>, 'from_node': [('cat_3', <built-in method cat of type object at 0x7f5a951b0aa0>)], 'seq_nr': -1, 'val': FakeTensor(..., size=(1, 4500, 85)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 4500, 85]), dtype=torch.float32, requires_grad=False, stride=(382500, 85, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f59f07a5a90>, 'name': 'output', 'op': 'output', 'target': 'output', '_input_nodes': {cat_3: None, clone: None, clone_1: None, sub: None, sub_1: None, expand_3: None, expand_7: None}, '_args': ((cat_3, clone, clone_1, sub, sub_1, expand_3, expand_7),), '_kwargs': {}, 'users': {}, 'type': None, '_prev': cat_3, '_next': , '_erased': False, '_repr_fn': None, 'meta': {'tensor_meta': None, 'val': None}}
