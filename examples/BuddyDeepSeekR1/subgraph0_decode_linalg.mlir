#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1, d2) -> (d0, d1)>
#map2 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1) -> (d0, 0)>
#map4 = affine_map<(d0, d1, d2) -> (d0, 0, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1, 0, d3)>
#map6 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>
#map7 = affine_map<(d0, d1, d2) -> (d0, d1, 0)>
#map8 = affine_map<(d0, d1, d2, d3) -> (d0, 0, d2, d3)>
#map9 = affine_map<(d0, d1, d2, d3) -> (d0, 0, d2, 0)>
module {
  func.func @subgraph0_decode(%arg0: tensor<151936x1536xf32>, %arg1: tensor<1x1xi64>, %arg2: tensor<1xi64>, %arg3: tensor<1xi64>, %arg4: tensor<64xf32>, %arg5: tensor<1536xf32>, %arg6: tensor<1536xf32>, %arg7: tensor<1536x1536xf32>, %arg8: tensor<256xf32>, %arg9: tensor<1536x256xf32>, %arg10: tensor<256xf32>, %arg11: tensor<1536x256xf32>, %arg12: tensor<1x2x1024x128xf32>, %arg13: tensor<1x2x1024x128xf32>, %arg14: tensor<1536x1536xf32>, %arg15: tensor<1536xf32>, %arg16: tensor<1536x8960xf32>, %arg17: tensor<1536x8960xf32>, %arg18: tensor<8960x1536xf32>, %arg19: tensor<1536xf32>, %arg20: tensor<1536xf32>, %arg21: tensor<1536x1536xf32>, %arg22: tensor<256xf32>, %arg23: tensor<1536x256xf32>, %arg24: tensor<256xf32>, %arg25: tensor<1536x256xf32>, %arg26: tensor<1x2x1024x128xf32>, %arg27: tensor<1x2x1024x128xf32>, %arg28: tensor<1536x1536xf32>, %arg29: tensor<1536xf32>, %arg30: tensor<1536x8960xf32>, %arg31: tensor<1536x8960xf32>, %arg32: tensor<8960x1536xf32>, %arg33: tensor<1536xf32>, %arg34: tensor<1536xf32>, %arg35: tensor<1536x1536xf32>, %arg36: tensor<256xf32>, %arg37: tensor<1536x256xf32>, %arg38: tensor<256xf32>, %arg39: tensor<1536x256xf32>, %arg40: tensor<1x2x1024x128xf32>, %arg41: tensor<1x2x1024x128xf32>, %arg42: tensor<1536x1536xf32>, %arg43: tensor<1536xf32>, %arg44: tensor<1536x8960xf32>, %arg45: tensor<1536x8960xf32>, %arg46: tensor<8960x1536xf32>, %arg47: tensor<1536xf32>, %arg48: tensor<1536xf32>, %arg49: tensor<1536x1536xf32>, %arg50: tensor<256xf32>, %arg51: tensor<1536x256xf32>, %arg52: tensor<256xf32>, %arg53: tensor<1536x256xf32>, %arg54: tensor<1x2x1024x128xf32>, %arg55: tensor<1x2x1024x128xf32>, %arg56: tensor<1536x1536xf32>, %arg57: tensor<1536xf32>, %arg58: tensor<1536x8960xf32>, %arg59: tensor<1536x8960xf32>, %arg60: tensor<8960x1536xf32>, %arg61: tensor<1536xf32>, %arg62: tensor<1536xf32>, %arg63: tensor<1536x1536xf32>, %arg64: tensor<256xf32>, %arg65: tensor<1536x256xf32>, %arg66: tensor<256xf32>, %arg67: tensor<1536x256xf32>, %arg68: tensor<1x2x1024x128xf32>, %arg69: tensor<1x2x1024x128xf32>, %arg70: tensor<1536x1536xf32>, %arg71: tensor<1536xf32>, %arg72: tensor<1536x8960xf32>, %arg73: tensor<1536x8960xf32>, %arg74: tensor<8960x1536xf32>, %arg75: tensor<1536xf32>, %arg76: tensor<1536xf32>, %arg77: tensor<1536x1536xf32>, %arg78: tensor<256xf32>, %arg79: tensor<1536x256xf32>, %arg80: tensor<256xf32>, %arg81: tensor<1536x256xf32>, %arg82: tensor<1x2x1024x128xf32>, %arg83: tensor<1x2x1024x128xf32>, %arg84: tensor<1536x1536xf32>, %arg85: tensor<1536xf32>, %arg86: tensor<1536x8960xf32>, %arg87: tensor<1536x8960xf32>, %arg88: tensor<8960x1536xf32>, %arg89: tensor<1536xf32>, %arg90: tensor<1536xf32>, %arg91: tensor<1536x1536xf32>, %arg92: tensor<256xf32>, %arg93: tensor<1536x256xf32>, %arg94: tensor<256xf32>, %arg95: tensor<1536x256xf32>, %arg96: tensor<1x2x1024x128xf32>, %arg97: tensor<1x2x1024x128xf32>, %arg98: tensor<1536x1536xf32>, %arg99: tensor<1536xf32>, %arg100: tensor<1536x8960xf32>, %arg101: tensor<1536x8960xf32>, %arg102: tensor<8960x1536xf32>, %arg103: tensor<1536xf32>, %arg104: tensor<1536xf32>, %arg105: tensor<1536x1536xf32>, %arg106: tensor<256xf32>, %arg107: tensor<1536x256xf32>, %arg108: tensor<256xf32>, %arg109: tensor<1536x256xf32>, %arg110: tensor<1x2x1024x128xf32>, %arg111: tensor<1x2x1024x128xf32>, %arg112: tensor<1536x1536xf32>, %arg113: tensor<1536xf32>, %arg114: tensor<1536x8960xf32>, %arg115: tensor<1536x8960xf32>, %arg116: tensor<8960x1536xf32>, %arg117: tensor<1536xf32>, %arg118: tensor<1536xf32>, %arg119: tensor<1536x1536xf32>, %arg120: tensor<256xf32>, %arg121: tensor<1536x256xf32>, %arg122: tensor<256xf32>, %arg123: tensor<1536x256xf32>, %arg124: tensor<1x2x1024x128xf32>, %arg125: tensor<1x2x1024x128xf32>, %arg126: tensor<1536x1536xf32>, %arg127: tensor<1536xf32>, %arg128: tensor<1536x8960xf32>, %arg129: tensor<1536x8960xf32>, %arg130: tensor<8960x1536xf32>, %arg131: tensor<1536xf32>, %arg132: tensor<1536xf32>, %arg133: tensor<1536x1536xf32>, %arg134: tensor<256xf32>, %arg135: tensor<1536x256xf32>, %arg136: tensor<256xf32>, %arg137: tensor<1536x256xf32>, %arg138: tensor<1x2x1024x128xf32>, %arg139: tensor<1x2x1024x128xf32>, %arg140: tensor<1536x1536xf32>, %arg141: tensor<1536xf32>, %arg142: tensor<1536x8960xf32>, %arg143: tensor<1536x8960xf32>, %arg144: tensor<8960x1536xf32>, %arg145: tensor<1536xf32>, %arg146: tensor<1536xf32>, %arg147: tensor<1536x1536xf32>, %arg148: tensor<256xf32>, %arg149: tensor<1536x256xf32>, %arg150: tensor<256xf32>, %arg151: tensor<1536x256xf32>, %arg152: tensor<1x2x1024x128xf32>, %arg153: tensor<1x2x1024x128xf32>, %arg154: tensor<1536x1536xf32>, %arg155: tensor<1536xf32>, %arg156: tensor<1536x8960xf32>, %arg157: tensor<1536x8960xf32>, %arg158: tensor<8960x1536xf32>, %arg159: tensor<1536xf32>, %arg160: tensor<1536xf32>, %arg161: tensor<1536x1536xf32>, %arg162: tensor<256xf32>, %arg163: tensor<1536x256xf32>, %arg164: tensor<256xf32>, %arg165: tensor<1536x256xf32>, %arg166: tensor<1x2x1024x128xf32>, %arg167: tensor<1x2x1024x128xf32>, %arg168: tensor<1536x1536xf32>, %arg169: tensor<1536xf32>, %arg170: tensor<1536x8960xf32>, %arg171: tensor<1536x8960xf32>, %arg172: tensor<8960x1536xf32>, %arg173: tensor<1536xf32>, %arg174: tensor<1536xf32>, %arg175: tensor<1536x1536xf32>, %arg176: tensor<256xf32>, %arg177: tensor<1536x256xf32>, %arg178: tensor<256xf32>, %arg179: tensor<1536x256xf32>, %arg180: tensor<1x2x1024x128xf32>, %arg181: tensor<1x2x1024x128xf32>, %arg182: tensor<1536x1536xf32>, %arg183: tensor<1536xf32>, %arg184: tensor<1536x8960xf32>, %arg185: tensor<1536x8960xf32>, %arg186: tensor<8960x1536xf32>, %arg187: tensor<1536xf32>, %arg188: tensor<1536xf32>, %arg189: tensor<1536x1536xf32>, %arg190: tensor<256xf32>, %arg191: tensor<1536x256xf32>, %arg192: tensor<256xf32>, %arg193: tensor<1536x256xf32>, %arg194: tensor<1x2x1024x128xf32>, %arg195: tensor<1x2x1024x128xf32>, %arg196: tensor<1536x1536xf32>, %arg197: tensor<1536xf32>, %arg198: tensor<1536x8960xf32>, %arg199: tensor<1536x8960xf32>, %arg200: tensor<8960x1536xf32>, %arg201: tensor<1536xf32>, %arg202: tensor<1536xf32>, %arg203: tensor<1536x1536xf32>, %arg204: tensor<256xf32>, %arg205: tensor<1536x256xf32>, %arg206: tensor<256xf32>, %arg207: tensor<1536x256xf32>, %arg208: tensor<1x2x1024x128xf32>, %arg209: tensor<1x2x1024x128xf32>, %arg210: tensor<1536x1536xf32>, %arg211: tensor<1536xf32>, %arg212: tensor<1536x8960xf32>, %arg213: tensor<1536x8960xf32>, %arg214: tensor<8960x1536xf32>, %arg215: tensor<1536xf32>, %arg216: tensor<1536xf32>, %arg217: tensor<1536x1536xf32>, %arg218: tensor<256xf32>, %arg219: tensor<1536x256xf32>, %arg220: tensor<256xf32>, %arg221: tensor<1536x256xf32>, %arg222: tensor<1x2x1024x128xf32>, %arg223: tensor<1x2x1024x128xf32>, %arg224: tensor<1536x1536xf32>, %arg225: tensor<1536xf32>, %arg226: tensor<1536x8960xf32>, %arg227: tensor<1536x8960xf32>, %arg228: tensor<8960x1536xf32>, %arg229: tensor<1536xf32>, %arg230: tensor<1536xf32>, %arg231: tensor<1536x1536xf32>, %arg232: tensor<256xf32>, %arg233: tensor<1536x256xf32>, %arg234: tensor<256xf32>, %arg235: tensor<1536x256xf32>, %arg236: tensor<1x2x1024x128xf32>, %arg237: tensor<1x2x1024x128xf32>, %arg238: tensor<1536x1536xf32>, %arg239: tensor<1536xf32>, %arg240: tensor<1536x8960xf32>, %arg241: tensor<1536x8960xf32>, %arg242: tensor<8960x1536xf32>, %arg243: tensor<1536xf32>, %arg244: tensor<1536xf32>, %arg245: tensor<1536x1536xf32>, %arg246: tensor<256xf32>, %arg247: tensor<1536x256xf32>, %arg248: tensor<256xf32>, %arg249: tensor<1536x256xf32>, %arg250: tensor<1x2x1024x128xf32>, %arg251: tensor<1x2x1024x128xf32>, %arg252: tensor<1536x1536xf32>, %arg253: tensor<1536xf32>, %arg254: tensor<1536x8960xf32>, %arg255: tensor<1536x8960xf32>, %arg256: tensor<8960x1536xf32>, %arg257: tensor<1536xf32>, %arg258: tensor<1536xf32>, %arg259: tensor<1536x1536xf32>, %arg260: tensor<256xf32>, %arg261: tensor<1536x256xf32>, %arg262: tensor<256xf32>, %arg263: tensor<1536x256xf32>, %arg264: tensor<1x2x1024x128xf32>, %arg265: tensor<1x2x1024x128xf32>, %arg266: tensor<1536x1536xf32>, %arg267: tensor<1536xf32>, %arg268: tensor<1536x8960xf32>, %arg269: tensor<1536x8960xf32>, %arg270: tensor<8960x1536xf32>, %arg271: tensor<1536xf32>, %arg272: tensor<1536xf32>, %arg273: tensor<1536x1536xf32>, %arg274: tensor<256xf32>, %arg275: tensor<1536x256xf32>, %arg276: tensor<256xf32>, %arg277: tensor<1536x256xf32>, %arg278: tensor<1x2x1024x128xf32>, %arg279: tensor<1x2x1024x128xf32>, %arg280: tensor<1536x1536xf32>, %arg281: tensor<1536xf32>, %arg282: tensor<1536x8960xf32>, %arg283: tensor<1536x8960xf32>, %arg284: tensor<8960x1536xf32>, %arg285: tensor<1536xf32>, %arg286: tensor<1536xf32>, %arg287: tensor<1536x1536xf32>, %arg288: tensor<256xf32>, %arg289: tensor<1536x256xf32>, %arg290: tensor<256xf32>, %arg291: tensor<1536x256xf32>, %arg292: tensor<1x2x1024x128xf32>, %arg293: tensor<1x2x1024x128xf32>, %arg294: tensor<1536x1536xf32>, %arg295: tensor<1536xf32>, %arg296: tensor<1536x8960xf32>, %arg297: tensor<1536x8960xf32>, %arg298: tensor<8960x1536xf32>, %arg299: tensor<1536xf32>, %arg300: tensor<1536xf32>, %arg301: tensor<1536x1536xf32>, %arg302: tensor<256xf32>, %arg303: tensor<1536x256xf32>, %arg304: tensor<256xf32>, %arg305: tensor<1536x256xf32>, %arg306: tensor<1x2x1024x128xf32>, %arg307: tensor<1x2x1024x128xf32>, %arg308: tensor<1536x1536xf32>, %arg309: tensor<1536xf32>, %arg310: tensor<1536x8960xf32>, %arg311: tensor<1536x8960xf32>, %arg312: tensor<8960x1536xf32>, %arg313: tensor<1536xf32>, %arg314: tensor<1536xf32>, %arg315: tensor<1536x1536xf32>, %arg316: tensor<256xf32>, %arg317: tensor<1536x256xf32>, %arg318: tensor<256xf32>, %arg319: tensor<1536x256xf32>, %arg320: tensor<1x2x1024x128xf32>, %arg321: tensor<1x2x1024x128xf32>, %arg322: tensor<1536x1536xf32>, %arg323: tensor<1536xf32>, %arg324: tensor<1536x8960xf32>, %arg325: tensor<1536x8960xf32>, %arg326: tensor<8960x1536xf32>, %arg327: tensor<1536xf32>, %arg328: tensor<1536xf32>, %arg329: tensor<1536x1536xf32>, %arg330: tensor<256xf32>, %arg331: tensor<1536x256xf32>, %arg332: tensor<256xf32>, %arg333: tensor<1536x256xf32>, %arg334: tensor<1x2x1024x128xf32>, %arg335: tensor<1x2x1024x128xf32>, %arg336: tensor<1536x1536xf32>, %arg337: tensor<1536xf32>, %arg338: tensor<1536x8960xf32>, %arg339: tensor<1536x8960xf32>, %arg340: tensor<8960x1536xf32>, %arg341: tensor<1536xf32>, %arg342: tensor<1536xf32>, %arg343: tensor<1536x1536xf32>, %arg344: tensor<256xf32>, %arg345: tensor<1536x256xf32>, %arg346: tensor<256xf32>, %arg347: tensor<1536x256xf32>, %arg348: tensor<1x2x1024x128xf32>, %arg349: tensor<1x2x1024x128xf32>, %arg350: tensor<1536x1536xf32>, %arg351: tensor<1536xf32>, %arg352: tensor<1536x8960xf32>, %arg353: tensor<1536x8960xf32>, %arg354: tensor<8960x1536xf32>, %arg355: tensor<1536xf32>, %arg356: tensor<1536xf32>, %arg357: tensor<1536x1536xf32>, %arg358: tensor<256xf32>, %arg359: tensor<1536x256xf32>, %arg360: tensor<256xf32>, %arg361: tensor<1536x256xf32>, %arg362: tensor<1x2x1024x128xf32>, %arg363: tensor<1x2x1024x128xf32>, %arg364: tensor<1536x1536xf32>, %arg365: tensor<1536xf32>, %arg366: tensor<1536x8960xf32>, %arg367: tensor<1536x8960xf32>, %arg368: tensor<8960x1536xf32>, %arg369: tensor<1536xf32>, %arg370: tensor<1536xf32>, %arg371: tensor<1536x1536xf32>, %arg372: tensor<256xf32>, %arg373: tensor<1536x256xf32>, %arg374: tensor<256xf32>, %arg375: tensor<1536x256xf32>, %arg376: tensor<1x2x1024x128xf32>, %arg377: tensor<1x2x1024x128xf32>, %arg378: tensor<1536x1536xf32>, %arg379: tensor<1536xf32>, %arg380: tensor<1536x8960xf32>, %arg381: tensor<1536x8960xf32>, %arg382: tensor<8960x1536xf32>, %arg383: tensor<1536xf32>, %arg384: tensor<1536xf32>, %arg385: tensor<1536x1536xf32>, %arg386: tensor<256xf32>, %arg387: tensor<1536x256xf32>, %arg388: tensor<256xf32>, %arg389: tensor<1536x256xf32>, %arg390: tensor<1x2x1024x128xf32>, %arg391: tensor<1x2x1024x128xf32>, %arg392: tensor<1536x1536xf32>, %arg393: tensor<1536xf32>, %arg394: tensor<1536x8960xf32>, %arg395: tensor<1536x8960xf32>, %arg396: tensor<8960x1536xf32>, %arg397: tensor<1536xf32>, %arg398: tensor<1536x151936xf32>) -> (tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x1x151936xf32>) {
    %cst = arith.constant dense<0.000000e+00> : vector<16xf32>
    %cst_0 = arith.constant dense<0xFF800000> : tensor<1x1x1x1024xf32>
    %cst_1 = arith.constant dense<0.000000e+00> : tensor<1x1x1x1024xf32>
    %cst_2 = arith.constant dense<6.51041686E-4> : tensor<1x1x1xf32>
    %cst_3 = arith.constant dense<"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tensor<1x1024xi64>
    %0 = tosa.const_shape  {values = dense<[1, 1, 151936]> : tensor<3xindex>} : () -> !tosa.shape<3>
    %cst_4 = arith.constant dense<0.000000e+00> : tensor<1x151936xf32>
    %1 = tosa.const_shape  {values = dense<[1, 8960]> : tensor<2xindex>} : () -> !tosa.shape<2>
    %2 = tosa.const_shape  {values = dense<[1, 1, 8960]> : tensor<3xindex>} : () -> !tosa.shape<3>
    %cst_5 = arith.constant dense<0.000000e+00> : tensor<1x8960xf32>
    %c6 = arith.constant 6 : index
    %cst_6 = arith.constant -1.000000e+30 : f32
    %cst_7 = arith.constant 0.0883883461 : f32
    %cst_8 = arith.constant 1.000000e+00 : f32
    %cst_9 = arith.constant 0.000000e+00 : f32
    %3 = tosa.const_shape  {values = dense<[1, 1, 1, 1024]> : tensor<4xindex>} : () -> !tosa.shape<4>
    %c128 = arith.constant 128 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %cst_10 = arith.constant dense<0> : tensor<1x2x1x128xi64>
    %4 = tosa.const_shape  {values = dense<1> : tensor<4xindex>} : () -> !tosa.shape<4>
    %5 = tosa.const_shape  {values = dense<[1, 1, 1, 128]> : tensor<4xindex>} : () -> !tosa.shape<4>
    %6 = tosa.const_shape  {values = dense<[1, 2, 1, 128]> : tensor<4xindex>} : () -> !tosa.shape<4>
    %7 = tosa.const_shape  {values = dense<[1, 256]> : tensor<2xindex>} : () -> !tosa.shape<2>
    %cst_11 = arith.constant dense<0.000000e+00> : tensor<1x256xf32>
    %8 = tosa.const_shape  {values = dense<[1, 12, 1, 128]> : tensor<4xindex>} : () -> !tosa.shape<4>
    %cst_12 = arith.constant dense<0.000000e+00> : tensor<1x1536xf32>
    %9 = tosa.const_shape  {values = dense<[1, 1536]> : tensor<2xindex>} : () -> !tosa.shape<2>
    %10 = tosa.const_shape  {values = dense<[1, 1, 1536]> : tensor<3xindex>} : () -> !tosa.shape<3>
    %cst_13 = arith.constant dense<9.99999997E-7> : tensor<1x1x1xf32>
    %c2_i32 = arith.constant 2 : i32
    %cst_14 = arith.constant dense<0> : tensor<1xi8>
    %11 = tosa.const_shape  {values = dense<[1, 1, 128]> : tensor<3xindex>} : () -> !tosa.shape<3>
    %cst_15 = arith.constant dense<0.000000e+00> : tensor<1x1x2x64xf32>
    %12 = tosa.const_shape  {values = dense<[1, 1, 1, 64]> : tensor<4xindex>} : () -> !tosa.shape<4>
    %cst_16 = arith.constant dense<0.000000e+00> : tensor<1xf32>
    %13 = tosa.const_shape  {values = dense<1> : tensor<3xindex>} : () -> !tosa.shape<3>
    %14 = tosa.const_shape  {values = dense<[1, 64, 1]> : tensor<3xindex>} : () -> !tosa.shape<3>
    %15 = tosa.const_shape  {values = dense<1> : tensor<2xindex>} : () -> !tosa.shape<2>
    %16 = tosa.const_shape  {values = dense<[1, 151936, 1536]> : tensor<3xindex>} : () -> !tosa.shape<3>
    %17 = tensor.empty() : tensor<1x1xi32>
    %18 = linalg.generic {indexing_maps = [#map, #map], iterator_types = ["parallel", "parallel"]} ins(%arg1 : tensor<1x1xi64>) outs(%17 : tensor<1x1xi32>) {
    ^bb0(%in: i64, %out: i32):
      %2454 = arith.trunci %in : i64 to i32
      linalg.yield %2454 : i32
    } -> tensor<1x1xi32>
    %expanded = tensor.expand_shape %arg0 [[0, 1], [2]] output_shape [1, 151936, 1536] : tensor<151936x1536xf32> into tensor<1x151936x1536xf32>
    %19 = tensor.empty() : tensor<1x1x1536xf32>
    %20 = linalg.generic {indexing_maps = [#map1, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%18 : tensor<1x1xi32>) outs(%19 : tensor<1x1x1536xf32>) {
    ^bb0(%in: i32, %out: f32):
      %c0_1172 = arith.constant 0 : index
      %2454 = arith.index_cast %in : i32 to index
      %2455 = linalg.index 2 : index
      %extracted = tensor.extract %expanded[%c0_1172, %2454, %2455] : tensor<1x151936x1536xf32>
      linalg.yield %extracted : f32
    } -> tensor<1x1x1536xf32>
    %expanded_17 = tensor.expand_shape %arg3 [[0, 1]] output_shape [1, 1] : tensor<1xi64> into tensor<1x1xi64>
    %21 = tensor.empty() : tensor<1x1024xi1>
    %22 = linalg.generic {indexing_maps = [#map3, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_17, %cst_3 : tensor<1x1xi64>, tensor<1x1024xi64>) outs(%21 : tensor<1x1024xi1>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i1):
      %2454 = arith.cmpi sge, %in, %in_1172 : i64
      linalg.yield %2454 : i1
    } -> tensor<1x1024xi1>
    %expanded_18 = tensor.expand_shape %arg4 [[0, 1, 2]] output_shape [1, 64, 1] : tensor<64xf32> into tensor<1x64x1xf32>
    %expanded_19 = tensor.expand_shape %arg3 [[0, 1, 2]] output_shape [1, 1, 1] : tensor<1xi64> into tensor<1x1x1xi64>
    %23 = tensor.empty() : tensor<1x1x1xf32>
    %24 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_19 : tensor<1x1x1xi64>) outs(%23 : tensor<1x1x1xf32>) {
    ^bb0(%in: i64, %out: f32):
      %2454 = arith.sitofp %in : i64 to f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %25 = tensor.empty() : tensor<1x64x1xf32>
    %26 = linalg.generic {indexing_maps = [#map2, #map4, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_18, %24 : tensor<1x64x1xf32>, tensor<1x1x1xf32>) outs(%25 : tensor<1x64x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x64x1xf32>
    %collapsed = tensor.collapse_shape %26 [[0], [1, 2]] : tensor<1x64x1xf32> into tensor<1x64xf32>
    %expanded_20 = tensor.expand_shape %collapsed [[0, 1, 2], [3]] output_shape [1, 1, 1, 64] : tensor<1x64xf32> into tensor<1x1x1x64xf32>
    %27 = tensor.empty() : tensor<1x1x2x64xf32>
    %28 = linalg.generic {indexing_maps = [#map5, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_20, %cst_15 : tensor<1x1x1x64xf32>, tensor<1x1x2x64xf32>) outs(%27 : tensor<1x1x2x64xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x2x64xf32>
    %collapsed_21 = tensor.collapse_shape %28 [[0], [1], [2, 3]] : tensor<1x1x2x64xf32> into tensor<1x1x128xf32>
    %29 = math.cos %collapsed_21 : tensor<1x1x128xf32>
    %30 = math.sin %collapsed_21 : tensor<1x1x128xf32>
    %31 = tensor.empty() : tensor<1x1x1536xf32>
    %32 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%20 : tensor<1x1x1536xf32>) outs(%31 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %33 = tensor.empty() : tensor<1x1xf32>
    %cst_22 = arith.constant 0.000000e+00 : f32
    %34 = linalg.fill ins(%cst_22 : f32) outs(%33 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced = linalg.reduce ins(%32 : tensor<1x1x1536xf32>) outs(%34 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_23 = tensor.expand_shape %reduced [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %35 = tensor.empty() : tensor<1x1x1xf32>
    %36 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_23, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%35 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %37 = tensor.empty() : tensor<1x1x1xf32>
    %38 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%36, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%37 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %39 = tensor.empty() : tensor<1x1x1xf32>
    %40 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%38 : tensor<1x1x1xf32>) outs(%39 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %41 = tensor.empty() : tensor<1x1x1536xf32>
    %42 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%20, %40 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%41 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_24 = tensor.expand_shape %arg5 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %43 = tensor.empty() : tensor<1x1x1536xf32>
    %44 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_24, %42 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%43 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_25 = tensor.collapse_shape %44 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %45 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_25, %arg7 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_26 = tensor.expand_shape %arg6 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %46 = tensor.empty() : tensor<1x1536xf32>
    %47 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_26, %45 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%46 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_27 = tensor.expand_shape %47 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_28 = tensor.collapse_shape %44 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %48 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_28, %arg9 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_29 = tensor.expand_shape %arg8 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %49 = tensor.empty() : tensor<1x256xf32>
    %50 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_29, %48 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%49 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_30 = tensor.expand_shape %50 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_31 = tensor.collapse_shape %44 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %51 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_31, %arg11 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_32 = tensor.expand_shape %arg10 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %52 = tensor.empty() : tensor<1x256xf32>
    %53 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_32, %51 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%52 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_33 = tensor.expand_shape %53 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_34 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_35 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %54 = tensor.empty() : tensor<1x12x1x128xf32>
    %55 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_27, %expanded_34 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%54 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice = tensor.extract_slice %expanded_27[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_36 = tensor.extract_slice %expanded_27[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %56 = tensor.empty() : tensor<1x12x1x64xf32>
    %57 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_36 : tensor<1x12x1x64xf32>) outs(%56 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %58 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice = tensor.insert_slice %57 into %58[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_37 = tensor.insert_slice %extracted_slice into %inserted_slice[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %59 = tensor.empty() : tensor<1x12x1x128xf32>
    %60 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_37, %expanded_35 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%59 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %61 = tensor.empty() : tensor<1x12x1x128xf32>
    %62 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%55, %60 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%61 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %63 = tensor.empty() : tensor<1x2x1x128xf32>
    %64 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_30, %expanded_34 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%63 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_38 = tensor.extract_slice %expanded_30[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_39 = tensor.extract_slice %expanded_30[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %65 = tensor.empty() : tensor<1x2x1x64xf32>
    %66 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_39 : tensor<1x2x1x64xf32>) outs(%65 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %67 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_40 = tensor.insert_slice %66 into %67[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_41 = tensor.insert_slice %extracted_slice_38 into %inserted_slice_40[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %68 = tensor.empty() : tensor<1x2x1x128xf32>
    %69 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_41, %expanded_35 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%68 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %70 = tensor.empty() : tensor<1x2x1x128xf32>
    %71 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%64, %69 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%70 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %72 = bufferization.to_buffer %arg12 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_42 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %73 = tensor.empty() : tensor<1x2x1x128xi64>
    %74 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_42, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%73 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %75 = bufferization.to_buffer %74 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %76 = bufferization.to_buffer %71 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %76[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %75[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %72[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %77 = bufferization.to_tensor %72 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %78 = bufferization.to_buffer %arg13 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_43 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %79 = tensor.empty() : tensor<1x2x1x128xi64>
    %80 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_43, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%79 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %81 = bufferization.to_buffer %80 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %82 = bufferization.to_buffer %expanded_33 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %82[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %81[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %78[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %83 = bufferization.to_tensor %78 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_44 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %84 = tensor.empty() : tensor<1x1x1x1024xf32>
    %85 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_44, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%84 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %86 = bufferization.to_buffer %62 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %87 = bufferization.to_buffer %85 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_45 = memref.alloc() : memref<1x12x1xf32>
    %alloc_46 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_46[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %86[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %72[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %87[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %78[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_46[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_46[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_45[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_46[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %88 = bufferization.to_tensor %alloc restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_47 = tensor.collapse_shape %88 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %89 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_47, %arg14 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_48 = tensor.expand_shape %89 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %90 = tensor.empty() : tensor<1x1x1536xf32>
    %91 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%20, %expanded_48 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%90 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %92 = tensor.empty() : tensor<1x1x1536xf32>
    %93 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%91 : tensor<1x1x1536xf32>) outs(%92 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %94 = tensor.empty() : tensor<1x1xf32>
    %cst_49 = arith.constant 0.000000e+00 : f32
    %95 = linalg.fill ins(%cst_49 : f32) outs(%94 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_50 = linalg.reduce ins(%93 : tensor<1x1x1536xf32>) outs(%95 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_51 = tensor.expand_shape %reduced_50 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %96 = tensor.empty() : tensor<1x1x1xf32>
    %97 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_51, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%96 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %98 = tensor.empty() : tensor<1x1x1xf32>
    %99 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%97, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%98 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %100 = tensor.empty() : tensor<1x1x1xf32>
    %101 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%99 : tensor<1x1x1xf32>) outs(%100 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %102 = tensor.empty() : tensor<1x1x1536xf32>
    %103 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%91, %101 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%102 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_52 = tensor.expand_shape %arg15 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %104 = tensor.empty() : tensor<1x1x1536xf32>
    %105 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_52, %103 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%104 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_53 = tensor.collapse_shape %105 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %106 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_53, %arg16 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_54 = tensor.expand_shape %106 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %107 = tensor.empty() : tensor<1x1x8960xf32>
    %108 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_54 : tensor<1x1x8960xf32>) outs(%107 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %109 = tensor.empty() : tensor<1x1x8960xf32>
    %110 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_54, %108 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%109 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_55 = tensor.collapse_shape %105 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %111 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_55, %arg17 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_56 = tensor.expand_shape %111 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %112 = tensor.empty() : tensor<1x1x8960xf32>
    %113 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%110, %expanded_56 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%112 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_57 = tensor.collapse_shape %113 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %114 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_57, %arg18 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_58 = tensor.expand_shape %114 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %115 = tensor.empty() : tensor<1x1x1536xf32>
    %116 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%91, %expanded_58 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%115 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %117 = tensor.empty() : tensor<1x1x1536xf32>
    %118 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%116 : tensor<1x1x1536xf32>) outs(%117 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %119 = tensor.empty() : tensor<1x1xf32>
    %cst_59 = arith.constant 0.000000e+00 : f32
    %120 = linalg.fill ins(%cst_59 : f32) outs(%119 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_60 = linalg.reduce ins(%118 : tensor<1x1x1536xf32>) outs(%120 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_61 = tensor.expand_shape %reduced_60 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %121 = tensor.empty() : tensor<1x1x1xf32>
    %122 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_61, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%121 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %123 = tensor.empty() : tensor<1x1x1xf32>
    %124 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%122, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%123 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %125 = tensor.empty() : tensor<1x1x1xf32>
    %126 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%124 : tensor<1x1x1xf32>) outs(%125 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %127 = tensor.empty() : tensor<1x1x1536xf32>
    %128 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%116, %126 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%127 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_62 = tensor.expand_shape %arg19 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %129 = tensor.empty() : tensor<1x1x1536xf32>
    %130 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_62, %128 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%129 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_63 = tensor.collapse_shape %130 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %131 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_63, %arg21 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_64 = tensor.expand_shape %arg20 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %132 = tensor.empty() : tensor<1x1536xf32>
    %133 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_64, %131 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%132 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_65 = tensor.expand_shape %133 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_66 = tensor.collapse_shape %130 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %134 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_66, %arg23 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_67 = tensor.expand_shape %arg22 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %135 = tensor.empty() : tensor<1x256xf32>
    %136 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_67, %134 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%135 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_68 = tensor.expand_shape %136 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_69 = tensor.collapse_shape %130 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %137 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_69, %arg25 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_70 = tensor.expand_shape %arg24 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %138 = tensor.empty() : tensor<1x256xf32>
    %139 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_70, %137 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%138 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_71 = tensor.expand_shape %139 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_72 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_73 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %140 = tensor.empty() : tensor<1x12x1x128xf32>
    %141 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_65, %expanded_72 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%140 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_74 = tensor.extract_slice %expanded_65[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_75 = tensor.extract_slice %expanded_65[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %142 = tensor.empty() : tensor<1x12x1x64xf32>
    %143 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_75 : tensor<1x12x1x64xf32>) outs(%142 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %144 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_76 = tensor.insert_slice %143 into %144[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_77 = tensor.insert_slice %extracted_slice_74 into %inserted_slice_76[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %145 = tensor.empty() : tensor<1x12x1x128xf32>
    %146 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_77, %expanded_73 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%145 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %147 = tensor.empty() : tensor<1x12x1x128xf32>
    %148 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%141, %146 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%147 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %149 = tensor.empty() : tensor<1x2x1x128xf32>
    %150 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_68, %expanded_72 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%149 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_78 = tensor.extract_slice %expanded_68[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_79 = tensor.extract_slice %expanded_68[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %151 = tensor.empty() : tensor<1x2x1x64xf32>
    %152 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_79 : tensor<1x2x1x64xf32>) outs(%151 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %153 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_80 = tensor.insert_slice %152 into %153[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_81 = tensor.insert_slice %extracted_slice_78 into %inserted_slice_80[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %154 = tensor.empty() : tensor<1x2x1x128xf32>
    %155 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_81, %expanded_73 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%154 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %156 = tensor.empty() : tensor<1x2x1x128xf32>
    %157 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%150, %155 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%156 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %158 = bufferization.to_buffer %arg26 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_82 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %159 = tensor.empty() : tensor<1x2x1x128xi64>
    %160 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_82, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%159 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %161 = bufferization.to_buffer %160 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %162 = bufferization.to_buffer %157 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %162[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %161[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %158[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %163 = bufferization.to_tensor %158 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %164 = bufferization.to_buffer %arg27 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_83 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %165 = tensor.empty() : tensor<1x2x1x128xi64>
    %166 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_83, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%165 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %167 = bufferization.to_buffer %166 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %168 = bufferization.to_buffer %expanded_71 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %168[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %167[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %164[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %169 = bufferization.to_tensor %164 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_84 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %170 = tensor.empty() : tensor<1x1x1x1024xf32>
    %171 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_84, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%170 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %172 = bufferization.to_buffer %148 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %173 = bufferization.to_buffer %171 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_85 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_86 = memref.alloc() : memref<1x12x1xf32>
    %alloc_87 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_87[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %172[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %158[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %173[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %164[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_87[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_87[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_86[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_87[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_85[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %174 = bufferization.to_tensor %alloc_85 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_88 = tensor.collapse_shape %174 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %175 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_88, %arg28 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_89 = tensor.expand_shape %175 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %176 = tensor.empty() : tensor<1x1x1536xf32>
    %177 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%116, %expanded_89 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%176 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %178 = tensor.empty() : tensor<1x1x1536xf32>
    %179 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%177 : tensor<1x1x1536xf32>) outs(%178 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %180 = tensor.empty() : tensor<1x1xf32>
    %cst_90 = arith.constant 0.000000e+00 : f32
    %181 = linalg.fill ins(%cst_90 : f32) outs(%180 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_91 = linalg.reduce ins(%179 : tensor<1x1x1536xf32>) outs(%181 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_92 = tensor.expand_shape %reduced_91 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %182 = tensor.empty() : tensor<1x1x1xf32>
    %183 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_92, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%182 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %184 = tensor.empty() : tensor<1x1x1xf32>
    %185 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%183, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%184 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %186 = tensor.empty() : tensor<1x1x1xf32>
    %187 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%185 : tensor<1x1x1xf32>) outs(%186 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %188 = tensor.empty() : tensor<1x1x1536xf32>
    %189 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%177, %187 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%188 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_93 = tensor.expand_shape %arg29 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %190 = tensor.empty() : tensor<1x1x1536xf32>
    %191 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_93, %189 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%190 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_94 = tensor.collapse_shape %191 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %192 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_94, %arg30 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_95 = tensor.expand_shape %192 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %193 = tensor.empty() : tensor<1x1x8960xf32>
    %194 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_95 : tensor<1x1x8960xf32>) outs(%193 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %195 = tensor.empty() : tensor<1x1x8960xf32>
    %196 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_95, %194 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%195 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_96 = tensor.collapse_shape %191 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %197 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_96, %arg31 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_97 = tensor.expand_shape %197 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %198 = tensor.empty() : tensor<1x1x8960xf32>
    %199 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%196, %expanded_97 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%198 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_98 = tensor.collapse_shape %199 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %200 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_98, %arg32 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_99 = tensor.expand_shape %200 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %201 = tensor.empty() : tensor<1x1x1536xf32>
    %202 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%177, %expanded_99 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%201 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %203 = tensor.empty() : tensor<1x1x1536xf32>
    %204 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%202 : tensor<1x1x1536xf32>) outs(%203 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %205 = tensor.empty() : tensor<1x1xf32>
    %cst_100 = arith.constant 0.000000e+00 : f32
    %206 = linalg.fill ins(%cst_100 : f32) outs(%205 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_101 = linalg.reduce ins(%204 : tensor<1x1x1536xf32>) outs(%206 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_102 = tensor.expand_shape %reduced_101 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %207 = tensor.empty() : tensor<1x1x1xf32>
    %208 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_102, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%207 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %209 = tensor.empty() : tensor<1x1x1xf32>
    %210 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%208, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%209 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %211 = tensor.empty() : tensor<1x1x1xf32>
    %212 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%210 : tensor<1x1x1xf32>) outs(%211 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %213 = tensor.empty() : tensor<1x1x1536xf32>
    %214 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%202, %212 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%213 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_103 = tensor.expand_shape %arg33 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %215 = tensor.empty() : tensor<1x1x1536xf32>
    %216 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_103, %214 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%215 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_104 = tensor.collapse_shape %216 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %217 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_104, %arg35 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_105 = tensor.expand_shape %arg34 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %218 = tensor.empty() : tensor<1x1536xf32>
    %219 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_105, %217 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%218 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_106 = tensor.expand_shape %219 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_107 = tensor.collapse_shape %216 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %220 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_107, %arg37 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_108 = tensor.expand_shape %arg36 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %221 = tensor.empty() : tensor<1x256xf32>
    %222 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_108, %220 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%221 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_109 = tensor.expand_shape %222 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_110 = tensor.collapse_shape %216 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %223 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_110, %arg39 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_111 = tensor.expand_shape %arg38 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %224 = tensor.empty() : tensor<1x256xf32>
    %225 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_111, %223 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%224 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_112 = tensor.expand_shape %225 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_113 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_114 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %226 = tensor.empty() : tensor<1x12x1x128xf32>
    %227 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_106, %expanded_113 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%226 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_115 = tensor.extract_slice %expanded_106[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_116 = tensor.extract_slice %expanded_106[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %228 = tensor.empty() : tensor<1x12x1x64xf32>
    %229 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_116 : tensor<1x12x1x64xf32>) outs(%228 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %230 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_117 = tensor.insert_slice %229 into %230[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_118 = tensor.insert_slice %extracted_slice_115 into %inserted_slice_117[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %231 = tensor.empty() : tensor<1x12x1x128xf32>
    %232 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_118, %expanded_114 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%231 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %233 = tensor.empty() : tensor<1x12x1x128xf32>
    %234 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%227, %232 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%233 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %235 = tensor.empty() : tensor<1x2x1x128xf32>
    %236 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_109, %expanded_113 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%235 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_119 = tensor.extract_slice %expanded_109[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_120 = tensor.extract_slice %expanded_109[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %237 = tensor.empty() : tensor<1x2x1x64xf32>
    %238 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_120 : tensor<1x2x1x64xf32>) outs(%237 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %239 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_121 = tensor.insert_slice %238 into %239[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_122 = tensor.insert_slice %extracted_slice_119 into %inserted_slice_121[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %240 = tensor.empty() : tensor<1x2x1x128xf32>
    %241 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_122, %expanded_114 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%240 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %242 = tensor.empty() : tensor<1x2x1x128xf32>
    %243 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%236, %241 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%242 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %244 = bufferization.to_buffer %arg40 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_123 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %245 = tensor.empty() : tensor<1x2x1x128xi64>
    %246 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_123, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%245 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %247 = bufferization.to_buffer %246 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %248 = bufferization.to_buffer %243 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %248[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %247[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %244[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %249 = bufferization.to_tensor %244 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %250 = bufferization.to_buffer %arg41 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_124 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %251 = tensor.empty() : tensor<1x2x1x128xi64>
    %252 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_124, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%251 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %253 = bufferization.to_buffer %252 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %254 = bufferization.to_buffer %expanded_112 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %254[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %253[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %250[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %255 = bufferization.to_tensor %250 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_125 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %256 = tensor.empty() : tensor<1x1x1x1024xf32>
    %257 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_125, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%256 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %258 = bufferization.to_buffer %234 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %259 = bufferization.to_buffer %257 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_126 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_127 = memref.alloc() : memref<1x12x1xf32>
    %alloc_128 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_128[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %258[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %244[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %259[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %250[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_128[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_128[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_127[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_128[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_126[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %260 = bufferization.to_tensor %alloc_126 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_129 = tensor.collapse_shape %260 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %261 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_129, %arg42 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_130 = tensor.expand_shape %261 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %262 = tensor.empty() : tensor<1x1x1536xf32>
    %263 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%202, %expanded_130 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%262 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %264 = tensor.empty() : tensor<1x1x1536xf32>
    %265 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%263 : tensor<1x1x1536xf32>) outs(%264 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %266 = tensor.empty() : tensor<1x1xf32>
    %cst_131 = arith.constant 0.000000e+00 : f32
    %267 = linalg.fill ins(%cst_131 : f32) outs(%266 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_132 = linalg.reduce ins(%265 : tensor<1x1x1536xf32>) outs(%267 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_133 = tensor.expand_shape %reduced_132 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %268 = tensor.empty() : tensor<1x1x1xf32>
    %269 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_133, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%268 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %270 = tensor.empty() : tensor<1x1x1xf32>
    %271 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%269, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%270 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %272 = tensor.empty() : tensor<1x1x1xf32>
    %273 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%271 : tensor<1x1x1xf32>) outs(%272 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %274 = tensor.empty() : tensor<1x1x1536xf32>
    %275 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%263, %273 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%274 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_134 = tensor.expand_shape %arg43 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %276 = tensor.empty() : tensor<1x1x1536xf32>
    %277 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_134, %275 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%276 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_135 = tensor.collapse_shape %277 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %278 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_135, %arg44 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_136 = tensor.expand_shape %278 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %279 = tensor.empty() : tensor<1x1x8960xf32>
    %280 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_136 : tensor<1x1x8960xf32>) outs(%279 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %281 = tensor.empty() : tensor<1x1x8960xf32>
    %282 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_136, %280 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%281 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_137 = tensor.collapse_shape %277 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %283 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_137, %arg45 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_138 = tensor.expand_shape %283 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %284 = tensor.empty() : tensor<1x1x8960xf32>
    %285 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%282, %expanded_138 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%284 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_139 = tensor.collapse_shape %285 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %286 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_139, %arg46 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_140 = tensor.expand_shape %286 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %287 = tensor.empty() : tensor<1x1x1536xf32>
    %288 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%263, %expanded_140 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%287 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %289 = tensor.empty() : tensor<1x1x1536xf32>
    %290 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%288 : tensor<1x1x1536xf32>) outs(%289 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %291 = tensor.empty() : tensor<1x1xf32>
    %cst_141 = arith.constant 0.000000e+00 : f32
    %292 = linalg.fill ins(%cst_141 : f32) outs(%291 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_142 = linalg.reduce ins(%290 : tensor<1x1x1536xf32>) outs(%292 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_143 = tensor.expand_shape %reduced_142 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %293 = tensor.empty() : tensor<1x1x1xf32>
    %294 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_143, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%293 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %295 = tensor.empty() : tensor<1x1x1xf32>
    %296 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%294, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%295 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %297 = tensor.empty() : tensor<1x1x1xf32>
    %298 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%296 : tensor<1x1x1xf32>) outs(%297 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %299 = tensor.empty() : tensor<1x1x1536xf32>
    %300 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%288, %298 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%299 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_144 = tensor.expand_shape %arg47 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %301 = tensor.empty() : tensor<1x1x1536xf32>
    %302 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_144, %300 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%301 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_145 = tensor.collapse_shape %302 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %303 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_145, %arg49 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_146 = tensor.expand_shape %arg48 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %304 = tensor.empty() : tensor<1x1536xf32>
    %305 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_146, %303 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%304 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_147 = tensor.expand_shape %305 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_148 = tensor.collapse_shape %302 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %306 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_148, %arg51 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_149 = tensor.expand_shape %arg50 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %307 = tensor.empty() : tensor<1x256xf32>
    %308 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_149, %306 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%307 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_150 = tensor.expand_shape %308 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_151 = tensor.collapse_shape %302 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %309 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_151, %arg53 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_152 = tensor.expand_shape %arg52 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %310 = tensor.empty() : tensor<1x256xf32>
    %311 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_152, %309 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%310 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_153 = tensor.expand_shape %311 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_154 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_155 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %312 = tensor.empty() : tensor<1x12x1x128xf32>
    %313 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_147, %expanded_154 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%312 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_156 = tensor.extract_slice %expanded_147[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_157 = tensor.extract_slice %expanded_147[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %314 = tensor.empty() : tensor<1x12x1x64xf32>
    %315 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_157 : tensor<1x12x1x64xf32>) outs(%314 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %316 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_158 = tensor.insert_slice %315 into %316[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_159 = tensor.insert_slice %extracted_slice_156 into %inserted_slice_158[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %317 = tensor.empty() : tensor<1x12x1x128xf32>
    %318 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_159, %expanded_155 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%317 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %319 = tensor.empty() : tensor<1x12x1x128xf32>
    %320 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%313, %318 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%319 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %321 = tensor.empty() : tensor<1x2x1x128xf32>
    %322 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_150, %expanded_154 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%321 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_160 = tensor.extract_slice %expanded_150[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_161 = tensor.extract_slice %expanded_150[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %323 = tensor.empty() : tensor<1x2x1x64xf32>
    %324 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_161 : tensor<1x2x1x64xf32>) outs(%323 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %325 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_162 = tensor.insert_slice %324 into %325[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_163 = tensor.insert_slice %extracted_slice_160 into %inserted_slice_162[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %326 = tensor.empty() : tensor<1x2x1x128xf32>
    %327 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_163, %expanded_155 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%326 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %328 = tensor.empty() : tensor<1x2x1x128xf32>
    %329 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%322, %327 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%328 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %330 = bufferization.to_buffer %arg54 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_164 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %331 = tensor.empty() : tensor<1x2x1x128xi64>
    %332 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_164, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%331 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %333 = bufferization.to_buffer %332 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %334 = bufferization.to_buffer %329 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %334[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %333[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %330[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %335 = bufferization.to_tensor %330 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %336 = bufferization.to_buffer %arg55 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_165 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %337 = tensor.empty() : tensor<1x2x1x128xi64>
    %338 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_165, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%337 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %339 = bufferization.to_buffer %338 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %340 = bufferization.to_buffer %expanded_153 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %340[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %339[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %336[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %341 = bufferization.to_tensor %336 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_166 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %342 = tensor.empty() : tensor<1x1x1x1024xf32>
    %343 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_166, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%342 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %344 = bufferization.to_buffer %320 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %345 = bufferization.to_buffer %343 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_167 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_168 = memref.alloc() : memref<1x12x1xf32>
    %alloc_169 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_169[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %344[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %330[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %345[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %336[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_169[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_169[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_168[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_169[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_167[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %346 = bufferization.to_tensor %alloc_167 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_170 = tensor.collapse_shape %346 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %347 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_170, %arg56 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_171 = tensor.expand_shape %347 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %348 = tensor.empty() : tensor<1x1x1536xf32>
    %349 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%288, %expanded_171 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%348 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %350 = tensor.empty() : tensor<1x1x1536xf32>
    %351 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%349 : tensor<1x1x1536xf32>) outs(%350 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %352 = tensor.empty() : tensor<1x1xf32>
    %cst_172 = arith.constant 0.000000e+00 : f32
    %353 = linalg.fill ins(%cst_172 : f32) outs(%352 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_173 = linalg.reduce ins(%351 : tensor<1x1x1536xf32>) outs(%353 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_174 = tensor.expand_shape %reduced_173 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %354 = tensor.empty() : tensor<1x1x1xf32>
    %355 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_174, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%354 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %356 = tensor.empty() : tensor<1x1x1xf32>
    %357 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%355, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%356 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %358 = tensor.empty() : tensor<1x1x1xf32>
    %359 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%357 : tensor<1x1x1xf32>) outs(%358 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %360 = tensor.empty() : tensor<1x1x1536xf32>
    %361 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%349, %359 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%360 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_175 = tensor.expand_shape %arg57 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %362 = tensor.empty() : tensor<1x1x1536xf32>
    %363 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_175, %361 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%362 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_176 = tensor.collapse_shape %363 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %364 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_176, %arg58 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_177 = tensor.expand_shape %364 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %365 = tensor.empty() : tensor<1x1x8960xf32>
    %366 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_177 : tensor<1x1x8960xf32>) outs(%365 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %367 = tensor.empty() : tensor<1x1x8960xf32>
    %368 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_177, %366 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%367 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_178 = tensor.collapse_shape %363 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %369 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_178, %arg59 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_179 = tensor.expand_shape %369 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %370 = tensor.empty() : tensor<1x1x8960xf32>
    %371 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%368, %expanded_179 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%370 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_180 = tensor.collapse_shape %371 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %372 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_180, %arg60 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_181 = tensor.expand_shape %372 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %373 = tensor.empty() : tensor<1x1x1536xf32>
    %374 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%349, %expanded_181 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%373 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %375 = tensor.empty() : tensor<1x1x1536xf32>
    %376 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%374 : tensor<1x1x1536xf32>) outs(%375 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %377 = tensor.empty() : tensor<1x1xf32>
    %cst_182 = arith.constant 0.000000e+00 : f32
    %378 = linalg.fill ins(%cst_182 : f32) outs(%377 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_183 = linalg.reduce ins(%376 : tensor<1x1x1536xf32>) outs(%378 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_184 = tensor.expand_shape %reduced_183 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %379 = tensor.empty() : tensor<1x1x1xf32>
    %380 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_184, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%379 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %381 = tensor.empty() : tensor<1x1x1xf32>
    %382 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%380, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%381 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %383 = tensor.empty() : tensor<1x1x1xf32>
    %384 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%382 : tensor<1x1x1xf32>) outs(%383 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %385 = tensor.empty() : tensor<1x1x1536xf32>
    %386 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%374, %384 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%385 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_185 = tensor.expand_shape %arg61 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %387 = tensor.empty() : tensor<1x1x1536xf32>
    %388 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_185, %386 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%387 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_186 = tensor.collapse_shape %388 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %389 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_186, %arg63 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_187 = tensor.expand_shape %arg62 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %390 = tensor.empty() : tensor<1x1536xf32>
    %391 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_187, %389 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%390 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_188 = tensor.expand_shape %391 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_189 = tensor.collapse_shape %388 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %392 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_189, %arg65 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_190 = tensor.expand_shape %arg64 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %393 = tensor.empty() : tensor<1x256xf32>
    %394 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_190, %392 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%393 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_191 = tensor.expand_shape %394 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_192 = tensor.collapse_shape %388 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %395 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_192, %arg67 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_193 = tensor.expand_shape %arg66 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %396 = tensor.empty() : tensor<1x256xf32>
    %397 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_193, %395 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%396 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_194 = tensor.expand_shape %397 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_195 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_196 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %398 = tensor.empty() : tensor<1x12x1x128xf32>
    %399 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_188, %expanded_195 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%398 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_197 = tensor.extract_slice %expanded_188[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_198 = tensor.extract_slice %expanded_188[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %400 = tensor.empty() : tensor<1x12x1x64xf32>
    %401 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_198 : tensor<1x12x1x64xf32>) outs(%400 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %402 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_199 = tensor.insert_slice %401 into %402[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_200 = tensor.insert_slice %extracted_slice_197 into %inserted_slice_199[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %403 = tensor.empty() : tensor<1x12x1x128xf32>
    %404 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_200, %expanded_196 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%403 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %405 = tensor.empty() : tensor<1x12x1x128xf32>
    %406 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%399, %404 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%405 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %407 = tensor.empty() : tensor<1x2x1x128xf32>
    %408 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_191, %expanded_195 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%407 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_201 = tensor.extract_slice %expanded_191[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_202 = tensor.extract_slice %expanded_191[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %409 = tensor.empty() : tensor<1x2x1x64xf32>
    %410 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_202 : tensor<1x2x1x64xf32>) outs(%409 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %411 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_203 = tensor.insert_slice %410 into %411[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_204 = tensor.insert_slice %extracted_slice_201 into %inserted_slice_203[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %412 = tensor.empty() : tensor<1x2x1x128xf32>
    %413 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_204, %expanded_196 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%412 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %414 = tensor.empty() : tensor<1x2x1x128xf32>
    %415 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%408, %413 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%414 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %416 = bufferization.to_buffer %arg68 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_205 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %417 = tensor.empty() : tensor<1x2x1x128xi64>
    %418 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_205, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%417 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %419 = bufferization.to_buffer %418 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %420 = bufferization.to_buffer %415 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %420[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %419[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %416[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %421 = bufferization.to_tensor %416 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %422 = bufferization.to_buffer %arg69 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_206 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %423 = tensor.empty() : tensor<1x2x1x128xi64>
    %424 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_206, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%423 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %425 = bufferization.to_buffer %424 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %426 = bufferization.to_buffer %expanded_194 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %426[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %425[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %422[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %427 = bufferization.to_tensor %422 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_207 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %428 = tensor.empty() : tensor<1x1x1x1024xf32>
    %429 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_207, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%428 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %430 = bufferization.to_buffer %406 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %431 = bufferization.to_buffer %429 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_208 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_209 = memref.alloc() : memref<1x12x1xf32>
    %alloc_210 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_210[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %430[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %416[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %431[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %422[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_210[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_210[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_209[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_210[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_208[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %432 = bufferization.to_tensor %alloc_208 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_211 = tensor.collapse_shape %432 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %433 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_211, %arg70 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_212 = tensor.expand_shape %433 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %434 = tensor.empty() : tensor<1x1x1536xf32>
    %435 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%374, %expanded_212 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%434 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %436 = tensor.empty() : tensor<1x1x1536xf32>
    %437 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%435 : tensor<1x1x1536xf32>) outs(%436 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %438 = tensor.empty() : tensor<1x1xf32>
    %cst_213 = arith.constant 0.000000e+00 : f32
    %439 = linalg.fill ins(%cst_213 : f32) outs(%438 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_214 = linalg.reduce ins(%437 : tensor<1x1x1536xf32>) outs(%439 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_215 = tensor.expand_shape %reduced_214 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %440 = tensor.empty() : tensor<1x1x1xf32>
    %441 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_215, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%440 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %442 = tensor.empty() : tensor<1x1x1xf32>
    %443 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%441, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%442 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %444 = tensor.empty() : tensor<1x1x1xf32>
    %445 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%443 : tensor<1x1x1xf32>) outs(%444 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %446 = tensor.empty() : tensor<1x1x1536xf32>
    %447 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%435, %445 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%446 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_216 = tensor.expand_shape %arg71 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %448 = tensor.empty() : tensor<1x1x1536xf32>
    %449 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_216, %447 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%448 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_217 = tensor.collapse_shape %449 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %450 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_217, %arg72 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_218 = tensor.expand_shape %450 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %451 = tensor.empty() : tensor<1x1x8960xf32>
    %452 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_218 : tensor<1x1x8960xf32>) outs(%451 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %453 = tensor.empty() : tensor<1x1x8960xf32>
    %454 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_218, %452 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%453 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_219 = tensor.collapse_shape %449 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %455 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_219, %arg73 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_220 = tensor.expand_shape %455 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %456 = tensor.empty() : tensor<1x1x8960xf32>
    %457 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%454, %expanded_220 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%456 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_221 = tensor.collapse_shape %457 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %458 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_221, %arg74 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_222 = tensor.expand_shape %458 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %459 = tensor.empty() : tensor<1x1x1536xf32>
    %460 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%435, %expanded_222 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%459 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %461 = tensor.empty() : tensor<1x1x1536xf32>
    %462 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%460 : tensor<1x1x1536xf32>) outs(%461 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %463 = tensor.empty() : tensor<1x1xf32>
    %cst_223 = arith.constant 0.000000e+00 : f32
    %464 = linalg.fill ins(%cst_223 : f32) outs(%463 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_224 = linalg.reduce ins(%462 : tensor<1x1x1536xf32>) outs(%464 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_225 = tensor.expand_shape %reduced_224 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %465 = tensor.empty() : tensor<1x1x1xf32>
    %466 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_225, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%465 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %467 = tensor.empty() : tensor<1x1x1xf32>
    %468 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%466, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%467 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %469 = tensor.empty() : tensor<1x1x1xf32>
    %470 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%468 : tensor<1x1x1xf32>) outs(%469 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %471 = tensor.empty() : tensor<1x1x1536xf32>
    %472 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%460, %470 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%471 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_226 = tensor.expand_shape %arg75 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %473 = tensor.empty() : tensor<1x1x1536xf32>
    %474 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_226, %472 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%473 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_227 = tensor.collapse_shape %474 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %475 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_227, %arg77 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_228 = tensor.expand_shape %arg76 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %476 = tensor.empty() : tensor<1x1536xf32>
    %477 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_228, %475 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%476 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_229 = tensor.expand_shape %477 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_230 = tensor.collapse_shape %474 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %478 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_230, %arg79 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_231 = tensor.expand_shape %arg78 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %479 = tensor.empty() : tensor<1x256xf32>
    %480 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_231, %478 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%479 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_232 = tensor.expand_shape %480 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_233 = tensor.collapse_shape %474 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %481 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_233, %arg81 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_234 = tensor.expand_shape %arg80 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %482 = tensor.empty() : tensor<1x256xf32>
    %483 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_234, %481 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%482 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_235 = tensor.expand_shape %483 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_236 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_237 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %484 = tensor.empty() : tensor<1x12x1x128xf32>
    %485 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_229, %expanded_236 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%484 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_238 = tensor.extract_slice %expanded_229[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_239 = tensor.extract_slice %expanded_229[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %486 = tensor.empty() : tensor<1x12x1x64xf32>
    %487 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_239 : tensor<1x12x1x64xf32>) outs(%486 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %488 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_240 = tensor.insert_slice %487 into %488[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_241 = tensor.insert_slice %extracted_slice_238 into %inserted_slice_240[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %489 = tensor.empty() : tensor<1x12x1x128xf32>
    %490 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_241, %expanded_237 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%489 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %491 = tensor.empty() : tensor<1x12x1x128xf32>
    %492 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%485, %490 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%491 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %493 = tensor.empty() : tensor<1x2x1x128xf32>
    %494 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_232, %expanded_236 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%493 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_242 = tensor.extract_slice %expanded_232[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_243 = tensor.extract_slice %expanded_232[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %495 = tensor.empty() : tensor<1x2x1x64xf32>
    %496 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_243 : tensor<1x2x1x64xf32>) outs(%495 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %497 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_244 = tensor.insert_slice %496 into %497[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_245 = tensor.insert_slice %extracted_slice_242 into %inserted_slice_244[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %498 = tensor.empty() : tensor<1x2x1x128xf32>
    %499 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_245, %expanded_237 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%498 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %500 = tensor.empty() : tensor<1x2x1x128xf32>
    %501 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%494, %499 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%500 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %502 = bufferization.to_buffer %arg82 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_246 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %503 = tensor.empty() : tensor<1x2x1x128xi64>
    %504 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_246, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%503 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %505 = bufferization.to_buffer %504 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %506 = bufferization.to_buffer %501 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %506[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %505[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %502[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %507 = bufferization.to_tensor %502 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %508 = bufferization.to_buffer %arg83 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_247 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %509 = tensor.empty() : tensor<1x2x1x128xi64>
    %510 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_247, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%509 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %511 = bufferization.to_buffer %510 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %512 = bufferization.to_buffer %expanded_235 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %512[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %511[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %508[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %513 = bufferization.to_tensor %508 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_248 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %514 = tensor.empty() : tensor<1x1x1x1024xf32>
    %515 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_248, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%514 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %516 = bufferization.to_buffer %492 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %517 = bufferization.to_buffer %515 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_249 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_250 = memref.alloc() : memref<1x12x1xf32>
    %alloc_251 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_251[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %516[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %502[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %517[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %508[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_251[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_251[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_250[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_251[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_249[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %518 = bufferization.to_tensor %alloc_249 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_252 = tensor.collapse_shape %518 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %519 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_252, %arg84 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_253 = tensor.expand_shape %519 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %520 = tensor.empty() : tensor<1x1x1536xf32>
    %521 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%460, %expanded_253 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%520 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %522 = tensor.empty() : tensor<1x1x1536xf32>
    %523 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%521 : tensor<1x1x1536xf32>) outs(%522 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %524 = tensor.empty() : tensor<1x1xf32>
    %cst_254 = arith.constant 0.000000e+00 : f32
    %525 = linalg.fill ins(%cst_254 : f32) outs(%524 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_255 = linalg.reduce ins(%523 : tensor<1x1x1536xf32>) outs(%525 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_256 = tensor.expand_shape %reduced_255 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %526 = tensor.empty() : tensor<1x1x1xf32>
    %527 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_256, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%526 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %528 = tensor.empty() : tensor<1x1x1xf32>
    %529 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%527, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%528 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %530 = tensor.empty() : tensor<1x1x1xf32>
    %531 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%529 : tensor<1x1x1xf32>) outs(%530 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %532 = tensor.empty() : tensor<1x1x1536xf32>
    %533 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%521, %531 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%532 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_257 = tensor.expand_shape %arg85 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %534 = tensor.empty() : tensor<1x1x1536xf32>
    %535 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_257, %533 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%534 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_258 = tensor.collapse_shape %535 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %536 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_258, %arg86 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_259 = tensor.expand_shape %536 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %537 = tensor.empty() : tensor<1x1x8960xf32>
    %538 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_259 : tensor<1x1x8960xf32>) outs(%537 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %539 = tensor.empty() : tensor<1x1x8960xf32>
    %540 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_259, %538 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%539 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_260 = tensor.collapse_shape %535 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %541 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_260, %arg87 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_261 = tensor.expand_shape %541 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %542 = tensor.empty() : tensor<1x1x8960xf32>
    %543 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%540, %expanded_261 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%542 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_262 = tensor.collapse_shape %543 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %544 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_262, %arg88 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_263 = tensor.expand_shape %544 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %545 = tensor.empty() : tensor<1x1x1536xf32>
    %546 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%521, %expanded_263 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%545 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %547 = tensor.empty() : tensor<1x1x1536xf32>
    %548 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%546 : tensor<1x1x1536xf32>) outs(%547 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %549 = tensor.empty() : tensor<1x1xf32>
    %cst_264 = arith.constant 0.000000e+00 : f32
    %550 = linalg.fill ins(%cst_264 : f32) outs(%549 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_265 = linalg.reduce ins(%548 : tensor<1x1x1536xf32>) outs(%550 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_266 = tensor.expand_shape %reduced_265 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %551 = tensor.empty() : tensor<1x1x1xf32>
    %552 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_266, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%551 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %553 = tensor.empty() : tensor<1x1x1xf32>
    %554 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%552, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%553 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %555 = tensor.empty() : tensor<1x1x1xf32>
    %556 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%554 : tensor<1x1x1xf32>) outs(%555 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %557 = tensor.empty() : tensor<1x1x1536xf32>
    %558 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%546, %556 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%557 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_267 = tensor.expand_shape %arg89 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %559 = tensor.empty() : tensor<1x1x1536xf32>
    %560 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_267, %558 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%559 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_268 = tensor.collapse_shape %560 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %561 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_268, %arg91 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_269 = tensor.expand_shape %arg90 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %562 = tensor.empty() : tensor<1x1536xf32>
    %563 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_269, %561 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%562 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_270 = tensor.expand_shape %563 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_271 = tensor.collapse_shape %560 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %564 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_271, %arg93 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_272 = tensor.expand_shape %arg92 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %565 = tensor.empty() : tensor<1x256xf32>
    %566 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_272, %564 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%565 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_273 = tensor.expand_shape %566 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_274 = tensor.collapse_shape %560 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %567 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_274, %arg95 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_275 = tensor.expand_shape %arg94 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %568 = tensor.empty() : tensor<1x256xf32>
    %569 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_275, %567 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%568 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_276 = tensor.expand_shape %569 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_277 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_278 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %570 = tensor.empty() : tensor<1x12x1x128xf32>
    %571 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_270, %expanded_277 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%570 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_279 = tensor.extract_slice %expanded_270[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_280 = tensor.extract_slice %expanded_270[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %572 = tensor.empty() : tensor<1x12x1x64xf32>
    %573 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_280 : tensor<1x12x1x64xf32>) outs(%572 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %574 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_281 = tensor.insert_slice %573 into %574[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_282 = tensor.insert_slice %extracted_slice_279 into %inserted_slice_281[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %575 = tensor.empty() : tensor<1x12x1x128xf32>
    %576 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_282, %expanded_278 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%575 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %577 = tensor.empty() : tensor<1x12x1x128xf32>
    %578 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%571, %576 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%577 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %579 = tensor.empty() : tensor<1x2x1x128xf32>
    %580 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_273, %expanded_277 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%579 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_283 = tensor.extract_slice %expanded_273[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_284 = tensor.extract_slice %expanded_273[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %581 = tensor.empty() : tensor<1x2x1x64xf32>
    %582 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_284 : tensor<1x2x1x64xf32>) outs(%581 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %583 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_285 = tensor.insert_slice %582 into %583[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_286 = tensor.insert_slice %extracted_slice_283 into %inserted_slice_285[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %584 = tensor.empty() : tensor<1x2x1x128xf32>
    %585 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_286, %expanded_278 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%584 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %586 = tensor.empty() : tensor<1x2x1x128xf32>
    %587 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%580, %585 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%586 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %588 = bufferization.to_buffer %arg96 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_287 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %589 = tensor.empty() : tensor<1x2x1x128xi64>
    %590 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_287, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%589 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %591 = bufferization.to_buffer %590 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %592 = bufferization.to_buffer %587 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %592[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %591[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %588[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %593 = bufferization.to_tensor %588 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %594 = bufferization.to_buffer %arg97 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_288 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %595 = tensor.empty() : tensor<1x2x1x128xi64>
    %596 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_288, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%595 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %597 = bufferization.to_buffer %596 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %598 = bufferization.to_buffer %expanded_276 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %598[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %597[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %594[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %599 = bufferization.to_tensor %594 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_289 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %600 = tensor.empty() : tensor<1x1x1x1024xf32>
    %601 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_289, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%600 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %602 = bufferization.to_buffer %578 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %603 = bufferization.to_buffer %601 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_290 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_291 = memref.alloc() : memref<1x12x1xf32>
    %alloc_292 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_292[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %602[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %588[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %603[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %594[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_292[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_292[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_291[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_292[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_290[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %604 = bufferization.to_tensor %alloc_290 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_293 = tensor.collapse_shape %604 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %605 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_293, %arg98 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_294 = tensor.expand_shape %605 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %606 = tensor.empty() : tensor<1x1x1536xf32>
    %607 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%546, %expanded_294 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%606 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %608 = tensor.empty() : tensor<1x1x1536xf32>
    %609 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%607 : tensor<1x1x1536xf32>) outs(%608 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %610 = tensor.empty() : tensor<1x1xf32>
    %cst_295 = arith.constant 0.000000e+00 : f32
    %611 = linalg.fill ins(%cst_295 : f32) outs(%610 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_296 = linalg.reduce ins(%609 : tensor<1x1x1536xf32>) outs(%611 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_297 = tensor.expand_shape %reduced_296 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %612 = tensor.empty() : tensor<1x1x1xf32>
    %613 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_297, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%612 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %614 = tensor.empty() : tensor<1x1x1xf32>
    %615 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%613, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%614 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %616 = tensor.empty() : tensor<1x1x1xf32>
    %617 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%615 : tensor<1x1x1xf32>) outs(%616 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %618 = tensor.empty() : tensor<1x1x1536xf32>
    %619 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%607, %617 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%618 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_298 = tensor.expand_shape %arg99 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %620 = tensor.empty() : tensor<1x1x1536xf32>
    %621 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_298, %619 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%620 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_299 = tensor.collapse_shape %621 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %622 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_299, %arg100 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_300 = tensor.expand_shape %622 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %623 = tensor.empty() : tensor<1x1x8960xf32>
    %624 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_300 : tensor<1x1x8960xf32>) outs(%623 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %625 = tensor.empty() : tensor<1x1x8960xf32>
    %626 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_300, %624 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%625 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_301 = tensor.collapse_shape %621 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %627 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_301, %arg101 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_302 = tensor.expand_shape %627 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %628 = tensor.empty() : tensor<1x1x8960xf32>
    %629 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%626, %expanded_302 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%628 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_303 = tensor.collapse_shape %629 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %630 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_303, %arg102 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_304 = tensor.expand_shape %630 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %631 = tensor.empty() : tensor<1x1x1536xf32>
    %632 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%607, %expanded_304 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%631 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %633 = tensor.empty() : tensor<1x1x1536xf32>
    %634 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%632 : tensor<1x1x1536xf32>) outs(%633 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %635 = tensor.empty() : tensor<1x1xf32>
    %cst_305 = arith.constant 0.000000e+00 : f32
    %636 = linalg.fill ins(%cst_305 : f32) outs(%635 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_306 = linalg.reduce ins(%634 : tensor<1x1x1536xf32>) outs(%636 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_307 = tensor.expand_shape %reduced_306 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %637 = tensor.empty() : tensor<1x1x1xf32>
    %638 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_307, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%637 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %639 = tensor.empty() : tensor<1x1x1xf32>
    %640 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%638, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%639 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %641 = tensor.empty() : tensor<1x1x1xf32>
    %642 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%640 : tensor<1x1x1xf32>) outs(%641 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %643 = tensor.empty() : tensor<1x1x1536xf32>
    %644 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%632, %642 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%643 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_308 = tensor.expand_shape %arg103 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %645 = tensor.empty() : tensor<1x1x1536xf32>
    %646 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_308, %644 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%645 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_309 = tensor.collapse_shape %646 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %647 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_309, %arg105 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_310 = tensor.expand_shape %arg104 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %648 = tensor.empty() : tensor<1x1536xf32>
    %649 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_310, %647 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%648 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_311 = tensor.expand_shape %649 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_312 = tensor.collapse_shape %646 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %650 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_312, %arg107 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_313 = tensor.expand_shape %arg106 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %651 = tensor.empty() : tensor<1x256xf32>
    %652 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_313, %650 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%651 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_314 = tensor.expand_shape %652 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_315 = tensor.collapse_shape %646 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %653 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_315, %arg109 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_316 = tensor.expand_shape %arg108 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %654 = tensor.empty() : tensor<1x256xf32>
    %655 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_316, %653 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%654 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_317 = tensor.expand_shape %655 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_318 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_319 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %656 = tensor.empty() : tensor<1x12x1x128xf32>
    %657 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_311, %expanded_318 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%656 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_320 = tensor.extract_slice %expanded_311[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_321 = tensor.extract_slice %expanded_311[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %658 = tensor.empty() : tensor<1x12x1x64xf32>
    %659 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_321 : tensor<1x12x1x64xf32>) outs(%658 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %660 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_322 = tensor.insert_slice %659 into %660[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_323 = tensor.insert_slice %extracted_slice_320 into %inserted_slice_322[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %661 = tensor.empty() : tensor<1x12x1x128xf32>
    %662 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_323, %expanded_319 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%661 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %663 = tensor.empty() : tensor<1x12x1x128xf32>
    %664 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%657, %662 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%663 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %665 = tensor.empty() : tensor<1x2x1x128xf32>
    %666 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_314, %expanded_318 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%665 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_324 = tensor.extract_slice %expanded_314[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_325 = tensor.extract_slice %expanded_314[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %667 = tensor.empty() : tensor<1x2x1x64xf32>
    %668 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_325 : tensor<1x2x1x64xf32>) outs(%667 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %669 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_326 = tensor.insert_slice %668 into %669[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_327 = tensor.insert_slice %extracted_slice_324 into %inserted_slice_326[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %670 = tensor.empty() : tensor<1x2x1x128xf32>
    %671 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_327, %expanded_319 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%670 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %672 = tensor.empty() : tensor<1x2x1x128xf32>
    %673 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%666, %671 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%672 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %674 = bufferization.to_buffer %arg110 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_328 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %675 = tensor.empty() : tensor<1x2x1x128xi64>
    %676 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_328, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%675 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %677 = bufferization.to_buffer %676 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %678 = bufferization.to_buffer %673 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %678[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %677[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %674[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %679 = bufferization.to_tensor %674 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %680 = bufferization.to_buffer %arg111 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_329 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %681 = tensor.empty() : tensor<1x2x1x128xi64>
    %682 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_329, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%681 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %683 = bufferization.to_buffer %682 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %684 = bufferization.to_buffer %expanded_317 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %684[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %683[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %680[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %685 = bufferization.to_tensor %680 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_330 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %686 = tensor.empty() : tensor<1x1x1x1024xf32>
    %687 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_330, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%686 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %688 = bufferization.to_buffer %664 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %689 = bufferization.to_buffer %687 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_331 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_332 = memref.alloc() : memref<1x12x1xf32>
    %alloc_333 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_333[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %688[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %674[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %689[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %680[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_333[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_333[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_332[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_333[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_331[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %690 = bufferization.to_tensor %alloc_331 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_334 = tensor.collapse_shape %690 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %691 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_334, %arg112 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_335 = tensor.expand_shape %691 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %692 = tensor.empty() : tensor<1x1x1536xf32>
    %693 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%632, %expanded_335 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%692 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %694 = tensor.empty() : tensor<1x1x1536xf32>
    %695 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%693 : tensor<1x1x1536xf32>) outs(%694 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %696 = tensor.empty() : tensor<1x1xf32>
    %cst_336 = arith.constant 0.000000e+00 : f32
    %697 = linalg.fill ins(%cst_336 : f32) outs(%696 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_337 = linalg.reduce ins(%695 : tensor<1x1x1536xf32>) outs(%697 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_338 = tensor.expand_shape %reduced_337 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %698 = tensor.empty() : tensor<1x1x1xf32>
    %699 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_338, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%698 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %700 = tensor.empty() : tensor<1x1x1xf32>
    %701 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%699, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%700 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %702 = tensor.empty() : tensor<1x1x1xf32>
    %703 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%701 : tensor<1x1x1xf32>) outs(%702 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %704 = tensor.empty() : tensor<1x1x1536xf32>
    %705 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%693, %703 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%704 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_339 = tensor.expand_shape %arg113 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %706 = tensor.empty() : tensor<1x1x1536xf32>
    %707 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_339, %705 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%706 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_340 = tensor.collapse_shape %707 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %708 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_340, %arg114 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_341 = tensor.expand_shape %708 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %709 = tensor.empty() : tensor<1x1x8960xf32>
    %710 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_341 : tensor<1x1x8960xf32>) outs(%709 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %711 = tensor.empty() : tensor<1x1x8960xf32>
    %712 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_341, %710 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%711 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_342 = tensor.collapse_shape %707 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %713 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_342, %arg115 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_343 = tensor.expand_shape %713 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %714 = tensor.empty() : tensor<1x1x8960xf32>
    %715 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%712, %expanded_343 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%714 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_344 = tensor.collapse_shape %715 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %716 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_344, %arg116 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_345 = tensor.expand_shape %716 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %717 = tensor.empty() : tensor<1x1x1536xf32>
    %718 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%693, %expanded_345 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%717 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %719 = tensor.empty() : tensor<1x1x1536xf32>
    %720 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%718 : tensor<1x1x1536xf32>) outs(%719 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %721 = tensor.empty() : tensor<1x1xf32>
    %cst_346 = arith.constant 0.000000e+00 : f32
    %722 = linalg.fill ins(%cst_346 : f32) outs(%721 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_347 = linalg.reduce ins(%720 : tensor<1x1x1536xf32>) outs(%722 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_348 = tensor.expand_shape %reduced_347 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %723 = tensor.empty() : tensor<1x1x1xf32>
    %724 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_348, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%723 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %725 = tensor.empty() : tensor<1x1x1xf32>
    %726 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%724, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%725 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %727 = tensor.empty() : tensor<1x1x1xf32>
    %728 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%726 : tensor<1x1x1xf32>) outs(%727 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %729 = tensor.empty() : tensor<1x1x1536xf32>
    %730 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%718, %728 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%729 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_349 = tensor.expand_shape %arg117 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %731 = tensor.empty() : tensor<1x1x1536xf32>
    %732 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_349, %730 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%731 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_350 = tensor.collapse_shape %732 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %733 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_350, %arg119 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_351 = tensor.expand_shape %arg118 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %734 = tensor.empty() : tensor<1x1536xf32>
    %735 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_351, %733 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%734 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_352 = tensor.expand_shape %735 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_353 = tensor.collapse_shape %732 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %736 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_353, %arg121 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_354 = tensor.expand_shape %arg120 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %737 = tensor.empty() : tensor<1x256xf32>
    %738 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_354, %736 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%737 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_355 = tensor.expand_shape %738 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_356 = tensor.collapse_shape %732 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %739 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_356, %arg123 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_357 = tensor.expand_shape %arg122 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %740 = tensor.empty() : tensor<1x256xf32>
    %741 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_357, %739 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%740 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_358 = tensor.expand_shape %741 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_359 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_360 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %742 = tensor.empty() : tensor<1x12x1x128xf32>
    %743 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_352, %expanded_359 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%742 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_361 = tensor.extract_slice %expanded_352[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_362 = tensor.extract_slice %expanded_352[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %744 = tensor.empty() : tensor<1x12x1x64xf32>
    %745 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_362 : tensor<1x12x1x64xf32>) outs(%744 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %746 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_363 = tensor.insert_slice %745 into %746[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_364 = tensor.insert_slice %extracted_slice_361 into %inserted_slice_363[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %747 = tensor.empty() : tensor<1x12x1x128xf32>
    %748 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_364, %expanded_360 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%747 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %749 = tensor.empty() : tensor<1x12x1x128xf32>
    %750 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%743, %748 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%749 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %751 = tensor.empty() : tensor<1x2x1x128xf32>
    %752 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_355, %expanded_359 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%751 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_365 = tensor.extract_slice %expanded_355[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_366 = tensor.extract_slice %expanded_355[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %753 = tensor.empty() : tensor<1x2x1x64xf32>
    %754 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_366 : tensor<1x2x1x64xf32>) outs(%753 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %755 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_367 = tensor.insert_slice %754 into %755[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_368 = tensor.insert_slice %extracted_slice_365 into %inserted_slice_367[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %756 = tensor.empty() : tensor<1x2x1x128xf32>
    %757 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_368, %expanded_360 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%756 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %758 = tensor.empty() : tensor<1x2x1x128xf32>
    %759 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%752, %757 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%758 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %760 = bufferization.to_buffer %arg124 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_369 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %761 = tensor.empty() : tensor<1x2x1x128xi64>
    %762 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_369, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%761 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %763 = bufferization.to_buffer %762 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %764 = bufferization.to_buffer %759 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %764[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %763[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %760[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %765 = bufferization.to_tensor %760 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %766 = bufferization.to_buffer %arg125 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_370 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %767 = tensor.empty() : tensor<1x2x1x128xi64>
    %768 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_370, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%767 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %769 = bufferization.to_buffer %768 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %770 = bufferization.to_buffer %expanded_358 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %770[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %769[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %766[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %771 = bufferization.to_tensor %766 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_371 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %772 = tensor.empty() : tensor<1x1x1x1024xf32>
    %773 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_371, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%772 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %774 = bufferization.to_buffer %750 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %775 = bufferization.to_buffer %773 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_372 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_373 = memref.alloc() : memref<1x12x1xf32>
    %alloc_374 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_374[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %774[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %760[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %775[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %766[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_374[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_374[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_373[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_374[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_372[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %776 = bufferization.to_tensor %alloc_372 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_375 = tensor.collapse_shape %776 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %777 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_375, %arg126 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_376 = tensor.expand_shape %777 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %778 = tensor.empty() : tensor<1x1x1536xf32>
    %779 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%718, %expanded_376 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%778 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %780 = tensor.empty() : tensor<1x1x1536xf32>
    %781 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%779 : tensor<1x1x1536xf32>) outs(%780 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %782 = tensor.empty() : tensor<1x1xf32>
    %cst_377 = arith.constant 0.000000e+00 : f32
    %783 = linalg.fill ins(%cst_377 : f32) outs(%782 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_378 = linalg.reduce ins(%781 : tensor<1x1x1536xf32>) outs(%783 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_379 = tensor.expand_shape %reduced_378 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %784 = tensor.empty() : tensor<1x1x1xf32>
    %785 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_379, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%784 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %786 = tensor.empty() : tensor<1x1x1xf32>
    %787 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%785, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%786 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %788 = tensor.empty() : tensor<1x1x1xf32>
    %789 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%787 : tensor<1x1x1xf32>) outs(%788 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %790 = tensor.empty() : tensor<1x1x1536xf32>
    %791 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%779, %789 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%790 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_380 = tensor.expand_shape %arg127 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %792 = tensor.empty() : tensor<1x1x1536xf32>
    %793 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_380, %791 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%792 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_381 = tensor.collapse_shape %793 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %794 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_381, %arg128 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_382 = tensor.expand_shape %794 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %795 = tensor.empty() : tensor<1x1x8960xf32>
    %796 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_382 : tensor<1x1x8960xf32>) outs(%795 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %797 = tensor.empty() : tensor<1x1x8960xf32>
    %798 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_382, %796 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%797 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_383 = tensor.collapse_shape %793 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %799 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_383, %arg129 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_384 = tensor.expand_shape %799 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %800 = tensor.empty() : tensor<1x1x8960xf32>
    %801 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%798, %expanded_384 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%800 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_385 = tensor.collapse_shape %801 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %802 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_385, %arg130 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_386 = tensor.expand_shape %802 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %803 = tensor.empty() : tensor<1x1x1536xf32>
    %804 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%779, %expanded_386 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%803 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %805 = tensor.empty() : tensor<1x1x1536xf32>
    %806 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%804 : tensor<1x1x1536xf32>) outs(%805 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %807 = tensor.empty() : tensor<1x1xf32>
    %cst_387 = arith.constant 0.000000e+00 : f32
    %808 = linalg.fill ins(%cst_387 : f32) outs(%807 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_388 = linalg.reduce ins(%806 : tensor<1x1x1536xf32>) outs(%808 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_389 = tensor.expand_shape %reduced_388 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %809 = tensor.empty() : tensor<1x1x1xf32>
    %810 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_389, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%809 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %811 = tensor.empty() : tensor<1x1x1xf32>
    %812 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%810, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%811 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %813 = tensor.empty() : tensor<1x1x1xf32>
    %814 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%812 : tensor<1x1x1xf32>) outs(%813 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %815 = tensor.empty() : tensor<1x1x1536xf32>
    %816 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%804, %814 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%815 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_390 = tensor.expand_shape %arg131 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %817 = tensor.empty() : tensor<1x1x1536xf32>
    %818 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_390, %816 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%817 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_391 = tensor.collapse_shape %818 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %819 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_391, %arg133 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_392 = tensor.expand_shape %arg132 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %820 = tensor.empty() : tensor<1x1536xf32>
    %821 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_392, %819 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%820 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_393 = tensor.expand_shape %821 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_394 = tensor.collapse_shape %818 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %822 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_394, %arg135 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_395 = tensor.expand_shape %arg134 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %823 = tensor.empty() : tensor<1x256xf32>
    %824 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_395, %822 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%823 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_396 = tensor.expand_shape %824 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_397 = tensor.collapse_shape %818 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %825 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_397, %arg137 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_398 = tensor.expand_shape %arg136 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %826 = tensor.empty() : tensor<1x256xf32>
    %827 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_398, %825 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%826 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_399 = tensor.expand_shape %827 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_400 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_401 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %828 = tensor.empty() : tensor<1x12x1x128xf32>
    %829 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_393, %expanded_400 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%828 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_402 = tensor.extract_slice %expanded_393[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_403 = tensor.extract_slice %expanded_393[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %830 = tensor.empty() : tensor<1x12x1x64xf32>
    %831 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_403 : tensor<1x12x1x64xf32>) outs(%830 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %832 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_404 = tensor.insert_slice %831 into %832[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_405 = tensor.insert_slice %extracted_slice_402 into %inserted_slice_404[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %833 = tensor.empty() : tensor<1x12x1x128xf32>
    %834 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_405, %expanded_401 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%833 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %835 = tensor.empty() : tensor<1x12x1x128xf32>
    %836 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%829, %834 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%835 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %837 = tensor.empty() : tensor<1x2x1x128xf32>
    %838 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_396, %expanded_400 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%837 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_406 = tensor.extract_slice %expanded_396[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_407 = tensor.extract_slice %expanded_396[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %839 = tensor.empty() : tensor<1x2x1x64xf32>
    %840 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_407 : tensor<1x2x1x64xf32>) outs(%839 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %841 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_408 = tensor.insert_slice %840 into %841[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_409 = tensor.insert_slice %extracted_slice_406 into %inserted_slice_408[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %842 = tensor.empty() : tensor<1x2x1x128xf32>
    %843 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_409, %expanded_401 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%842 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %844 = tensor.empty() : tensor<1x2x1x128xf32>
    %845 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%838, %843 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%844 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %846 = bufferization.to_buffer %arg138 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_410 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %847 = tensor.empty() : tensor<1x2x1x128xi64>
    %848 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_410, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%847 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %849 = bufferization.to_buffer %848 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %850 = bufferization.to_buffer %845 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %850[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %849[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %846[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %851 = bufferization.to_tensor %846 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %852 = bufferization.to_buffer %arg139 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_411 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %853 = tensor.empty() : tensor<1x2x1x128xi64>
    %854 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_411, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%853 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %855 = bufferization.to_buffer %854 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %856 = bufferization.to_buffer %expanded_399 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %856[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %855[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %852[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %857 = bufferization.to_tensor %852 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_412 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %858 = tensor.empty() : tensor<1x1x1x1024xf32>
    %859 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_412, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%858 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %860 = bufferization.to_buffer %836 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %861 = bufferization.to_buffer %859 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_413 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_414 = memref.alloc() : memref<1x12x1xf32>
    %alloc_415 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_415[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %860[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %846[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %861[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %852[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_415[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_415[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_414[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_415[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_413[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %862 = bufferization.to_tensor %alloc_413 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_416 = tensor.collapse_shape %862 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %863 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_416, %arg140 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_417 = tensor.expand_shape %863 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %864 = tensor.empty() : tensor<1x1x1536xf32>
    %865 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%804, %expanded_417 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%864 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %866 = tensor.empty() : tensor<1x1x1536xf32>
    %867 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%865 : tensor<1x1x1536xf32>) outs(%866 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %868 = tensor.empty() : tensor<1x1xf32>
    %cst_418 = arith.constant 0.000000e+00 : f32
    %869 = linalg.fill ins(%cst_418 : f32) outs(%868 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_419 = linalg.reduce ins(%867 : tensor<1x1x1536xf32>) outs(%869 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_420 = tensor.expand_shape %reduced_419 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %870 = tensor.empty() : tensor<1x1x1xf32>
    %871 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_420, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%870 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %872 = tensor.empty() : tensor<1x1x1xf32>
    %873 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%871, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%872 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %874 = tensor.empty() : tensor<1x1x1xf32>
    %875 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%873 : tensor<1x1x1xf32>) outs(%874 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %876 = tensor.empty() : tensor<1x1x1536xf32>
    %877 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%865, %875 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%876 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_421 = tensor.expand_shape %arg141 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %878 = tensor.empty() : tensor<1x1x1536xf32>
    %879 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_421, %877 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%878 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_422 = tensor.collapse_shape %879 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %880 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_422, %arg142 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_423 = tensor.expand_shape %880 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %881 = tensor.empty() : tensor<1x1x8960xf32>
    %882 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_423 : tensor<1x1x8960xf32>) outs(%881 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %883 = tensor.empty() : tensor<1x1x8960xf32>
    %884 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_423, %882 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%883 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_424 = tensor.collapse_shape %879 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %885 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_424, %arg143 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_425 = tensor.expand_shape %885 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %886 = tensor.empty() : tensor<1x1x8960xf32>
    %887 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%884, %expanded_425 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%886 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_426 = tensor.collapse_shape %887 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %888 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_426, %arg144 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_427 = tensor.expand_shape %888 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %889 = tensor.empty() : tensor<1x1x1536xf32>
    %890 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%865, %expanded_427 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%889 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %891 = tensor.empty() : tensor<1x1x1536xf32>
    %892 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%890 : tensor<1x1x1536xf32>) outs(%891 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %893 = tensor.empty() : tensor<1x1xf32>
    %cst_428 = arith.constant 0.000000e+00 : f32
    %894 = linalg.fill ins(%cst_428 : f32) outs(%893 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_429 = linalg.reduce ins(%892 : tensor<1x1x1536xf32>) outs(%894 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_430 = tensor.expand_shape %reduced_429 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %895 = tensor.empty() : tensor<1x1x1xf32>
    %896 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_430, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%895 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %897 = tensor.empty() : tensor<1x1x1xf32>
    %898 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%896, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%897 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %899 = tensor.empty() : tensor<1x1x1xf32>
    %900 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%898 : tensor<1x1x1xf32>) outs(%899 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %901 = tensor.empty() : tensor<1x1x1536xf32>
    %902 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%890, %900 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%901 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_431 = tensor.expand_shape %arg145 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %903 = tensor.empty() : tensor<1x1x1536xf32>
    %904 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_431, %902 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%903 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_432 = tensor.collapse_shape %904 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %905 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_432, %arg147 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_433 = tensor.expand_shape %arg146 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %906 = tensor.empty() : tensor<1x1536xf32>
    %907 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_433, %905 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%906 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_434 = tensor.expand_shape %907 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_435 = tensor.collapse_shape %904 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %908 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_435, %arg149 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_436 = tensor.expand_shape %arg148 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %909 = tensor.empty() : tensor<1x256xf32>
    %910 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_436, %908 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%909 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_437 = tensor.expand_shape %910 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_438 = tensor.collapse_shape %904 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %911 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_438, %arg151 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_439 = tensor.expand_shape %arg150 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %912 = tensor.empty() : tensor<1x256xf32>
    %913 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_439, %911 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%912 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_440 = tensor.expand_shape %913 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_441 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_442 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %914 = tensor.empty() : tensor<1x12x1x128xf32>
    %915 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_434, %expanded_441 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%914 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_443 = tensor.extract_slice %expanded_434[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_444 = tensor.extract_slice %expanded_434[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %916 = tensor.empty() : tensor<1x12x1x64xf32>
    %917 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_444 : tensor<1x12x1x64xf32>) outs(%916 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %918 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_445 = tensor.insert_slice %917 into %918[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_446 = tensor.insert_slice %extracted_slice_443 into %inserted_slice_445[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %919 = tensor.empty() : tensor<1x12x1x128xf32>
    %920 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_446, %expanded_442 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%919 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %921 = tensor.empty() : tensor<1x12x1x128xf32>
    %922 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%915, %920 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%921 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %923 = tensor.empty() : tensor<1x2x1x128xf32>
    %924 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_437, %expanded_441 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%923 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_447 = tensor.extract_slice %expanded_437[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_448 = tensor.extract_slice %expanded_437[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %925 = tensor.empty() : tensor<1x2x1x64xf32>
    %926 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_448 : tensor<1x2x1x64xf32>) outs(%925 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %927 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_449 = tensor.insert_slice %926 into %927[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_450 = tensor.insert_slice %extracted_slice_447 into %inserted_slice_449[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %928 = tensor.empty() : tensor<1x2x1x128xf32>
    %929 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_450, %expanded_442 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%928 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %930 = tensor.empty() : tensor<1x2x1x128xf32>
    %931 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%924, %929 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%930 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %932 = bufferization.to_buffer %arg152 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_451 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %933 = tensor.empty() : tensor<1x2x1x128xi64>
    %934 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_451, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%933 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %935 = bufferization.to_buffer %934 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %936 = bufferization.to_buffer %931 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %936[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %935[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %932[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %937 = bufferization.to_tensor %932 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %938 = bufferization.to_buffer %arg153 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_452 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %939 = tensor.empty() : tensor<1x2x1x128xi64>
    %940 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_452, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%939 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %941 = bufferization.to_buffer %940 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %942 = bufferization.to_buffer %expanded_440 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %942[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %941[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %938[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %943 = bufferization.to_tensor %938 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_453 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %944 = tensor.empty() : tensor<1x1x1x1024xf32>
    %945 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_453, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%944 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %946 = bufferization.to_buffer %922 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %947 = bufferization.to_buffer %945 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_454 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_455 = memref.alloc() : memref<1x12x1xf32>
    %alloc_456 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_456[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %946[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %932[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %947[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %938[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_456[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_456[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_455[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_456[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_454[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %948 = bufferization.to_tensor %alloc_454 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_457 = tensor.collapse_shape %948 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %949 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_457, %arg154 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_458 = tensor.expand_shape %949 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %950 = tensor.empty() : tensor<1x1x1536xf32>
    %951 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%890, %expanded_458 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%950 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %952 = tensor.empty() : tensor<1x1x1536xf32>
    %953 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%951 : tensor<1x1x1536xf32>) outs(%952 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %954 = tensor.empty() : tensor<1x1xf32>
    %cst_459 = arith.constant 0.000000e+00 : f32
    %955 = linalg.fill ins(%cst_459 : f32) outs(%954 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_460 = linalg.reduce ins(%953 : tensor<1x1x1536xf32>) outs(%955 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_461 = tensor.expand_shape %reduced_460 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %956 = tensor.empty() : tensor<1x1x1xf32>
    %957 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_461, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%956 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %958 = tensor.empty() : tensor<1x1x1xf32>
    %959 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%957, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%958 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %960 = tensor.empty() : tensor<1x1x1xf32>
    %961 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%959 : tensor<1x1x1xf32>) outs(%960 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %962 = tensor.empty() : tensor<1x1x1536xf32>
    %963 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%951, %961 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%962 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_462 = tensor.expand_shape %arg155 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %964 = tensor.empty() : tensor<1x1x1536xf32>
    %965 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_462, %963 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%964 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_463 = tensor.collapse_shape %965 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %966 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_463, %arg156 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_464 = tensor.expand_shape %966 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %967 = tensor.empty() : tensor<1x1x8960xf32>
    %968 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_464 : tensor<1x1x8960xf32>) outs(%967 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %969 = tensor.empty() : tensor<1x1x8960xf32>
    %970 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_464, %968 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%969 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_465 = tensor.collapse_shape %965 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %971 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_465, %arg157 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_466 = tensor.expand_shape %971 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %972 = tensor.empty() : tensor<1x1x8960xf32>
    %973 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%970, %expanded_466 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%972 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_467 = tensor.collapse_shape %973 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %974 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_467, %arg158 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_468 = tensor.expand_shape %974 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %975 = tensor.empty() : tensor<1x1x1536xf32>
    %976 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%951, %expanded_468 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%975 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %977 = tensor.empty() : tensor<1x1x1536xf32>
    %978 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%976 : tensor<1x1x1536xf32>) outs(%977 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %979 = tensor.empty() : tensor<1x1xf32>
    %cst_469 = arith.constant 0.000000e+00 : f32
    %980 = linalg.fill ins(%cst_469 : f32) outs(%979 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_470 = linalg.reduce ins(%978 : tensor<1x1x1536xf32>) outs(%980 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_471 = tensor.expand_shape %reduced_470 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %981 = tensor.empty() : tensor<1x1x1xf32>
    %982 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_471, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%981 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %983 = tensor.empty() : tensor<1x1x1xf32>
    %984 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%982, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%983 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %985 = tensor.empty() : tensor<1x1x1xf32>
    %986 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%984 : tensor<1x1x1xf32>) outs(%985 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %987 = tensor.empty() : tensor<1x1x1536xf32>
    %988 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%976, %986 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%987 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_472 = tensor.expand_shape %arg159 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %989 = tensor.empty() : tensor<1x1x1536xf32>
    %990 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_472, %988 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%989 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_473 = tensor.collapse_shape %990 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %991 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_473, %arg161 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_474 = tensor.expand_shape %arg160 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %992 = tensor.empty() : tensor<1x1536xf32>
    %993 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_474, %991 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%992 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_475 = tensor.expand_shape %993 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_476 = tensor.collapse_shape %990 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %994 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_476, %arg163 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_477 = tensor.expand_shape %arg162 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %995 = tensor.empty() : tensor<1x256xf32>
    %996 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_477, %994 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%995 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_478 = tensor.expand_shape %996 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_479 = tensor.collapse_shape %990 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %997 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_479, %arg165 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_480 = tensor.expand_shape %arg164 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %998 = tensor.empty() : tensor<1x256xf32>
    %999 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_480, %997 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%998 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_481 = tensor.expand_shape %999 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_482 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_483 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %1000 = tensor.empty() : tensor<1x12x1x128xf32>
    %1001 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_475, %expanded_482 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1000 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_484 = tensor.extract_slice %expanded_475[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_485 = tensor.extract_slice %expanded_475[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %1002 = tensor.empty() : tensor<1x12x1x64xf32>
    %1003 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_485 : tensor<1x12x1x64xf32>) outs(%1002 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %1004 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_486 = tensor.insert_slice %1003 into %1004[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_487 = tensor.insert_slice %extracted_slice_484 into %inserted_slice_486[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %1005 = tensor.empty() : tensor<1x12x1x128xf32>
    %1006 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_487, %expanded_483 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1005 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %1007 = tensor.empty() : tensor<1x12x1x128xf32>
    %1008 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1001, %1006 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%1007 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %1009 = tensor.empty() : tensor<1x2x1x128xf32>
    %1010 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_478, %expanded_482 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1009 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_488 = tensor.extract_slice %expanded_478[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_489 = tensor.extract_slice %expanded_478[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %1011 = tensor.empty() : tensor<1x2x1x64xf32>
    %1012 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_489 : tensor<1x2x1x64xf32>) outs(%1011 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %1013 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_490 = tensor.insert_slice %1012 into %1013[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_491 = tensor.insert_slice %extracted_slice_488 into %inserted_slice_490[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %1014 = tensor.empty() : tensor<1x2x1x128xf32>
    %1015 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_491, %expanded_483 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1014 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %1016 = tensor.empty() : tensor<1x2x1x128xf32>
    %1017 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1010, %1015 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%1016 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %1018 = bufferization.to_buffer %arg166 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_492 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %1019 = tensor.empty() : tensor<1x2x1x128xi64>
    %1020 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_492, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%1019 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %1021 = bufferization.to_buffer %1020 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %1022 = bufferization.to_buffer %1017 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %1022[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %1021[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %1018[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %1023 = bufferization.to_tensor %1018 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %1024 = bufferization.to_buffer %arg167 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_493 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %1025 = tensor.empty() : tensor<1x2x1x128xi64>
    %1026 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_493, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%1025 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %1027 = bufferization.to_buffer %1026 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %1028 = bufferization.to_buffer %expanded_481 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %1028[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %1027[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %1024[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %1029 = bufferization.to_tensor %1024 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_494 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %1030 = tensor.empty() : tensor<1x1x1x1024xf32>
    %1031 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_494, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%1030 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %1032 = bufferization.to_buffer %1008 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %1033 = bufferization.to_buffer %1031 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_495 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_496 = memref.alloc() : memref<1x12x1xf32>
    %alloc_497 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_497[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %1032[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %1018[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %1033[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %1024[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_497[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_497[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_496[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_497[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_495[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %1034 = bufferization.to_tensor %alloc_495 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_498 = tensor.collapse_shape %1034 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %1035 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_498, %arg168 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_499 = tensor.expand_shape %1035 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %1036 = tensor.empty() : tensor<1x1x1536xf32>
    %1037 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%976, %expanded_499 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1036 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1038 = tensor.empty() : tensor<1x1x1536xf32>
    %1039 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1037 : tensor<1x1x1536xf32>) outs(%1038 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1040 = tensor.empty() : tensor<1x1xf32>
    %cst_500 = arith.constant 0.000000e+00 : f32
    %1041 = linalg.fill ins(%cst_500 : f32) outs(%1040 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_501 = linalg.reduce ins(%1039 : tensor<1x1x1536xf32>) outs(%1041 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_502 = tensor.expand_shape %reduced_501 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %1042 = tensor.empty() : tensor<1x1x1xf32>
    %1043 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_502, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1042 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1044 = tensor.empty() : tensor<1x1x1xf32>
    %1045 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1043, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1044 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1046 = tensor.empty() : tensor<1x1x1xf32>
    %1047 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1045 : tensor<1x1x1xf32>) outs(%1046 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1048 = tensor.empty() : tensor<1x1x1536xf32>
    %1049 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1037, %1047 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%1048 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_503 = tensor.expand_shape %arg169 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %1050 = tensor.empty() : tensor<1x1x1536xf32>
    %1051 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_503, %1049 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1050 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_504 = tensor.collapse_shape %1051 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1052 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_504, %arg170 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_505 = tensor.expand_shape %1052 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %1053 = tensor.empty() : tensor<1x1x8960xf32>
    %1054 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_505 : tensor<1x1x8960xf32>) outs(%1053 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %1055 = tensor.empty() : tensor<1x1x8960xf32>
    %1056 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_505, %1054 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%1055 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_506 = tensor.collapse_shape %1051 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1057 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_506, %arg171 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_507 = tensor.expand_shape %1057 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %1058 = tensor.empty() : tensor<1x1x8960xf32>
    %1059 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1056, %expanded_507 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%1058 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_508 = tensor.collapse_shape %1059 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %1060 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_508, %arg172 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_509 = tensor.expand_shape %1060 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %1061 = tensor.empty() : tensor<1x1x1536xf32>
    %1062 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1037, %expanded_509 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1061 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1063 = tensor.empty() : tensor<1x1x1536xf32>
    %1064 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1062 : tensor<1x1x1536xf32>) outs(%1063 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1065 = tensor.empty() : tensor<1x1xf32>
    %cst_510 = arith.constant 0.000000e+00 : f32
    %1066 = linalg.fill ins(%cst_510 : f32) outs(%1065 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_511 = linalg.reduce ins(%1064 : tensor<1x1x1536xf32>) outs(%1066 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_512 = tensor.expand_shape %reduced_511 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %1067 = tensor.empty() : tensor<1x1x1xf32>
    %1068 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_512, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1067 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1069 = tensor.empty() : tensor<1x1x1xf32>
    %1070 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1068, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1069 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1071 = tensor.empty() : tensor<1x1x1xf32>
    %1072 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1070 : tensor<1x1x1xf32>) outs(%1071 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1073 = tensor.empty() : tensor<1x1x1536xf32>
    %1074 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1062, %1072 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%1073 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_513 = tensor.expand_shape %arg173 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %1075 = tensor.empty() : tensor<1x1x1536xf32>
    %1076 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_513, %1074 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1075 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_514 = tensor.collapse_shape %1076 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1077 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_514, %arg175 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_515 = tensor.expand_shape %arg174 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %1078 = tensor.empty() : tensor<1x1536xf32>
    %1079 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_515, %1077 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%1078 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_516 = tensor.expand_shape %1079 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_517 = tensor.collapse_shape %1076 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1080 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_517, %arg177 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_518 = tensor.expand_shape %arg176 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %1081 = tensor.empty() : tensor<1x256xf32>
    %1082 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_518, %1080 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%1081 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_519 = tensor.expand_shape %1082 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_520 = tensor.collapse_shape %1076 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1083 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_520, %arg179 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_521 = tensor.expand_shape %arg178 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %1084 = tensor.empty() : tensor<1x256xf32>
    %1085 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_521, %1083 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%1084 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_522 = tensor.expand_shape %1085 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_523 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_524 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %1086 = tensor.empty() : tensor<1x12x1x128xf32>
    %1087 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_516, %expanded_523 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1086 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_525 = tensor.extract_slice %expanded_516[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_526 = tensor.extract_slice %expanded_516[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %1088 = tensor.empty() : tensor<1x12x1x64xf32>
    %1089 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_526 : tensor<1x12x1x64xf32>) outs(%1088 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %1090 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_527 = tensor.insert_slice %1089 into %1090[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_528 = tensor.insert_slice %extracted_slice_525 into %inserted_slice_527[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %1091 = tensor.empty() : tensor<1x12x1x128xf32>
    %1092 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_528, %expanded_524 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1091 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %1093 = tensor.empty() : tensor<1x12x1x128xf32>
    %1094 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1087, %1092 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%1093 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %1095 = tensor.empty() : tensor<1x2x1x128xf32>
    %1096 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_519, %expanded_523 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1095 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_529 = tensor.extract_slice %expanded_519[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_530 = tensor.extract_slice %expanded_519[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %1097 = tensor.empty() : tensor<1x2x1x64xf32>
    %1098 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_530 : tensor<1x2x1x64xf32>) outs(%1097 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %1099 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_531 = tensor.insert_slice %1098 into %1099[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_532 = tensor.insert_slice %extracted_slice_529 into %inserted_slice_531[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %1100 = tensor.empty() : tensor<1x2x1x128xf32>
    %1101 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_532, %expanded_524 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1100 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %1102 = tensor.empty() : tensor<1x2x1x128xf32>
    %1103 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1096, %1101 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%1102 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %1104 = bufferization.to_buffer %arg180 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_533 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %1105 = tensor.empty() : tensor<1x2x1x128xi64>
    %1106 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_533, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%1105 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %1107 = bufferization.to_buffer %1106 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %1108 = bufferization.to_buffer %1103 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %1108[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %1107[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %1104[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %1109 = bufferization.to_tensor %1104 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %1110 = bufferization.to_buffer %arg181 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_534 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %1111 = tensor.empty() : tensor<1x2x1x128xi64>
    %1112 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_534, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%1111 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %1113 = bufferization.to_buffer %1112 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %1114 = bufferization.to_buffer %expanded_522 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %1114[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %1113[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %1110[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %1115 = bufferization.to_tensor %1110 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_535 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %1116 = tensor.empty() : tensor<1x1x1x1024xf32>
    %1117 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_535, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%1116 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %1118 = bufferization.to_buffer %1094 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %1119 = bufferization.to_buffer %1117 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_536 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_537 = memref.alloc() : memref<1x12x1xf32>
    %alloc_538 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_538[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %1118[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %1104[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %1119[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %1110[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_538[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_538[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_537[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_538[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_536[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %1120 = bufferization.to_tensor %alloc_536 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_539 = tensor.collapse_shape %1120 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %1121 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_539, %arg182 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_540 = tensor.expand_shape %1121 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %1122 = tensor.empty() : tensor<1x1x1536xf32>
    %1123 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1062, %expanded_540 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1122 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1124 = tensor.empty() : tensor<1x1x1536xf32>
    %1125 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1123 : tensor<1x1x1536xf32>) outs(%1124 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1126 = tensor.empty() : tensor<1x1xf32>
    %cst_541 = arith.constant 0.000000e+00 : f32
    %1127 = linalg.fill ins(%cst_541 : f32) outs(%1126 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_542 = linalg.reduce ins(%1125 : tensor<1x1x1536xf32>) outs(%1127 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_543 = tensor.expand_shape %reduced_542 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %1128 = tensor.empty() : tensor<1x1x1xf32>
    %1129 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_543, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1128 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1130 = tensor.empty() : tensor<1x1x1xf32>
    %1131 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1129, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1130 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1132 = tensor.empty() : tensor<1x1x1xf32>
    %1133 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1131 : tensor<1x1x1xf32>) outs(%1132 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1134 = tensor.empty() : tensor<1x1x1536xf32>
    %1135 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1123, %1133 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%1134 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_544 = tensor.expand_shape %arg183 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %1136 = tensor.empty() : tensor<1x1x1536xf32>
    %1137 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_544, %1135 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1136 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_545 = tensor.collapse_shape %1137 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1138 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_545, %arg184 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_546 = tensor.expand_shape %1138 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %1139 = tensor.empty() : tensor<1x1x8960xf32>
    %1140 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_546 : tensor<1x1x8960xf32>) outs(%1139 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %1141 = tensor.empty() : tensor<1x1x8960xf32>
    %1142 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_546, %1140 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%1141 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_547 = tensor.collapse_shape %1137 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1143 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_547, %arg185 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_548 = tensor.expand_shape %1143 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %1144 = tensor.empty() : tensor<1x1x8960xf32>
    %1145 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1142, %expanded_548 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%1144 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_549 = tensor.collapse_shape %1145 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %1146 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_549, %arg186 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_550 = tensor.expand_shape %1146 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %1147 = tensor.empty() : tensor<1x1x1536xf32>
    %1148 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1123, %expanded_550 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1147 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1149 = tensor.empty() : tensor<1x1x1536xf32>
    %1150 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1148 : tensor<1x1x1536xf32>) outs(%1149 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1151 = tensor.empty() : tensor<1x1xf32>
    %cst_551 = arith.constant 0.000000e+00 : f32
    %1152 = linalg.fill ins(%cst_551 : f32) outs(%1151 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_552 = linalg.reduce ins(%1150 : tensor<1x1x1536xf32>) outs(%1152 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_553 = tensor.expand_shape %reduced_552 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %1153 = tensor.empty() : tensor<1x1x1xf32>
    %1154 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_553, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1153 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1155 = tensor.empty() : tensor<1x1x1xf32>
    %1156 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1154, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1155 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1157 = tensor.empty() : tensor<1x1x1xf32>
    %1158 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1156 : tensor<1x1x1xf32>) outs(%1157 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1159 = tensor.empty() : tensor<1x1x1536xf32>
    %1160 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1148, %1158 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%1159 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_554 = tensor.expand_shape %arg187 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %1161 = tensor.empty() : tensor<1x1x1536xf32>
    %1162 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_554, %1160 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1161 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_555 = tensor.collapse_shape %1162 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1163 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_555, %arg189 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_556 = tensor.expand_shape %arg188 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %1164 = tensor.empty() : tensor<1x1536xf32>
    %1165 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_556, %1163 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%1164 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_557 = tensor.expand_shape %1165 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_558 = tensor.collapse_shape %1162 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1166 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_558, %arg191 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_559 = tensor.expand_shape %arg190 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %1167 = tensor.empty() : tensor<1x256xf32>
    %1168 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_559, %1166 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%1167 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_560 = tensor.expand_shape %1168 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_561 = tensor.collapse_shape %1162 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1169 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_561, %arg193 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_562 = tensor.expand_shape %arg192 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %1170 = tensor.empty() : tensor<1x256xf32>
    %1171 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_562, %1169 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%1170 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_563 = tensor.expand_shape %1171 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_564 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_565 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %1172 = tensor.empty() : tensor<1x12x1x128xf32>
    %1173 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_557, %expanded_564 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1172 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_566 = tensor.extract_slice %expanded_557[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_567 = tensor.extract_slice %expanded_557[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %1174 = tensor.empty() : tensor<1x12x1x64xf32>
    %1175 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_567 : tensor<1x12x1x64xf32>) outs(%1174 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %1176 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_568 = tensor.insert_slice %1175 into %1176[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_569 = tensor.insert_slice %extracted_slice_566 into %inserted_slice_568[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %1177 = tensor.empty() : tensor<1x12x1x128xf32>
    %1178 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_569, %expanded_565 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1177 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %1179 = tensor.empty() : tensor<1x12x1x128xf32>
    %1180 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1173, %1178 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%1179 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %1181 = tensor.empty() : tensor<1x2x1x128xf32>
    %1182 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_560, %expanded_564 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1181 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_570 = tensor.extract_slice %expanded_560[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_571 = tensor.extract_slice %expanded_560[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %1183 = tensor.empty() : tensor<1x2x1x64xf32>
    %1184 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_571 : tensor<1x2x1x64xf32>) outs(%1183 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %1185 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_572 = tensor.insert_slice %1184 into %1185[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_573 = tensor.insert_slice %extracted_slice_570 into %inserted_slice_572[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %1186 = tensor.empty() : tensor<1x2x1x128xf32>
    %1187 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_573, %expanded_565 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1186 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %1188 = tensor.empty() : tensor<1x2x1x128xf32>
    %1189 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1182, %1187 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%1188 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %1190 = bufferization.to_buffer %arg194 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_574 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %1191 = tensor.empty() : tensor<1x2x1x128xi64>
    %1192 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_574, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%1191 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %1193 = bufferization.to_buffer %1192 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %1194 = bufferization.to_buffer %1189 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %1194[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %1193[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %1190[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %1195 = bufferization.to_tensor %1190 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %1196 = bufferization.to_buffer %arg195 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_575 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %1197 = tensor.empty() : tensor<1x2x1x128xi64>
    %1198 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_575, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%1197 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %1199 = bufferization.to_buffer %1198 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %1200 = bufferization.to_buffer %expanded_563 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %1200[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %1199[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %1196[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %1201 = bufferization.to_tensor %1196 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_576 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %1202 = tensor.empty() : tensor<1x1x1x1024xf32>
    %1203 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_576, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%1202 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %1204 = bufferization.to_buffer %1180 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %1205 = bufferization.to_buffer %1203 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_577 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_578 = memref.alloc() : memref<1x12x1xf32>
    %alloc_579 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_579[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %1204[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %1190[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %1205[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %1196[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_579[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_579[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_578[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_579[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_577[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %1206 = bufferization.to_tensor %alloc_577 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_580 = tensor.collapse_shape %1206 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %1207 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_580, %arg196 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_581 = tensor.expand_shape %1207 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %1208 = tensor.empty() : tensor<1x1x1536xf32>
    %1209 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1148, %expanded_581 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1208 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1210 = tensor.empty() : tensor<1x1x1536xf32>
    %1211 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1209 : tensor<1x1x1536xf32>) outs(%1210 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1212 = tensor.empty() : tensor<1x1xf32>
    %cst_582 = arith.constant 0.000000e+00 : f32
    %1213 = linalg.fill ins(%cst_582 : f32) outs(%1212 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_583 = linalg.reduce ins(%1211 : tensor<1x1x1536xf32>) outs(%1213 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_584 = tensor.expand_shape %reduced_583 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %1214 = tensor.empty() : tensor<1x1x1xf32>
    %1215 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_584, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1214 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1216 = tensor.empty() : tensor<1x1x1xf32>
    %1217 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1215, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1216 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1218 = tensor.empty() : tensor<1x1x1xf32>
    %1219 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1217 : tensor<1x1x1xf32>) outs(%1218 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1220 = tensor.empty() : tensor<1x1x1536xf32>
    %1221 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1209, %1219 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%1220 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_585 = tensor.expand_shape %arg197 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %1222 = tensor.empty() : tensor<1x1x1536xf32>
    %1223 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_585, %1221 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1222 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_586 = tensor.collapse_shape %1223 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1224 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_586, %arg198 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_587 = tensor.expand_shape %1224 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %1225 = tensor.empty() : tensor<1x1x8960xf32>
    %1226 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_587 : tensor<1x1x8960xf32>) outs(%1225 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %1227 = tensor.empty() : tensor<1x1x8960xf32>
    %1228 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_587, %1226 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%1227 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_588 = tensor.collapse_shape %1223 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1229 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_588, %arg199 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_589 = tensor.expand_shape %1229 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %1230 = tensor.empty() : tensor<1x1x8960xf32>
    %1231 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1228, %expanded_589 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%1230 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_590 = tensor.collapse_shape %1231 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %1232 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_590, %arg200 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_591 = tensor.expand_shape %1232 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %1233 = tensor.empty() : tensor<1x1x1536xf32>
    %1234 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1209, %expanded_591 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1233 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1235 = tensor.empty() : tensor<1x1x1536xf32>
    %1236 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1234 : tensor<1x1x1536xf32>) outs(%1235 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1237 = tensor.empty() : tensor<1x1xf32>
    %cst_592 = arith.constant 0.000000e+00 : f32
    %1238 = linalg.fill ins(%cst_592 : f32) outs(%1237 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_593 = linalg.reduce ins(%1236 : tensor<1x1x1536xf32>) outs(%1238 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_594 = tensor.expand_shape %reduced_593 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %1239 = tensor.empty() : tensor<1x1x1xf32>
    %1240 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_594, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1239 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1241 = tensor.empty() : tensor<1x1x1xf32>
    %1242 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1240, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1241 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1243 = tensor.empty() : tensor<1x1x1xf32>
    %1244 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1242 : tensor<1x1x1xf32>) outs(%1243 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1245 = tensor.empty() : tensor<1x1x1536xf32>
    %1246 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1234, %1244 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%1245 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_595 = tensor.expand_shape %arg201 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %1247 = tensor.empty() : tensor<1x1x1536xf32>
    %1248 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_595, %1246 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1247 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_596 = tensor.collapse_shape %1248 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1249 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_596, %arg203 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_597 = tensor.expand_shape %arg202 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %1250 = tensor.empty() : tensor<1x1536xf32>
    %1251 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_597, %1249 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%1250 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_598 = tensor.expand_shape %1251 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_599 = tensor.collapse_shape %1248 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1252 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_599, %arg205 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_600 = tensor.expand_shape %arg204 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %1253 = tensor.empty() : tensor<1x256xf32>
    %1254 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_600, %1252 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%1253 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_601 = tensor.expand_shape %1254 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_602 = tensor.collapse_shape %1248 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1255 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_602, %arg207 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_603 = tensor.expand_shape %arg206 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %1256 = tensor.empty() : tensor<1x256xf32>
    %1257 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_603, %1255 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%1256 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_604 = tensor.expand_shape %1257 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_605 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_606 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %1258 = tensor.empty() : tensor<1x12x1x128xf32>
    %1259 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_598, %expanded_605 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1258 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_607 = tensor.extract_slice %expanded_598[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_608 = tensor.extract_slice %expanded_598[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %1260 = tensor.empty() : tensor<1x12x1x64xf32>
    %1261 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_608 : tensor<1x12x1x64xf32>) outs(%1260 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %1262 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_609 = tensor.insert_slice %1261 into %1262[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_610 = tensor.insert_slice %extracted_slice_607 into %inserted_slice_609[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %1263 = tensor.empty() : tensor<1x12x1x128xf32>
    %1264 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_610, %expanded_606 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1263 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %1265 = tensor.empty() : tensor<1x12x1x128xf32>
    %1266 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1259, %1264 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%1265 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %1267 = tensor.empty() : tensor<1x2x1x128xf32>
    %1268 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_601, %expanded_605 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1267 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_611 = tensor.extract_slice %expanded_601[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_612 = tensor.extract_slice %expanded_601[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %1269 = tensor.empty() : tensor<1x2x1x64xf32>
    %1270 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_612 : tensor<1x2x1x64xf32>) outs(%1269 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %1271 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_613 = tensor.insert_slice %1270 into %1271[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_614 = tensor.insert_slice %extracted_slice_611 into %inserted_slice_613[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %1272 = tensor.empty() : tensor<1x2x1x128xf32>
    %1273 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_614, %expanded_606 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1272 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %1274 = tensor.empty() : tensor<1x2x1x128xf32>
    %1275 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1268, %1273 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%1274 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %1276 = bufferization.to_buffer %arg208 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_615 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %1277 = tensor.empty() : tensor<1x2x1x128xi64>
    %1278 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_615, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%1277 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %1279 = bufferization.to_buffer %1278 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %1280 = bufferization.to_buffer %1275 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %1280[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %1279[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %1276[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %1281 = bufferization.to_tensor %1276 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %1282 = bufferization.to_buffer %arg209 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_616 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %1283 = tensor.empty() : tensor<1x2x1x128xi64>
    %1284 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_616, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%1283 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %1285 = bufferization.to_buffer %1284 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %1286 = bufferization.to_buffer %expanded_604 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %1286[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %1285[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %1282[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %1287 = bufferization.to_tensor %1282 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_617 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %1288 = tensor.empty() : tensor<1x1x1x1024xf32>
    %1289 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_617, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%1288 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %1290 = bufferization.to_buffer %1266 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %1291 = bufferization.to_buffer %1289 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_618 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_619 = memref.alloc() : memref<1x12x1xf32>
    %alloc_620 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_620[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %1290[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %1276[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %1291[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %1282[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_620[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_620[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_619[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_620[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_618[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %1292 = bufferization.to_tensor %alloc_618 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_621 = tensor.collapse_shape %1292 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %1293 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_621, %arg210 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_622 = tensor.expand_shape %1293 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %1294 = tensor.empty() : tensor<1x1x1536xf32>
    %1295 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1234, %expanded_622 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1294 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1296 = tensor.empty() : tensor<1x1x1536xf32>
    %1297 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1295 : tensor<1x1x1536xf32>) outs(%1296 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1298 = tensor.empty() : tensor<1x1xf32>
    %cst_623 = arith.constant 0.000000e+00 : f32
    %1299 = linalg.fill ins(%cst_623 : f32) outs(%1298 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_624 = linalg.reduce ins(%1297 : tensor<1x1x1536xf32>) outs(%1299 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_625 = tensor.expand_shape %reduced_624 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %1300 = tensor.empty() : tensor<1x1x1xf32>
    %1301 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_625, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1300 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1302 = tensor.empty() : tensor<1x1x1xf32>
    %1303 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1301, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1302 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1304 = tensor.empty() : tensor<1x1x1xf32>
    %1305 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1303 : tensor<1x1x1xf32>) outs(%1304 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1306 = tensor.empty() : tensor<1x1x1536xf32>
    %1307 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1295, %1305 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%1306 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_626 = tensor.expand_shape %arg211 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %1308 = tensor.empty() : tensor<1x1x1536xf32>
    %1309 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_626, %1307 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1308 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_627 = tensor.collapse_shape %1309 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1310 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_627, %arg212 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_628 = tensor.expand_shape %1310 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %1311 = tensor.empty() : tensor<1x1x8960xf32>
    %1312 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_628 : tensor<1x1x8960xf32>) outs(%1311 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %1313 = tensor.empty() : tensor<1x1x8960xf32>
    %1314 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_628, %1312 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%1313 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_629 = tensor.collapse_shape %1309 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1315 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_629, %arg213 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_630 = tensor.expand_shape %1315 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %1316 = tensor.empty() : tensor<1x1x8960xf32>
    %1317 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1314, %expanded_630 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%1316 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_631 = tensor.collapse_shape %1317 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %1318 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_631, %arg214 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_632 = tensor.expand_shape %1318 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %1319 = tensor.empty() : tensor<1x1x1536xf32>
    %1320 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1295, %expanded_632 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1319 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1321 = tensor.empty() : tensor<1x1x1536xf32>
    %1322 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1320 : tensor<1x1x1536xf32>) outs(%1321 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1323 = tensor.empty() : tensor<1x1xf32>
    %cst_633 = arith.constant 0.000000e+00 : f32
    %1324 = linalg.fill ins(%cst_633 : f32) outs(%1323 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_634 = linalg.reduce ins(%1322 : tensor<1x1x1536xf32>) outs(%1324 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_635 = tensor.expand_shape %reduced_634 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %1325 = tensor.empty() : tensor<1x1x1xf32>
    %1326 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_635, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1325 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1327 = tensor.empty() : tensor<1x1x1xf32>
    %1328 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1326, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1327 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1329 = tensor.empty() : tensor<1x1x1xf32>
    %1330 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1328 : tensor<1x1x1xf32>) outs(%1329 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1331 = tensor.empty() : tensor<1x1x1536xf32>
    %1332 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1320, %1330 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%1331 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_636 = tensor.expand_shape %arg215 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %1333 = tensor.empty() : tensor<1x1x1536xf32>
    %1334 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_636, %1332 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1333 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_637 = tensor.collapse_shape %1334 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1335 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_637, %arg217 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_638 = tensor.expand_shape %arg216 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %1336 = tensor.empty() : tensor<1x1536xf32>
    %1337 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_638, %1335 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%1336 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_639 = tensor.expand_shape %1337 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_640 = tensor.collapse_shape %1334 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1338 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_640, %arg219 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_641 = tensor.expand_shape %arg218 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %1339 = tensor.empty() : tensor<1x256xf32>
    %1340 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_641, %1338 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%1339 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_642 = tensor.expand_shape %1340 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_643 = tensor.collapse_shape %1334 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1341 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_643, %arg221 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_644 = tensor.expand_shape %arg220 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %1342 = tensor.empty() : tensor<1x256xf32>
    %1343 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_644, %1341 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%1342 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_645 = tensor.expand_shape %1343 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_646 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_647 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %1344 = tensor.empty() : tensor<1x12x1x128xf32>
    %1345 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_639, %expanded_646 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1344 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_648 = tensor.extract_slice %expanded_639[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_649 = tensor.extract_slice %expanded_639[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %1346 = tensor.empty() : tensor<1x12x1x64xf32>
    %1347 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_649 : tensor<1x12x1x64xf32>) outs(%1346 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %1348 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_650 = tensor.insert_slice %1347 into %1348[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_651 = tensor.insert_slice %extracted_slice_648 into %inserted_slice_650[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %1349 = tensor.empty() : tensor<1x12x1x128xf32>
    %1350 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_651, %expanded_647 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1349 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %1351 = tensor.empty() : tensor<1x12x1x128xf32>
    %1352 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1345, %1350 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%1351 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %1353 = tensor.empty() : tensor<1x2x1x128xf32>
    %1354 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_642, %expanded_646 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1353 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_652 = tensor.extract_slice %expanded_642[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_653 = tensor.extract_slice %expanded_642[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %1355 = tensor.empty() : tensor<1x2x1x64xf32>
    %1356 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_653 : tensor<1x2x1x64xf32>) outs(%1355 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %1357 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_654 = tensor.insert_slice %1356 into %1357[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_655 = tensor.insert_slice %extracted_slice_652 into %inserted_slice_654[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %1358 = tensor.empty() : tensor<1x2x1x128xf32>
    %1359 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_655, %expanded_647 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1358 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %1360 = tensor.empty() : tensor<1x2x1x128xf32>
    %1361 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1354, %1359 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%1360 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %1362 = bufferization.to_buffer %arg222 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_656 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %1363 = tensor.empty() : tensor<1x2x1x128xi64>
    %1364 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_656, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%1363 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %1365 = bufferization.to_buffer %1364 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %1366 = bufferization.to_buffer %1361 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %1366[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %1365[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %1362[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %1367 = bufferization.to_tensor %1362 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %1368 = bufferization.to_buffer %arg223 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_657 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %1369 = tensor.empty() : tensor<1x2x1x128xi64>
    %1370 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_657, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%1369 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %1371 = bufferization.to_buffer %1370 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %1372 = bufferization.to_buffer %expanded_645 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %1372[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %1371[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %1368[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %1373 = bufferization.to_tensor %1368 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_658 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %1374 = tensor.empty() : tensor<1x1x1x1024xf32>
    %1375 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_658, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%1374 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %1376 = bufferization.to_buffer %1352 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %1377 = bufferization.to_buffer %1375 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_659 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_660 = memref.alloc() : memref<1x12x1xf32>
    %alloc_661 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_661[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %1376[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %1362[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %1377[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %1368[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_661[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_661[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_660[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_661[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_659[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %1378 = bufferization.to_tensor %alloc_659 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_662 = tensor.collapse_shape %1378 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %1379 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_662, %arg224 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_663 = tensor.expand_shape %1379 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %1380 = tensor.empty() : tensor<1x1x1536xf32>
    %1381 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1320, %expanded_663 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1380 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1382 = tensor.empty() : tensor<1x1x1536xf32>
    %1383 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1381 : tensor<1x1x1536xf32>) outs(%1382 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1384 = tensor.empty() : tensor<1x1xf32>
    %cst_664 = arith.constant 0.000000e+00 : f32
    %1385 = linalg.fill ins(%cst_664 : f32) outs(%1384 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_665 = linalg.reduce ins(%1383 : tensor<1x1x1536xf32>) outs(%1385 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_666 = tensor.expand_shape %reduced_665 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %1386 = tensor.empty() : tensor<1x1x1xf32>
    %1387 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_666, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1386 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1388 = tensor.empty() : tensor<1x1x1xf32>
    %1389 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1387, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1388 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1390 = tensor.empty() : tensor<1x1x1xf32>
    %1391 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1389 : tensor<1x1x1xf32>) outs(%1390 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1392 = tensor.empty() : tensor<1x1x1536xf32>
    %1393 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1381, %1391 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%1392 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_667 = tensor.expand_shape %arg225 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %1394 = tensor.empty() : tensor<1x1x1536xf32>
    %1395 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_667, %1393 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1394 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_668 = tensor.collapse_shape %1395 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1396 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_668, %arg226 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_669 = tensor.expand_shape %1396 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %1397 = tensor.empty() : tensor<1x1x8960xf32>
    %1398 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_669 : tensor<1x1x8960xf32>) outs(%1397 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %1399 = tensor.empty() : tensor<1x1x8960xf32>
    %1400 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_669, %1398 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%1399 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_670 = tensor.collapse_shape %1395 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1401 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_670, %arg227 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_671 = tensor.expand_shape %1401 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %1402 = tensor.empty() : tensor<1x1x8960xf32>
    %1403 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1400, %expanded_671 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%1402 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_672 = tensor.collapse_shape %1403 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %1404 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_672, %arg228 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_673 = tensor.expand_shape %1404 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %1405 = tensor.empty() : tensor<1x1x1536xf32>
    %1406 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1381, %expanded_673 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1405 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1407 = tensor.empty() : tensor<1x1x1536xf32>
    %1408 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1406 : tensor<1x1x1536xf32>) outs(%1407 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1409 = tensor.empty() : tensor<1x1xf32>
    %cst_674 = arith.constant 0.000000e+00 : f32
    %1410 = linalg.fill ins(%cst_674 : f32) outs(%1409 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_675 = linalg.reduce ins(%1408 : tensor<1x1x1536xf32>) outs(%1410 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_676 = tensor.expand_shape %reduced_675 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %1411 = tensor.empty() : tensor<1x1x1xf32>
    %1412 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_676, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1411 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1413 = tensor.empty() : tensor<1x1x1xf32>
    %1414 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1412, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1413 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1415 = tensor.empty() : tensor<1x1x1xf32>
    %1416 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1414 : tensor<1x1x1xf32>) outs(%1415 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1417 = tensor.empty() : tensor<1x1x1536xf32>
    %1418 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1406, %1416 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%1417 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_677 = tensor.expand_shape %arg229 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %1419 = tensor.empty() : tensor<1x1x1536xf32>
    %1420 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_677, %1418 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1419 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_678 = tensor.collapse_shape %1420 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1421 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_678, %arg231 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_679 = tensor.expand_shape %arg230 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %1422 = tensor.empty() : tensor<1x1536xf32>
    %1423 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_679, %1421 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%1422 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_680 = tensor.expand_shape %1423 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_681 = tensor.collapse_shape %1420 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1424 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_681, %arg233 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_682 = tensor.expand_shape %arg232 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %1425 = tensor.empty() : tensor<1x256xf32>
    %1426 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_682, %1424 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%1425 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_683 = tensor.expand_shape %1426 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_684 = tensor.collapse_shape %1420 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1427 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_684, %arg235 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_685 = tensor.expand_shape %arg234 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %1428 = tensor.empty() : tensor<1x256xf32>
    %1429 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_685, %1427 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%1428 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_686 = tensor.expand_shape %1429 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_687 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_688 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %1430 = tensor.empty() : tensor<1x12x1x128xf32>
    %1431 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_680, %expanded_687 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1430 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_689 = tensor.extract_slice %expanded_680[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_690 = tensor.extract_slice %expanded_680[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %1432 = tensor.empty() : tensor<1x12x1x64xf32>
    %1433 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_690 : tensor<1x12x1x64xf32>) outs(%1432 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %1434 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_691 = tensor.insert_slice %1433 into %1434[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_692 = tensor.insert_slice %extracted_slice_689 into %inserted_slice_691[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %1435 = tensor.empty() : tensor<1x12x1x128xf32>
    %1436 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_692, %expanded_688 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1435 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %1437 = tensor.empty() : tensor<1x12x1x128xf32>
    %1438 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1431, %1436 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%1437 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %1439 = tensor.empty() : tensor<1x2x1x128xf32>
    %1440 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_683, %expanded_687 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1439 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_693 = tensor.extract_slice %expanded_683[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_694 = tensor.extract_slice %expanded_683[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %1441 = tensor.empty() : tensor<1x2x1x64xf32>
    %1442 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_694 : tensor<1x2x1x64xf32>) outs(%1441 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %1443 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_695 = tensor.insert_slice %1442 into %1443[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_696 = tensor.insert_slice %extracted_slice_693 into %inserted_slice_695[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %1444 = tensor.empty() : tensor<1x2x1x128xf32>
    %1445 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_696, %expanded_688 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1444 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %1446 = tensor.empty() : tensor<1x2x1x128xf32>
    %1447 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1440, %1445 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%1446 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %1448 = bufferization.to_buffer %arg236 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_697 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %1449 = tensor.empty() : tensor<1x2x1x128xi64>
    %1450 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_697, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%1449 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %1451 = bufferization.to_buffer %1450 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %1452 = bufferization.to_buffer %1447 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %1452[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %1451[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %1448[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %1453 = bufferization.to_tensor %1448 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %1454 = bufferization.to_buffer %arg237 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_698 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %1455 = tensor.empty() : tensor<1x2x1x128xi64>
    %1456 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_698, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%1455 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %1457 = bufferization.to_buffer %1456 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %1458 = bufferization.to_buffer %expanded_686 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %1458[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %1457[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %1454[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %1459 = bufferization.to_tensor %1454 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_699 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %1460 = tensor.empty() : tensor<1x1x1x1024xf32>
    %1461 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_699, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%1460 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %1462 = bufferization.to_buffer %1438 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %1463 = bufferization.to_buffer %1461 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_700 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_701 = memref.alloc() : memref<1x12x1xf32>
    %alloc_702 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_702[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %1462[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %1448[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %1463[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %1454[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_702[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_702[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_701[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_702[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_700[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %1464 = bufferization.to_tensor %alloc_700 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_703 = tensor.collapse_shape %1464 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %1465 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_703, %arg238 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_704 = tensor.expand_shape %1465 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %1466 = tensor.empty() : tensor<1x1x1536xf32>
    %1467 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1406, %expanded_704 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1466 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1468 = tensor.empty() : tensor<1x1x1536xf32>
    %1469 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1467 : tensor<1x1x1536xf32>) outs(%1468 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1470 = tensor.empty() : tensor<1x1xf32>
    %cst_705 = arith.constant 0.000000e+00 : f32
    %1471 = linalg.fill ins(%cst_705 : f32) outs(%1470 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_706 = linalg.reduce ins(%1469 : tensor<1x1x1536xf32>) outs(%1471 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_707 = tensor.expand_shape %reduced_706 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %1472 = tensor.empty() : tensor<1x1x1xf32>
    %1473 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_707, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1472 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1474 = tensor.empty() : tensor<1x1x1xf32>
    %1475 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1473, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1474 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1476 = tensor.empty() : tensor<1x1x1xf32>
    %1477 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1475 : tensor<1x1x1xf32>) outs(%1476 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1478 = tensor.empty() : tensor<1x1x1536xf32>
    %1479 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1467, %1477 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%1478 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_708 = tensor.expand_shape %arg239 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %1480 = tensor.empty() : tensor<1x1x1536xf32>
    %1481 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_708, %1479 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1480 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_709 = tensor.collapse_shape %1481 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1482 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_709, %arg240 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_710 = tensor.expand_shape %1482 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %1483 = tensor.empty() : tensor<1x1x8960xf32>
    %1484 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_710 : tensor<1x1x8960xf32>) outs(%1483 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %1485 = tensor.empty() : tensor<1x1x8960xf32>
    %1486 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_710, %1484 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%1485 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_711 = tensor.collapse_shape %1481 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1487 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_711, %arg241 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_712 = tensor.expand_shape %1487 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %1488 = tensor.empty() : tensor<1x1x8960xf32>
    %1489 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1486, %expanded_712 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%1488 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_713 = tensor.collapse_shape %1489 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %1490 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_713, %arg242 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_714 = tensor.expand_shape %1490 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %1491 = tensor.empty() : tensor<1x1x1536xf32>
    %1492 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1467, %expanded_714 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1491 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1493 = tensor.empty() : tensor<1x1x1536xf32>
    %1494 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1492 : tensor<1x1x1536xf32>) outs(%1493 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1495 = tensor.empty() : tensor<1x1xf32>
    %cst_715 = arith.constant 0.000000e+00 : f32
    %1496 = linalg.fill ins(%cst_715 : f32) outs(%1495 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_716 = linalg.reduce ins(%1494 : tensor<1x1x1536xf32>) outs(%1496 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_717 = tensor.expand_shape %reduced_716 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %1497 = tensor.empty() : tensor<1x1x1xf32>
    %1498 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_717, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1497 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1499 = tensor.empty() : tensor<1x1x1xf32>
    %1500 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1498, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1499 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1501 = tensor.empty() : tensor<1x1x1xf32>
    %1502 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1500 : tensor<1x1x1xf32>) outs(%1501 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1503 = tensor.empty() : tensor<1x1x1536xf32>
    %1504 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1492, %1502 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%1503 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_718 = tensor.expand_shape %arg243 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %1505 = tensor.empty() : tensor<1x1x1536xf32>
    %1506 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_718, %1504 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1505 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_719 = tensor.collapse_shape %1506 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1507 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_719, %arg245 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_720 = tensor.expand_shape %arg244 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %1508 = tensor.empty() : tensor<1x1536xf32>
    %1509 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_720, %1507 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%1508 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_721 = tensor.expand_shape %1509 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_722 = tensor.collapse_shape %1506 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1510 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_722, %arg247 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_723 = tensor.expand_shape %arg246 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %1511 = tensor.empty() : tensor<1x256xf32>
    %1512 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_723, %1510 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%1511 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_724 = tensor.expand_shape %1512 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_725 = tensor.collapse_shape %1506 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1513 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_725, %arg249 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_726 = tensor.expand_shape %arg248 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %1514 = tensor.empty() : tensor<1x256xf32>
    %1515 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_726, %1513 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%1514 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_727 = tensor.expand_shape %1515 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_728 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_729 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %1516 = tensor.empty() : tensor<1x12x1x128xf32>
    %1517 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_721, %expanded_728 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1516 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_730 = tensor.extract_slice %expanded_721[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_731 = tensor.extract_slice %expanded_721[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %1518 = tensor.empty() : tensor<1x12x1x64xf32>
    %1519 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_731 : tensor<1x12x1x64xf32>) outs(%1518 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %1520 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_732 = tensor.insert_slice %1519 into %1520[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_733 = tensor.insert_slice %extracted_slice_730 into %inserted_slice_732[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %1521 = tensor.empty() : tensor<1x12x1x128xf32>
    %1522 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_733, %expanded_729 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1521 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %1523 = tensor.empty() : tensor<1x12x1x128xf32>
    %1524 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1517, %1522 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%1523 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %1525 = tensor.empty() : tensor<1x2x1x128xf32>
    %1526 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_724, %expanded_728 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1525 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_734 = tensor.extract_slice %expanded_724[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_735 = tensor.extract_slice %expanded_724[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %1527 = tensor.empty() : tensor<1x2x1x64xf32>
    %1528 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_735 : tensor<1x2x1x64xf32>) outs(%1527 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %1529 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_736 = tensor.insert_slice %1528 into %1529[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_737 = tensor.insert_slice %extracted_slice_734 into %inserted_slice_736[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %1530 = tensor.empty() : tensor<1x2x1x128xf32>
    %1531 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_737, %expanded_729 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1530 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %1532 = tensor.empty() : tensor<1x2x1x128xf32>
    %1533 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1526, %1531 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%1532 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %1534 = bufferization.to_buffer %arg250 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_738 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %1535 = tensor.empty() : tensor<1x2x1x128xi64>
    %1536 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_738, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%1535 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %1537 = bufferization.to_buffer %1536 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %1538 = bufferization.to_buffer %1533 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %1538[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %1537[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %1534[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %1539 = bufferization.to_tensor %1534 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %1540 = bufferization.to_buffer %arg251 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_739 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %1541 = tensor.empty() : tensor<1x2x1x128xi64>
    %1542 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_739, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%1541 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %1543 = bufferization.to_buffer %1542 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %1544 = bufferization.to_buffer %expanded_727 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %1544[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %1543[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %1540[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %1545 = bufferization.to_tensor %1540 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_740 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %1546 = tensor.empty() : tensor<1x1x1x1024xf32>
    %1547 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_740, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%1546 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %1548 = bufferization.to_buffer %1524 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %1549 = bufferization.to_buffer %1547 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_741 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_742 = memref.alloc() : memref<1x12x1xf32>
    %alloc_743 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_743[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %1548[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %1534[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %1549[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %1540[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_743[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_743[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_742[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_743[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_741[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %1550 = bufferization.to_tensor %alloc_741 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_744 = tensor.collapse_shape %1550 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %1551 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_744, %arg252 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_745 = tensor.expand_shape %1551 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %1552 = tensor.empty() : tensor<1x1x1536xf32>
    %1553 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1492, %expanded_745 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1552 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1554 = tensor.empty() : tensor<1x1x1536xf32>
    %1555 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1553 : tensor<1x1x1536xf32>) outs(%1554 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1556 = tensor.empty() : tensor<1x1xf32>
    %cst_746 = arith.constant 0.000000e+00 : f32
    %1557 = linalg.fill ins(%cst_746 : f32) outs(%1556 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_747 = linalg.reduce ins(%1555 : tensor<1x1x1536xf32>) outs(%1557 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_748 = tensor.expand_shape %reduced_747 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %1558 = tensor.empty() : tensor<1x1x1xf32>
    %1559 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_748, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1558 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1560 = tensor.empty() : tensor<1x1x1xf32>
    %1561 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1559, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1560 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1562 = tensor.empty() : tensor<1x1x1xf32>
    %1563 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1561 : tensor<1x1x1xf32>) outs(%1562 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1564 = tensor.empty() : tensor<1x1x1536xf32>
    %1565 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1553, %1563 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%1564 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_749 = tensor.expand_shape %arg253 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %1566 = tensor.empty() : tensor<1x1x1536xf32>
    %1567 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_749, %1565 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1566 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_750 = tensor.collapse_shape %1567 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1568 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_750, %arg254 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_751 = tensor.expand_shape %1568 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %1569 = tensor.empty() : tensor<1x1x8960xf32>
    %1570 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_751 : tensor<1x1x8960xf32>) outs(%1569 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %1571 = tensor.empty() : tensor<1x1x8960xf32>
    %1572 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_751, %1570 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%1571 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_752 = tensor.collapse_shape %1567 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1573 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_752, %arg255 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_753 = tensor.expand_shape %1573 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %1574 = tensor.empty() : tensor<1x1x8960xf32>
    %1575 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1572, %expanded_753 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%1574 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_754 = tensor.collapse_shape %1575 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %1576 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_754, %arg256 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_755 = tensor.expand_shape %1576 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %1577 = tensor.empty() : tensor<1x1x1536xf32>
    %1578 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1553, %expanded_755 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1577 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1579 = tensor.empty() : tensor<1x1x1536xf32>
    %1580 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1578 : tensor<1x1x1536xf32>) outs(%1579 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1581 = tensor.empty() : tensor<1x1xf32>
    %cst_756 = arith.constant 0.000000e+00 : f32
    %1582 = linalg.fill ins(%cst_756 : f32) outs(%1581 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_757 = linalg.reduce ins(%1580 : tensor<1x1x1536xf32>) outs(%1582 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_758 = tensor.expand_shape %reduced_757 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %1583 = tensor.empty() : tensor<1x1x1xf32>
    %1584 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_758, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1583 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1585 = tensor.empty() : tensor<1x1x1xf32>
    %1586 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1584, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1585 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1587 = tensor.empty() : tensor<1x1x1xf32>
    %1588 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1586 : tensor<1x1x1xf32>) outs(%1587 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1589 = tensor.empty() : tensor<1x1x1536xf32>
    %1590 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1578, %1588 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%1589 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_759 = tensor.expand_shape %arg257 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %1591 = tensor.empty() : tensor<1x1x1536xf32>
    %1592 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_759, %1590 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1591 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_760 = tensor.collapse_shape %1592 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1593 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_760, %arg259 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_761 = tensor.expand_shape %arg258 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %1594 = tensor.empty() : tensor<1x1536xf32>
    %1595 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_761, %1593 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%1594 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_762 = tensor.expand_shape %1595 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_763 = tensor.collapse_shape %1592 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1596 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_763, %arg261 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_764 = tensor.expand_shape %arg260 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %1597 = tensor.empty() : tensor<1x256xf32>
    %1598 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_764, %1596 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%1597 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_765 = tensor.expand_shape %1598 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_766 = tensor.collapse_shape %1592 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1599 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_766, %arg263 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_767 = tensor.expand_shape %arg262 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %1600 = tensor.empty() : tensor<1x256xf32>
    %1601 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_767, %1599 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%1600 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_768 = tensor.expand_shape %1601 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_769 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_770 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %1602 = tensor.empty() : tensor<1x12x1x128xf32>
    %1603 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_762, %expanded_769 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1602 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_771 = tensor.extract_slice %expanded_762[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_772 = tensor.extract_slice %expanded_762[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %1604 = tensor.empty() : tensor<1x12x1x64xf32>
    %1605 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_772 : tensor<1x12x1x64xf32>) outs(%1604 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %1606 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_773 = tensor.insert_slice %1605 into %1606[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_774 = tensor.insert_slice %extracted_slice_771 into %inserted_slice_773[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %1607 = tensor.empty() : tensor<1x12x1x128xf32>
    %1608 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_774, %expanded_770 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1607 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %1609 = tensor.empty() : tensor<1x12x1x128xf32>
    %1610 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1603, %1608 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%1609 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %1611 = tensor.empty() : tensor<1x2x1x128xf32>
    %1612 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_765, %expanded_769 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1611 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_775 = tensor.extract_slice %expanded_765[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_776 = tensor.extract_slice %expanded_765[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %1613 = tensor.empty() : tensor<1x2x1x64xf32>
    %1614 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_776 : tensor<1x2x1x64xf32>) outs(%1613 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %1615 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_777 = tensor.insert_slice %1614 into %1615[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_778 = tensor.insert_slice %extracted_slice_775 into %inserted_slice_777[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %1616 = tensor.empty() : tensor<1x2x1x128xf32>
    %1617 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_778, %expanded_770 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1616 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %1618 = tensor.empty() : tensor<1x2x1x128xf32>
    %1619 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1612, %1617 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%1618 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %1620 = bufferization.to_buffer %arg264 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_779 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %1621 = tensor.empty() : tensor<1x2x1x128xi64>
    %1622 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_779, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%1621 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %1623 = bufferization.to_buffer %1622 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %1624 = bufferization.to_buffer %1619 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %1624[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %1623[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %1620[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %1625 = bufferization.to_tensor %1620 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %1626 = bufferization.to_buffer %arg265 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_780 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %1627 = tensor.empty() : tensor<1x2x1x128xi64>
    %1628 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_780, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%1627 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %1629 = bufferization.to_buffer %1628 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %1630 = bufferization.to_buffer %expanded_768 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %1630[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %1629[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %1626[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %1631 = bufferization.to_tensor %1626 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_781 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %1632 = tensor.empty() : tensor<1x1x1x1024xf32>
    %1633 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_781, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%1632 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %1634 = bufferization.to_buffer %1610 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %1635 = bufferization.to_buffer %1633 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_782 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_783 = memref.alloc() : memref<1x12x1xf32>
    %alloc_784 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_784[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %1634[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %1620[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %1635[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %1626[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_784[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_784[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_783[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_784[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_782[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %1636 = bufferization.to_tensor %alloc_782 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_785 = tensor.collapse_shape %1636 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %1637 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_785, %arg266 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_786 = tensor.expand_shape %1637 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %1638 = tensor.empty() : tensor<1x1x1536xf32>
    %1639 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1578, %expanded_786 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1638 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1640 = tensor.empty() : tensor<1x1x1536xf32>
    %1641 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1639 : tensor<1x1x1536xf32>) outs(%1640 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1642 = tensor.empty() : tensor<1x1xf32>
    %cst_787 = arith.constant 0.000000e+00 : f32
    %1643 = linalg.fill ins(%cst_787 : f32) outs(%1642 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_788 = linalg.reduce ins(%1641 : tensor<1x1x1536xf32>) outs(%1643 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_789 = tensor.expand_shape %reduced_788 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %1644 = tensor.empty() : tensor<1x1x1xf32>
    %1645 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_789, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1644 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1646 = tensor.empty() : tensor<1x1x1xf32>
    %1647 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1645, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1646 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1648 = tensor.empty() : tensor<1x1x1xf32>
    %1649 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1647 : tensor<1x1x1xf32>) outs(%1648 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1650 = tensor.empty() : tensor<1x1x1536xf32>
    %1651 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1639, %1649 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%1650 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_790 = tensor.expand_shape %arg267 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %1652 = tensor.empty() : tensor<1x1x1536xf32>
    %1653 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_790, %1651 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1652 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_791 = tensor.collapse_shape %1653 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1654 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_791, %arg268 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_792 = tensor.expand_shape %1654 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %1655 = tensor.empty() : tensor<1x1x8960xf32>
    %1656 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_792 : tensor<1x1x8960xf32>) outs(%1655 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %1657 = tensor.empty() : tensor<1x1x8960xf32>
    %1658 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_792, %1656 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%1657 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_793 = tensor.collapse_shape %1653 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1659 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_793, %arg269 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_794 = tensor.expand_shape %1659 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %1660 = tensor.empty() : tensor<1x1x8960xf32>
    %1661 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1658, %expanded_794 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%1660 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_795 = tensor.collapse_shape %1661 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %1662 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_795, %arg270 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_796 = tensor.expand_shape %1662 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %1663 = tensor.empty() : tensor<1x1x1536xf32>
    %1664 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1639, %expanded_796 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1663 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1665 = tensor.empty() : tensor<1x1x1536xf32>
    %1666 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1664 : tensor<1x1x1536xf32>) outs(%1665 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1667 = tensor.empty() : tensor<1x1xf32>
    %cst_797 = arith.constant 0.000000e+00 : f32
    %1668 = linalg.fill ins(%cst_797 : f32) outs(%1667 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_798 = linalg.reduce ins(%1666 : tensor<1x1x1536xf32>) outs(%1668 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_799 = tensor.expand_shape %reduced_798 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %1669 = tensor.empty() : tensor<1x1x1xf32>
    %1670 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_799, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1669 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1671 = tensor.empty() : tensor<1x1x1xf32>
    %1672 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1670, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1671 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1673 = tensor.empty() : tensor<1x1x1xf32>
    %1674 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1672 : tensor<1x1x1xf32>) outs(%1673 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1675 = tensor.empty() : tensor<1x1x1536xf32>
    %1676 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1664, %1674 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%1675 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_800 = tensor.expand_shape %arg271 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %1677 = tensor.empty() : tensor<1x1x1536xf32>
    %1678 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_800, %1676 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1677 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_801 = tensor.collapse_shape %1678 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1679 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_801, %arg273 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_802 = tensor.expand_shape %arg272 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %1680 = tensor.empty() : tensor<1x1536xf32>
    %1681 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_802, %1679 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%1680 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_803 = tensor.expand_shape %1681 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_804 = tensor.collapse_shape %1678 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1682 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_804, %arg275 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_805 = tensor.expand_shape %arg274 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %1683 = tensor.empty() : tensor<1x256xf32>
    %1684 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_805, %1682 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%1683 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_806 = tensor.expand_shape %1684 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_807 = tensor.collapse_shape %1678 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1685 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_807, %arg277 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_808 = tensor.expand_shape %arg276 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %1686 = tensor.empty() : tensor<1x256xf32>
    %1687 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_808, %1685 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%1686 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_809 = tensor.expand_shape %1687 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_810 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_811 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %1688 = tensor.empty() : tensor<1x12x1x128xf32>
    %1689 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_803, %expanded_810 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1688 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_812 = tensor.extract_slice %expanded_803[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_813 = tensor.extract_slice %expanded_803[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %1690 = tensor.empty() : tensor<1x12x1x64xf32>
    %1691 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_813 : tensor<1x12x1x64xf32>) outs(%1690 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %1692 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_814 = tensor.insert_slice %1691 into %1692[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_815 = tensor.insert_slice %extracted_slice_812 into %inserted_slice_814[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %1693 = tensor.empty() : tensor<1x12x1x128xf32>
    %1694 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_815, %expanded_811 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1693 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %1695 = tensor.empty() : tensor<1x12x1x128xf32>
    %1696 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1689, %1694 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%1695 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %1697 = tensor.empty() : tensor<1x2x1x128xf32>
    %1698 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_806, %expanded_810 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1697 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_816 = tensor.extract_slice %expanded_806[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_817 = tensor.extract_slice %expanded_806[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %1699 = tensor.empty() : tensor<1x2x1x64xf32>
    %1700 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_817 : tensor<1x2x1x64xf32>) outs(%1699 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %1701 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_818 = tensor.insert_slice %1700 into %1701[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_819 = tensor.insert_slice %extracted_slice_816 into %inserted_slice_818[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %1702 = tensor.empty() : tensor<1x2x1x128xf32>
    %1703 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_819, %expanded_811 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1702 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %1704 = tensor.empty() : tensor<1x2x1x128xf32>
    %1705 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1698, %1703 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%1704 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %1706 = bufferization.to_buffer %arg278 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_820 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %1707 = tensor.empty() : tensor<1x2x1x128xi64>
    %1708 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_820, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%1707 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %1709 = bufferization.to_buffer %1708 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %1710 = bufferization.to_buffer %1705 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %1710[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %1709[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %1706[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %1711 = bufferization.to_tensor %1706 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %1712 = bufferization.to_buffer %arg279 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_821 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %1713 = tensor.empty() : tensor<1x2x1x128xi64>
    %1714 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_821, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%1713 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %1715 = bufferization.to_buffer %1714 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %1716 = bufferization.to_buffer %expanded_809 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %1716[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %1715[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %1712[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %1717 = bufferization.to_tensor %1712 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_822 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %1718 = tensor.empty() : tensor<1x1x1x1024xf32>
    %1719 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_822, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%1718 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %1720 = bufferization.to_buffer %1696 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %1721 = bufferization.to_buffer %1719 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_823 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_824 = memref.alloc() : memref<1x12x1xf32>
    %alloc_825 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_825[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %1720[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %1706[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %1721[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %1712[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_825[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_825[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_824[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_825[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_823[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %1722 = bufferization.to_tensor %alloc_823 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_826 = tensor.collapse_shape %1722 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %1723 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_826, %arg280 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_827 = tensor.expand_shape %1723 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %1724 = tensor.empty() : tensor<1x1x1536xf32>
    %1725 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1664, %expanded_827 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1724 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1726 = tensor.empty() : tensor<1x1x1536xf32>
    %1727 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1725 : tensor<1x1x1536xf32>) outs(%1726 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1728 = tensor.empty() : tensor<1x1xf32>
    %cst_828 = arith.constant 0.000000e+00 : f32
    %1729 = linalg.fill ins(%cst_828 : f32) outs(%1728 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_829 = linalg.reduce ins(%1727 : tensor<1x1x1536xf32>) outs(%1729 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_830 = tensor.expand_shape %reduced_829 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %1730 = tensor.empty() : tensor<1x1x1xf32>
    %1731 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_830, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1730 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1732 = tensor.empty() : tensor<1x1x1xf32>
    %1733 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1731, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1732 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1734 = tensor.empty() : tensor<1x1x1xf32>
    %1735 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1733 : tensor<1x1x1xf32>) outs(%1734 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1736 = tensor.empty() : tensor<1x1x1536xf32>
    %1737 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1725, %1735 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%1736 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_831 = tensor.expand_shape %arg281 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %1738 = tensor.empty() : tensor<1x1x1536xf32>
    %1739 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_831, %1737 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1738 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_832 = tensor.collapse_shape %1739 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1740 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_832, %arg282 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_833 = tensor.expand_shape %1740 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %1741 = tensor.empty() : tensor<1x1x8960xf32>
    %1742 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_833 : tensor<1x1x8960xf32>) outs(%1741 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %1743 = tensor.empty() : tensor<1x1x8960xf32>
    %1744 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_833, %1742 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%1743 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_834 = tensor.collapse_shape %1739 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1745 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_834, %arg283 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_835 = tensor.expand_shape %1745 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %1746 = tensor.empty() : tensor<1x1x8960xf32>
    %1747 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1744, %expanded_835 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%1746 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_836 = tensor.collapse_shape %1747 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %1748 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_836, %arg284 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_837 = tensor.expand_shape %1748 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %1749 = tensor.empty() : tensor<1x1x1536xf32>
    %1750 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1725, %expanded_837 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1749 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1751 = tensor.empty() : tensor<1x1x1536xf32>
    %1752 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1750 : tensor<1x1x1536xf32>) outs(%1751 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1753 = tensor.empty() : tensor<1x1xf32>
    %cst_838 = arith.constant 0.000000e+00 : f32
    %1754 = linalg.fill ins(%cst_838 : f32) outs(%1753 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_839 = linalg.reduce ins(%1752 : tensor<1x1x1536xf32>) outs(%1754 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_840 = tensor.expand_shape %reduced_839 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %1755 = tensor.empty() : tensor<1x1x1xf32>
    %1756 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_840, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1755 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1757 = tensor.empty() : tensor<1x1x1xf32>
    %1758 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1756, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1757 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1759 = tensor.empty() : tensor<1x1x1xf32>
    %1760 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1758 : tensor<1x1x1xf32>) outs(%1759 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1761 = tensor.empty() : tensor<1x1x1536xf32>
    %1762 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1750, %1760 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%1761 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_841 = tensor.expand_shape %arg285 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %1763 = tensor.empty() : tensor<1x1x1536xf32>
    %1764 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_841, %1762 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1763 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_842 = tensor.collapse_shape %1764 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1765 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_842, %arg287 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_843 = tensor.expand_shape %arg286 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %1766 = tensor.empty() : tensor<1x1536xf32>
    %1767 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_843, %1765 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%1766 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_844 = tensor.expand_shape %1767 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_845 = tensor.collapse_shape %1764 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1768 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_845, %arg289 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_846 = tensor.expand_shape %arg288 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %1769 = tensor.empty() : tensor<1x256xf32>
    %1770 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_846, %1768 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%1769 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_847 = tensor.expand_shape %1770 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_848 = tensor.collapse_shape %1764 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1771 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_848, %arg291 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_849 = tensor.expand_shape %arg290 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %1772 = tensor.empty() : tensor<1x256xf32>
    %1773 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_849, %1771 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%1772 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_850 = tensor.expand_shape %1773 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_851 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_852 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %1774 = tensor.empty() : tensor<1x12x1x128xf32>
    %1775 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_844, %expanded_851 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1774 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_853 = tensor.extract_slice %expanded_844[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_854 = tensor.extract_slice %expanded_844[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %1776 = tensor.empty() : tensor<1x12x1x64xf32>
    %1777 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_854 : tensor<1x12x1x64xf32>) outs(%1776 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %1778 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_855 = tensor.insert_slice %1777 into %1778[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_856 = tensor.insert_slice %extracted_slice_853 into %inserted_slice_855[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %1779 = tensor.empty() : tensor<1x12x1x128xf32>
    %1780 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_856, %expanded_852 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1779 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %1781 = tensor.empty() : tensor<1x12x1x128xf32>
    %1782 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1775, %1780 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%1781 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %1783 = tensor.empty() : tensor<1x2x1x128xf32>
    %1784 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_847, %expanded_851 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1783 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_857 = tensor.extract_slice %expanded_847[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_858 = tensor.extract_slice %expanded_847[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %1785 = tensor.empty() : tensor<1x2x1x64xf32>
    %1786 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_858 : tensor<1x2x1x64xf32>) outs(%1785 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %1787 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_859 = tensor.insert_slice %1786 into %1787[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_860 = tensor.insert_slice %extracted_slice_857 into %inserted_slice_859[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %1788 = tensor.empty() : tensor<1x2x1x128xf32>
    %1789 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_860, %expanded_852 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1788 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %1790 = tensor.empty() : tensor<1x2x1x128xf32>
    %1791 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1784, %1789 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%1790 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %1792 = bufferization.to_buffer %arg292 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_861 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %1793 = tensor.empty() : tensor<1x2x1x128xi64>
    %1794 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_861, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%1793 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %1795 = bufferization.to_buffer %1794 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %1796 = bufferization.to_buffer %1791 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %1796[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %1795[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %1792[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %1797 = bufferization.to_tensor %1792 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %1798 = bufferization.to_buffer %arg293 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_862 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %1799 = tensor.empty() : tensor<1x2x1x128xi64>
    %1800 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_862, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%1799 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %1801 = bufferization.to_buffer %1800 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %1802 = bufferization.to_buffer %expanded_850 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %1802[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %1801[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %1798[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %1803 = bufferization.to_tensor %1798 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_863 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %1804 = tensor.empty() : tensor<1x1x1x1024xf32>
    %1805 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_863, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%1804 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %1806 = bufferization.to_buffer %1782 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %1807 = bufferization.to_buffer %1805 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_864 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_865 = memref.alloc() : memref<1x12x1xf32>
    %alloc_866 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_866[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %1806[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %1792[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %1807[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %1798[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_866[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_866[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_865[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_866[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_864[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %1808 = bufferization.to_tensor %alloc_864 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_867 = tensor.collapse_shape %1808 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %1809 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_867, %arg294 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_868 = tensor.expand_shape %1809 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %1810 = tensor.empty() : tensor<1x1x1536xf32>
    %1811 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1750, %expanded_868 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1810 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1812 = tensor.empty() : tensor<1x1x1536xf32>
    %1813 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1811 : tensor<1x1x1536xf32>) outs(%1812 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1814 = tensor.empty() : tensor<1x1xf32>
    %cst_869 = arith.constant 0.000000e+00 : f32
    %1815 = linalg.fill ins(%cst_869 : f32) outs(%1814 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_870 = linalg.reduce ins(%1813 : tensor<1x1x1536xf32>) outs(%1815 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_871 = tensor.expand_shape %reduced_870 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %1816 = tensor.empty() : tensor<1x1x1xf32>
    %1817 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_871, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1816 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1818 = tensor.empty() : tensor<1x1x1xf32>
    %1819 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1817, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1818 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1820 = tensor.empty() : tensor<1x1x1xf32>
    %1821 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1819 : tensor<1x1x1xf32>) outs(%1820 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1822 = tensor.empty() : tensor<1x1x1536xf32>
    %1823 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1811, %1821 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%1822 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_872 = tensor.expand_shape %arg295 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %1824 = tensor.empty() : tensor<1x1x1536xf32>
    %1825 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_872, %1823 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1824 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_873 = tensor.collapse_shape %1825 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1826 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_873, %arg296 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_874 = tensor.expand_shape %1826 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %1827 = tensor.empty() : tensor<1x1x8960xf32>
    %1828 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_874 : tensor<1x1x8960xf32>) outs(%1827 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %1829 = tensor.empty() : tensor<1x1x8960xf32>
    %1830 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_874, %1828 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%1829 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_875 = tensor.collapse_shape %1825 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1831 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_875, %arg297 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_876 = tensor.expand_shape %1831 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %1832 = tensor.empty() : tensor<1x1x8960xf32>
    %1833 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1830, %expanded_876 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%1832 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_877 = tensor.collapse_shape %1833 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %1834 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_877, %arg298 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_878 = tensor.expand_shape %1834 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %1835 = tensor.empty() : tensor<1x1x1536xf32>
    %1836 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1811, %expanded_878 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1835 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1837 = tensor.empty() : tensor<1x1x1536xf32>
    %1838 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1836 : tensor<1x1x1536xf32>) outs(%1837 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1839 = tensor.empty() : tensor<1x1xf32>
    %cst_879 = arith.constant 0.000000e+00 : f32
    %1840 = linalg.fill ins(%cst_879 : f32) outs(%1839 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_880 = linalg.reduce ins(%1838 : tensor<1x1x1536xf32>) outs(%1840 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_881 = tensor.expand_shape %reduced_880 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %1841 = tensor.empty() : tensor<1x1x1xf32>
    %1842 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_881, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1841 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1843 = tensor.empty() : tensor<1x1x1xf32>
    %1844 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1842, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1843 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1845 = tensor.empty() : tensor<1x1x1xf32>
    %1846 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1844 : tensor<1x1x1xf32>) outs(%1845 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1847 = tensor.empty() : tensor<1x1x1536xf32>
    %1848 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1836, %1846 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%1847 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_882 = tensor.expand_shape %arg299 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %1849 = tensor.empty() : tensor<1x1x1536xf32>
    %1850 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_882, %1848 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1849 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_883 = tensor.collapse_shape %1850 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1851 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_883, %arg301 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_884 = tensor.expand_shape %arg300 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %1852 = tensor.empty() : tensor<1x1536xf32>
    %1853 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_884, %1851 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%1852 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_885 = tensor.expand_shape %1853 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_886 = tensor.collapse_shape %1850 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1854 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_886, %arg303 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_887 = tensor.expand_shape %arg302 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %1855 = tensor.empty() : tensor<1x256xf32>
    %1856 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_887, %1854 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%1855 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_888 = tensor.expand_shape %1856 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_889 = tensor.collapse_shape %1850 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1857 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_889, %arg305 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_890 = tensor.expand_shape %arg304 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %1858 = tensor.empty() : tensor<1x256xf32>
    %1859 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_890, %1857 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%1858 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_891 = tensor.expand_shape %1859 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_892 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_893 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %1860 = tensor.empty() : tensor<1x12x1x128xf32>
    %1861 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_885, %expanded_892 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1860 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_894 = tensor.extract_slice %expanded_885[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_895 = tensor.extract_slice %expanded_885[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %1862 = tensor.empty() : tensor<1x12x1x64xf32>
    %1863 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_895 : tensor<1x12x1x64xf32>) outs(%1862 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %1864 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_896 = tensor.insert_slice %1863 into %1864[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_897 = tensor.insert_slice %extracted_slice_894 into %inserted_slice_896[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %1865 = tensor.empty() : tensor<1x12x1x128xf32>
    %1866 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_897, %expanded_893 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1865 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %1867 = tensor.empty() : tensor<1x12x1x128xf32>
    %1868 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1861, %1866 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%1867 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %1869 = tensor.empty() : tensor<1x2x1x128xf32>
    %1870 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_888, %expanded_892 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1869 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_898 = tensor.extract_slice %expanded_888[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_899 = tensor.extract_slice %expanded_888[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %1871 = tensor.empty() : tensor<1x2x1x64xf32>
    %1872 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_899 : tensor<1x2x1x64xf32>) outs(%1871 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %1873 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_900 = tensor.insert_slice %1872 into %1873[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_901 = tensor.insert_slice %extracted_slice_898 into %inserted_slice_900[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %1874 = tensor.empty() : tensor<1x2x1x128xf32>
    %1875 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_901, %expanded_893 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1874 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %1876 = tensor.empty() : tensor<1x2x1x128xf32>
    %1877 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1870, %1875 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%1876 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %1878 = bufferization.to_buffer %arg306 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_902 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %1879 = tensor.empty() : tensor<1x2x1x128xi64>
    %1880 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_902, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%1879 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %1881 = bufferization.to_buffer %1880 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %1882 = bufferization.to_buffer %1877 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %1882[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %1881[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %1878[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %1883 = bufferization.to_tensor %1878 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %1884 = bufferization.to_buffer %arg307 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_903 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %1885 = tensor.empty() : tensor<1x2x1x128xi64>
    %1886 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_903, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%1885 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %1887 = bufferization.to_buffer %1886 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %1888 = bufferization.to_buffer %expanded_891 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %1888[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %1887[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %1884[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %1889 = bufferization.to_tensor %1884 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_904 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %1890 = tensor.empty() : tensor<1x1x1x1024xf32>
    %1891 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_904, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%1890 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %1892 = bufferization.to_buffer %1868 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %1893 = bufferization.to_buffer %1891 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_905 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_906 = memref.alloc() : memref<1x12x1xf32>
    %alloc_907 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_907[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %1892[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %1878[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %1893[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %1884[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_907[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_907[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_906[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_907[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_905[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %1894 = bufferization.to_tensor %alloc_905 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_908 = tensor.collapse_shape %1894 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %1895 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_908, %arg308 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_909 = tensor.expand_shape %1895 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %1896 = tensor.empty() : tensor<1x1x1536xf32>
    %1897 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1836, %expanded_909 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1896 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1898 = tensor.empty() : tensor<1x1x1536xf32>
    %1899 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1897 : tensor<1x1x1536xf32>) outs(%1898 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1900 = tensor.empty() : tensor<1x1xf32>
    %cst_910 = arith.constant 0.000000e+00 : f32
    %1901 = linalg.fill ins(%cst_910 : f32) outs(%1900 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_911 = linalg.reduce ins(%1899 : tensor<1x1x1536xf32>) outs(%1901 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_912 = tensor.expand_shape %reduced_911 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %1902 = tensor.empty() : tensor<1x1x1xf32>
    %1903 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_912, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1902 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1904 = tensor.empty() : tensor<1x1x1xf32>
    %1905 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1903, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1904 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1906 = tensor.empty() : tensor<1x1x1xf32>
    %1907 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1905 : tensor<1x1x1xf32>) outs(%1906 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1908 = tensor.empty() : tensor<1x1x1536xf32>
    %1909 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1897, %1907 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%1908 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_913 = tensor.expand_shape %arg309 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %1910 = tensor.empty() : tensor<1x1x1536xf32>
    %1911 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_913, %1909 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1910 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_914 = tensor.collapse_shape %1911 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1912 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_914, %arg310 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_915 = tensor.expand_shape %1912 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %1913 = tensor.empty() : tensor<1x1x8960xf32>
    %1914 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_915 : tensor<1x1x8960xf32>) outs(%1913 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %1915 = tensor.empty() : tensor<1x1x8960xf32>
    %1916 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_915, %1914 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%1915 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_916 = tensor.collapse_shape %1911 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1917 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_916, %arg311 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_917 = tensor.expand_shape %1917 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %1918 = tensor.empty() : tensor<1x1x8960xf32>
    %1919 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1916, %expanded_917 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%1918 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_918 = tensor.collapse_shape %1919 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %1920 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_918, %arg312 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_919 = tensor.expand_shape %1920 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %1921 = tensor.empty() : tensor<1x1x1536xf32>
    %1922 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1897, %expanded_919 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1921 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1923 = tensor.empty() : tensor<1x1x1536xf32>
    %1924 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1922 : tensor<1x1x1536xf32>) outs(%1923 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1925 = tensor.empty() : tensor<1x1xf32>
    %cst_920 = arith.constant 0.000000e+00 : f32
    %1926 = linalg.fill ins(%cst_920 : f32) outs(%1925 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_921 = linalg.reduce ins(%1924 : tensor<1x1x1536xf32>) outs(%1926 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_922 = tensor.expand_shape %reduced_921 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %1927 = tensor.empty() : tensor<1x1x1xf32>
    %1928 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_922, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1927 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1929 = tensor.empty() : tensor<1x1x1xf32>
    %1930 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1928, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1929 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1931 = tensor.empty() : tensor<1x1x1xf32>
    %1932 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1930 : tensor<1x1x1xf32>) outs(%1931 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1933 = tensor.empty() : tensor<1x1x1536xf32>
    %1934 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1922, %1932 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%1933 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_923 = tensor.expand_shape %arg313 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %1935 = tensor.empty() : tensor<1x1x1536xf32>
    %1936 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_923, %1934 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1935 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_924 = tensor.collapse_shape %1936 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1937 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_924, %arg315 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_925 = tensor.expand_shape %arg314 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %1938 = tensor.empty() : tensor<1x1536xf32>
    %1939 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_925, %1937 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%1938 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_926 = tensor.expand_shape %1939 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_927 = tensor.collapse_shape %1936 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1940 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_927, %arg317 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_928 = tensor.expand_shape %arg316 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %1941 = tensor.empty() : tensor<1x256xf32>
    %1942 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_928, %1940 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%1941 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_929 = tensor.expand_shape %1942 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_930 = tensor.collapse_shape %1936 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1943 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_930, %arg319 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_931 = tensor.expand_shape %arg318 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %1944 = tensor.empty() : tensor<1x256xf32>
    %1945 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_931, %1943 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%1944 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_932 = tensor.expand_shape %1945 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_933 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_934 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %1946 = tensor.empty() : tensor<1x12x1x128xf32>
    %1947 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_926, %expanded_933 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1946 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_935 = tensor.extract_slice %expanded_926[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_936 = tensor.extract_slice %expanded_926[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %1948 = tensor.empty() : tensor<1x12x1x64xf32>
    %1949 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_936 : tensor<1x12x1x64xf32>) outs(%1948 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %1950 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_937 = tensor.insert_slice %1949 into %1950[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_938 = tensor.insert_slice %extracted_slice_935 into %inserted_slice_937[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %1951 = tensor.empty() : tensor<1x12x1x128xf32>
    %1952 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_938, %expanded_934 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1951 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %1953 = tensor.empty() : tensor<1x12x1x128xf32>
    %1954 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1947, %1952 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%1953 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %1955 = tensor.empty() : tensor<1x2x1x128xf32>
    %1956 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_929, %expanded_933 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1955 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_939 = tensor.extract_slice %expanded_929[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_940 = tensor.extract_slice %expanded_929[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %1957 = tensor.empty() : tensor<1x2x1x64xf32>
    %1958 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_940 : tensor<1x2x1x64xf32>) outs(%1957 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %1959 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_941 = tensor.insert_slice %1958 into %1959[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_942 = tensor.insert_slice %extracted_slice_939 into %inserted_slice_941[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %1960 = tensor.empty() : tensor<1x2x1x128xf32>
    %1961 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_942, %expanded_934 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%1960 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %1962 = tensor.empty() : tensor<1x2x1x128xf32>
    %1963 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%1956, %1961 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%1962 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %1964 = bufferization.to_buffer %arg320 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_943 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %1965 = tensor.empty() : tensor<1x2x1x128xi64>
    %1966 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_943, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%1965 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %1967 = bufferization.to_buffer %1966 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %1968 = bufferization.to_buffer %1963 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %1968[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %1967[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %1964[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %1969 = bufferization.to_tensor %1964 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %1970 = bufferization.to_buffer %arg321 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_944 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %1971 = tensor.empty() : tensor<1x2x1x128xi64>
    %1972 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_944, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%1971 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %1973 = bufferization.to_buffer %1972 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %1974 = bufferization.to_buffer %expanded_932 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %1974[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %1973[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %1970[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %1975 = bufferization.to_tensor %1970 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_945 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %1976 = tensor.empty() : tensor<1x1x1x1024xf32>
    %1977 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_945, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%1976 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %1978 = bufferization.to_buffer %1954 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %1979 = bufferization.to_buffer %1977 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_946 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_947 = memref.alloc() : memref<1x12x1xf32>
    %alloc_948 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_948[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %1978[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %1964[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %1979[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %1970[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_948[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_948[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_947[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_948[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_946[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %1980 = bufferization.to_tensor %alloc_946 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_949 = tensor.collapse_shape %1980 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %1981 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_949, %arg322 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_950 = tensor.expand_shape %1981 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %1982 = tensor.empty() : tensor<1x1x1536xf32>
    %1983 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1922, %expanded_950 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1982 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1984 = tensor.empty() : tensor<1x1x1536xf32>
    %1985 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1983 : tensor<1x1x1536xf32>) outs(%1984 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %1986 = tensor.empty() : tensor<1x1xf32>
    %cst_951 = arith.constant 0.000000e+00 : f32
    %1987 = linalg.fill ins(%cst_951 : f32) outs(%1986 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_952 = linalg.reduce ins(%1985 : tensor<1x1x1536xf32>) outs(%1987 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_953 = tensor.expand_shape %reduced_952 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %1988 = tensor.empty() : tensor<1x1x1xf32>
    %1989 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_953, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1988 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1990 = tensor.empty() : tensor<1x1x1xf32>
    %1991 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1989, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%1990 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1992 = tensor.empty() : tensor<1x1x1xf32>
    %1993 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1991 : tensor<1x1x1xf32>) outs(%1992 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %1994 = tensor.empty() : tensor<1x1x1536xf32>
    %1995 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1983, %1993 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%1994 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_954 = tensor.expand_shape %arg323 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %1996 = tensor.empty() : tensor<1x1x1536xf32>
    %1997 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_954, %1995 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%1996 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_955 = tensor.collapse_shape %1997 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %1998 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_955, %arg324 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_956 = tensor.expand_shape %1998 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %1999 = tensor.empty() : tensor<1x1x8960xf32>
    %2000 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_956 : tensor<1x1x8960xf32>) outs(%1999 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %2001 = tensor.empty() : tensor<1x1x8960xf32>
    %2002 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_956, %2000 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%2001 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_957 = tensor.collapse_shape %1997 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2003 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_957, %arg325 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_958 = tensor.expand_shape %2003 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %2004 = tensor.empty() : tensor<1x1x8960xf32>
    %2005 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2002, %expanded_958 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%2004 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_959 = tensor.collapse_shape %2005 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %2006 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_959, %arg326 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_960 = tensor.expand_shape %2006 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %2007 = tensor.empty() : tensor<1x1x1536xf32>
    %2008 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%1983, %expanded_960 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%2007 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %2009 = tensor.empty() : tensor<1x1x1536xf32>
    %2010 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2008 : tensor<1x1x1536xf32>) outs(%2009 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %2011 = tensor.empty() : tensor<1x1xf32>
    %cst_961 = arith.constant 0.000000e+00 : f32
    %2012 = linalg.fill ins(%cst_961 : f32) outs(%2011 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_962 = linalg.reduce ins(%2010 : tensor<1x1x1536xf32>) outs(%2012 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_963 = tensor.expand_shape %reduced_962 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %2013 = tensor.empty() : tensor<1x1x1xf32>
    %2014 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_963, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%2013 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2015 = tensor.empty() : tensor<1x1x1xf32>
    %2016 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2014, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%2015 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2017 = tensor.empty() : tensor<1x1x1xf32>
    %2018 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2016 : tensor<1x1x1xf32>) outs(%2017 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2019 = tensor.empty() : tensor<1x1x1536xf32>
    %2020 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2008, %2018 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%2019 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_964 = tensor.expand_shape %arg327 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %2021 = tensor.empty() : tensor<1x1x1536xf32>
    %2022 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_964, %2020 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%2021 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_965 = tensor.collapse_shape %2022 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2023 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_965, %arg329 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_966 = tensor.expand_shape %arg328 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %2024 = tensor.empty() : tensor<1x1536xf32>
    %2025 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_966, %2023 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%2024 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_967 = tensor.expand_shape %2025 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_968 = tensor.collapse_shape %2022 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2026 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_968, %arg331 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_969 = tensor.expand_shape %arg330 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %2027 = tensor.empty() : tensor<1x256xf32>
    %2028 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_969, %2026 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%2027 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_970 = tensor.expand_shape %2028 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_971 = tensor.collapse_shape %2022 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2029 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_971, %arg333 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_972 = tensor.expand_shape %arg332 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %2030 = tensor.empty() : tensor<1x256xf32>
    %2031 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_972, %2029 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%2030 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_973 = tensor.expand_shape %2031 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_974 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_975 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %2032 = tensor.empty() : tensor<1x12x1x128xf32>
    %2033 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_967, %expanded_974 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%2032 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_976 = tensor.extract_slice %expanded_967[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_977 = tensor.extract_slice %expanded_967[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %2034 = tensor.empty() : tensor<1x12x1x64xf32>
    %2035 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_977 : tensor<1x12x1x64xf32>) outs(%2034 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %2036 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_978 = tensor.insert_slice %2035 into %2036[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_979 = tensor.insert_slice %extracted_slice_976 into %inserted_slice_978[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %2037 = tensor.empty() : tensor<1x12x1x128xf32>
    %2038 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_979, %expanded_975 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%2037 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %2039 = tensor.empty() : tensor<1x12x1x128xf32>
    %2040 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%2033, %2038 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%2039 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %2041 = tensor.empty() : tensor<1x2x1x128xf32>
    %2042 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_970, %expanded_974 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%2041 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_980 = tensor.extract_slice %expanded_970[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_981 = tensor.extract_slice %expanded_970[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %2043 = tensor.empty() : tensor<1x2x1x64xf32>
    %2044 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_981 : tensor<1x2x1x64xf32>) outs(%2043 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %2045 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_982 = tensor.insert_slice %2044 into %2045[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_983 = tensor.insert_slice %extracted_slice_980 into %inserted_slice_982[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %2046 = tensor.empty() : tensor<1x2x1x128xf32>
    %2047 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_983, %expanded_975 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%2046 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %2048 = tensor.empty() : tensor<1x2x1x128xf32>
    %2049 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%2042, %2047 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%2048 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %2050 = bufferization.to_buffer %arg334 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_984 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %2051 = tensor.empty() : tensor<1x2x1x128xi64>
    %2052 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_984, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%2051 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %2053 = bufferization.to_buffer %2052 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %2054 = bufferization.to_buffer %2049 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %2054[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %2053[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %2050[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %2055 = bufferization.to_tensor %2050 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %2056 = bufferization.to_buffer %arg335 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_985 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %2057 = tensor.empty() : tensor<1x2x1x128xi64>
    %2058 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_985, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%2057 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %2059 = bufferization.to_buffer %2058 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %2060 = bufferization.to_buffer %expanded_973 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %2060[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %2059[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %2056[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %2061 = bufferization.to_tensor %2056 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_986 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %2062 = tensor.empty() : tensor<1x1x1x1024xf32>
    %2063 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_986, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%2062 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %2064 = bufferization.to_buffer %2040 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %2065 = bufferization.to_buffer %2063 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_987 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_988 = memref.alloc() : memref<1x12x1xf32>
    %alloc_989 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_989[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %2064[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %2050[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %2065[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %2056[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_989[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_989[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_988[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_989[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_987[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %2066 = bufferization.to_tensor %alloc_987 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_990 = tensor.collapse_shape %2066 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %2067 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_990, %arg336 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_991 = tensor.expand_shape %2067 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %2068 = tensor.empty() : tensor<1x1x1536xf32>
    %2069 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2008, %expanded_991 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%2068 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %2070 = tensor.empty() : tensor<1x1x1536xf32>
    %2071 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2069 : tensor<1x1x1536xf32>) outs(%2070 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %2072 = tensor.empty() : tensor<1x1xf32>
    %cst_992 = arith.constant 0.000000e+00 : f32
    %2073 = linalg.fill ins(%cst_992 : f32) outs(%2072 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_993 = linalg.reduce ins(%2071 : tensor<1x1x1536xf32>) outs(%2073 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_994 = tensor.expand_shape %reduced_993 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %2074 = tensor.empty() : tensor<1x1x1xf32>
    %2075 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_994, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%2074 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2076 = tensor.empty() : tensor<1x1x1xf32>
    %2077 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2075, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%2076 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2078 = tensor.empty() : tensor<1x1x1xf32>
    %2079 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2077 : tensor<1x1x1xf32>) outs(%2078 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2080 = tensor.empty() : tensor<1x1x1536xf32>
    %2081 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2069, %2079 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%2080 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_995 = tensor.expand_shape %arg337 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %2082 = tensor.empty() : tensor<1x1x1536xf32>
    %2083 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_995, %2081 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%2082 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_996 = tensor.collapse_shape %2083 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2084 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_996, %arg338 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_997 = tensor.expand_shape %2084 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %2085 = tensor.empty() : tensor<1x1x8960xf32>
    %2086 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_997 : tensor<1x1x8960xf32>) outs(%2085 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %2087 = tensor.empty() : tensor<1x1x8960xf32>
    %2088 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_997, %2086 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%2087 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_998 = tensor.collapse_shape %2083 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2089 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_998, %arg339 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_999 = tensor.expand_shape %2089 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %2090 = tensor.empty() : tensor<1x1x8960xf32>
    %2091 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2088, %expanded_999 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%2090 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_1000 = tensor.collapse_shape %2091 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %2092 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1000, %arg340 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_1001 = tensor.expand_shape %2092 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %2093 = tensor.empty() : tensor<1x1x1536xf32>
    %2094 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2069, %expanded_1001 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%2093 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %2095 = tensor.empty() : tensor<1x1x1536xf32>
    %2096 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2094 : tensor<1x1x1536xf32>) outs(%2095 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %2097 = tensor.empty() : tensor<1x1xf32>
    %cst_1002 = arith.constant 0.000000e+00 : f32
    %2098 = linalg.fill ins(%cst_1002 : f32) outs(%2097 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_1003 = linalg.reduce ins(%2096 : tensor<1x1x1536xf32>) outs(%2098 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_1004 = tensor.expand_shape %reduced_1003 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %2099 = tensor.empty() : tensor<1x1x1xf32>
    %2100 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1004, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%2099 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2101 = tensor.empty() : tensor<1x1x1xf32>
    %2102 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2100, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%2101 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2103 = tensor.empty() : tensor<1x1x1xf32>
    %2104 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2102 : tensor<1x1x1xf32>) outs(%2103 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2105 = tensor.empty() : tensor<1x1x1536xf32>
    %2106 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2094, %2104 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%2105 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_1005 = tensor.expand_shape %arg341 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %2107 = tensor.empty() : tensor<1x1x1536xf32>
    %2108 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1005, %2106 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%2107 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_1006 = tensor.collapse_shape %2108 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2109 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1006, %arg343 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_1007 = tensor.expand_shape %arg342 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %2110 = tensor.empty() : tensor<1x1536xf32>
    %2111 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_1007, %2109 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%2110 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_1008 = tensor.expand_shape %2111 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_1009 = tensor.collapse_shape %2108 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2112 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1009, %arg345 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_1010 = tensor.expand_shape %arg344 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %2113 = tensor.empty() : tensor<1x256xf32>
    %2114 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_1010, %2112 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%2113 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_1011 = tensor.expand_shape %2114 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_1012 = tensor.collapse_shape %2108 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2115 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1012, %arg347 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_1013 = tensor.expand_shape %arg346 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %2116 = tensor.empty() : tensor<1x256xf32>
    %2117 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_1013, %2115 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%2116 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_1014 = tensor.expand_shape %2117 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_1015 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_1016 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %2118 = tensor.empty() : tensor<1x12x1x128xf32>
    %2119 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_1008, %expanded_1015 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%2118 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_1017 = tensor.extract_slice %expanded_1008[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_1018 = tensor.extract_slice %expanded_1008[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %2120 = tensor.empty() : tensor<1x12x1x64xf32>
    %2121 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_1018 : tensor<1x12x1x64xf32>) outs(%2120 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %2122 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_1019 = tensor.insert_slice %2121 into %2122[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_1020 = tensor.insert_slice %extracted_slice_1017 into %inserted_slice_1019[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %2123 = tensor.empty() : tensor<1x12x1x128xf32>
    %2124 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_1020, %expanded_1016 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%2123 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %2125 = tensor.empty() : tensor<1x12x1x128xf32>
    %2126 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%2119, %2124 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%2125 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %2127 = tensor.empty() : tensor<1x2x1x128xf32>
    %2128 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_1011, %expanded_1015 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%2127 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_1021 = tensor.extract_slice %expanded_1011[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_1022 = tensor.extract_slice %expanded_1011[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %2129 = tensor.empty() : tensor<1x2x1x64xf32>
    %2130 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_1022 : tensor<1x2x1x64xf32>) outs(%2129 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %2131 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_1023 = tensor.insert_slice %2130 into %2131[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_1024 = tensor.insert_slice %extracted_slice_1021 into %inserted_slice_1023[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %2132 = tensor.empty() : tensor<1x2x1x128xf32>
    %2133 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_1024, %expanded_1016 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%2132 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %2134 = tensor.empty() : tensor<1x2x1x128xf32>
    %2135 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%2128, %2133 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%2134 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %2136 = bufferization.to_buffer %arg348 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_1025 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %2137 = tensor.empty() : tensor<1x2x1x128xi64>
    %2138 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_1025, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%2137 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %2139 = bufferization.to_buffer %2138 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %2140 = bufferization.to_buffer %2135 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %2140[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %2139[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %2136[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %2141 = bufferization.to_tensor %2136 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %2142 = bufferization.to_buffer %arg349 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_1026 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %2143 = tensor.empty() : tensor<1x2x1x128xi64>
    %2144 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_1026, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%2143 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %2145 = bufferization.to_buffer %2144 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %2146 = bufferization.to_buffer %expanded_1014 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %2146[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %2145[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %2142[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %2147 = bufferization.to_tensor %2142 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_1027 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %2148 = tensor.empty() : tensor<1x1x1x1024xf32>
    %2149 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_1027, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%2148 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %2150 = bufferization.to_buffer %2126 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %2151 = bufferization.to_buffer %2149 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_1028 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_1029 = memref.alloc() : memref<1x12x1xf32>
    %alloc_1030 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_1030[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %2150[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %2136[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %2151[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %2142[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_1030[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_1030[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_1029[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_1030[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_1028[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %2152 = bufferization.to_tensor %alloc_1028 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_1031 = tensor.collapse_shape %2152 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %2153 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1031, %arg350 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_1032 = tensor.expand_shape %2153 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %2154 = tensor.empty() : tensor<1x1x1536xf32>
    %2155 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2094, %expanded_1032 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%2154 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %2156 = tensor.empty() : tensor<1x1x1536xf32>
    %2157 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2155 : tensor<1x1x1536xf32>) outs(%2156 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %2158 = tensor.empty() : tensor<1x1xf32>
    %cst_1033 = arith.constant 0.000000e+00 : f32
    %2159 = linalg.fill ins(%cst_1033 : f32) outs(%2158 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_1034 = linalg.reduce ins(%2157 : tensor<1x1x1536xf32>) outs(%2159 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_1035 = tensor.expand_shape %reduced_1034 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %2160 = tensor.empty() : tensor<1x1x1xf32>
    %2161 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1035, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%2160 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2162 = tensor.empty() : tensor<1x1x1xf32>
    %2163 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2161, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%2162 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2164 = tensor.empty() : tensor<1x1x1xf32>
    %2165 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2163 : tensor<1x1x1xf32>) outs(%2164 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2166 = tensor.empty() : tensor<1x1x1536xf32>
    %2167 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2155, %2165 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%2166 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_1036 = tensor.expand_shape %arg351 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %2168 = tensor.empty() : tensor<1x1x1536xf32>
    %2169 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1036, %2167 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%2168 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_1037 = tensor.collapse_shape %2169 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2170 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1037, %arg352 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_1038 = tensor.expand_shape %2170 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %2171 = tensor.empty() : tensor<1x1x8960xf32>
    %2172 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1038 : tensor<1x1x8960xf32>) outs(%2171 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %2173 = tensor.empty() : tensor<1x1x8960xf32>
    %2174 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1038, %2172 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%2173 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_1039 = tensor.collapse_shape %2169 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2175 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1039, %arg353 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_1040 = tensor.expand_shape %2175 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %2176 = tensor.empty() : tensor<1x1x8960xf32>
    %2177 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2174, %expanded_1040 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%2176 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_1041 = tensor.collapse_shape %2177 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %2178 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1041, %arg354 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_1042 = tensor.expand_shape %2178 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %2179 = tensor.empty() : tensor<1x1x1536xf32>
    %2180 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2155, %expanded_1042 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%2179 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %2181 = tensor.empty() : tensor<1x1x1536xf32>
    %2182 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2180 : tensor<1x1x1536xf32>) outs(%2181 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %2183 = tensor.empty() : tensor<1x1xf32>
    %cst_1043 = arith.constant 0.000000e+00 : f32
    %2184 = linalg.fill ins(%cst_1043 : f32) outs(%2183 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_1044 = linalg.reduce ins(%2182 : tensor<1x1x1536xf32>) outs(%2184 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_1045 = tensor.expand_shape %reduced_1044 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %2185 = tensor.empty() : tensor<1x1x1xf32>
    %2186 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1045, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%2185 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2187 = tensor.empty() : tensor<1x1x1xf32>
    %2188 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2186, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%2187 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2189 = tensor.empty() : tensor<1x1x1xf32>
    %2190 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2188 : tensor<1x1x1xf32>) outs(%2189 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2191 = tensor.empty() : tensor<1x1x1536xf32>
    %2192 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2180, %2190 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%2191 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_1046 = tensor.expand_shape %arg355 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %2193 = tensor.empty() : tensor<1x1x1536xf32>
    %2194 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1046, %2192 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%2193 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_1047 = tensor.collapse_shape %2194 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2195 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1047, %arg357 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_1048 = tensor.expand_shape %arg356 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %2196 = tensor.empty() : tensor<1x1536xf32>
    %2197 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_1048, %2195 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%2196 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_1049 = tensor.expand_shape %2197 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_1050 = tensor.collapse_shape %2194 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2198 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1050, %arg359 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_1051 = tensor.expand_shape %arg358 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %2199 = tensor.empty() : tensor<1x256xf32>
    %2200 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_1051, %2198 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%2199 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_1052 = tensor.expand_shape %2200 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_1053 = tensor.collapse_shape %2194 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2201 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1053, %arg361 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_1054 = tensor.expand_shape %arg360 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %2202 = tensor.empty() : tensor<1x256xf32>
    %2203 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_1054, %2201 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%2202 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_1055 = tensor.expand_shape %2203 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_1056 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_1057 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %2204 = tensor.empty() : tensor<1x12x1x128xf32>
    %2205 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_1049, %expanded_1056 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%2204 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_1058 = tensor.extract_slice %expanded_1049[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_1059 = tensor.extract_slice %expanded_1049[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %2206 = tensor.empty() : tensor<1x12x1x64xf32>
    %2207 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_1059 : tensor<1x12x1x64xf32>) outs(%2206 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %2208 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_1060 = tensor.insert_slice %2207 into %2208[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_1061 = tensor.insert_slice %extracted_slice_1058 into %inserted_slice_1060[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %2209 = tensor.empty() : tensor<1x12x1x128xf32>
    %2210 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_1061, %expanded_1057 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%2209 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %2211 = tensor.empty() : tensor<1x12x1x128xf32>
    %2212 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%2205, %2210 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%2211 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %2213 = tensor.empty() : tensor<1x2x1x128xf32>
    %2214 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_1052, %expanded_1056 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%2213 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_1062 = tensor.extract_slice %expanded_1052[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_1063 = tensor.extract_slice %expanded_1052[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %2215 = tensor.empty() : tensor<1x2x1x64xf32>
    %2216 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_1063 : tensor<1x2x1x64xf32>) outs(%2215 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %2217 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_1064 = tensor.insert_slice %2216 into %2217[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_1065 = tensor.insert_slice %extracted_slice_1062 into %inserted_slice_1064[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %2218 = tensor.empty() : tensor<1x2x1x128xf32>
    %2219 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_1065, %expanded_1057 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%2218 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %2220 = tensor.empty() : tensor<1x2x1x128xf32>
    %2221 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%2214, %2219 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%2220 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %2222 = bufferization.to_buffer %arg362 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_1066 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %2223 = tensor.empty() : tensor<1x2x1x128xi64>
    %2224 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_1066, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%2223 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %2225 = bufferization.to_buffer %2224 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %2226 = bufferization.to_buffer %2221 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %2226[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %2225[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %2222[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %2227 = bufferization.to_tensor %2222 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %2228 = bufferization.to_buffer %arg363 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_1067 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %2229 = tensor.empty() : tensor<1x2x1x128xi64>
    %2230 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_1067, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%2229 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %2231 = bufferization.to_buffer %2230 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %2232 = bufferization.to_buffer %expanded_1055 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %2232[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %2231[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %2228[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %2233 = bufferization.to_tensor %2228 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_1068 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %2234 = tensor.empty() : tensor<1x1x1x1024xf32>
    %2235 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_1068, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%2234 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %2236 = bufferization.to_buffer %2212 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %2237 = bufferization.to_buffer %2235 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_1069 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_1070 = memref.alloc() : memref<1x12x1xf32>
    %alloc_1071 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_1071[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %2236[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %2222[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %2237[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %2228[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_1071[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_1071[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_1070[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_1071[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_1069[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %2238 = bufferization.to_tensor %alloc_1069 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_1072 = tensor.collapse_shape %2238 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %2239 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1072, %arg364 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_1073 = tensor.expand_shape %2239 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %2240 = tensor.empty() : tensor<1x1x1536xf32>
    %2241 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2180, %expanded_1073 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%2240 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %2242 = tensor.empty() : tensor<1x1x1536xf32>
    %2243 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2241 : tensor<1x1x1536xf32>) outs(%2242 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %2244 = tensor.empty() : tensor<1x1xf32>
    %cst_1074 = arith.constant 0.000000e+00 : f32
    %2245 = linalg.fill ins(%cst_1074 : f32) outs(%2244 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_1075 = linalg.reduce ins(%2243 : tensor<1x1x1536xf32>) outs(%2245 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_1076 = tensor.expand_shape %reduced_1075 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %2246 = tensor.empty() : tensor<1x1x1xf32>
    %2247 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1076, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%2246 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2248 = tensor.empty() : tensor<1x1x1xf32>
    %2249 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2247, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%2248 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2250 = tensor.empty() : tensor<1x1x1xf32>
    %2251 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2249 : tensor<1x1x1xf32>) outs(%2250 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2252 = tensor.empty() : tensor<1x1x1536xf32>
    %2253 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2241, %2251 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%2252 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_1077 = tensor.expand_shape %arg365 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %2254 = tensor.empty() : tensor<1x1x1536xf32>
    %2255 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1077, %2253 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%2254 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_1078 = tensor.collapse_shape %2255 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2256 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1078, %arg366 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_1079 = tensor.expand_shape %2256 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %2257 = tensor.empty() : tensor<1x1x8960xf32>
    %2258 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1079 : tensor<1x1x8960xf32>) outs(%2257 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %2259 = tensor.empty() : tensor<1x1x8960xf32>
    %2260 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1079, %2258 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%2259 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_1080 = tensor.collapse_shape %2255 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2261 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1080, %arg367 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_1081 = tensor.expand_shape %2261 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %2262 = tensor.empty() : tensor<1x1x8960xf32>
    %2263 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2260, %expanded_1081 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%2262 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_1082 = tensor.collapse_shape %2263 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %2264 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1082, %arg368 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_1083 = tensor.expand_shape %2264 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %2265 = tensor.empty() : tensor<1x1x1536xf32>
    %2266 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2241, %expanded_1083 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%2265 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %2267 = tensor.empty() : tensor<1x1x1536xf32>
    %2268 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2266 : tensor<1x1x1536xf32>) outs(%2267 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %2269 = tensor.empty() : tensor<1x1xf32>
    %cst_1084 = arith.constant 0.000000e+00 : f32
    %2270 = linalg.fill ins(%cst_1084 : f32) outs(%2269 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_1085 = linalg.reduce ins(%2268 : tensor<1x1x1536xf32>) outs(%2270 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_1086 = tensor.expand_shape %reduced_1085 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %2271 = tensor.empty() : tensor<1x1x1xf32>
    %2272 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1086, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%2271 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2273 = tensor.empty() : tensor<1x1x1xf32>
    %2274 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2272, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%2273 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2275 = tensor.empty() : tensor<1x1x1xf32>
    %2276 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2274 : tensor<1x1x1xf32>) outs(%2275 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2277 = tensor.empty() : tensor<1x1x1536xf32>
    %2278 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2266, %2276 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%2277 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_1087 = tensor.expand_shape %arg369 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %2279 = tensor.empty() : tensor<1x1x1536xf32>
    %2280 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1087, %2278 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%2279 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_1088 = tensor.collapse_shape %2280 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2281 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1088, %arg371 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_1089 = tensor.expand_shape %arg370 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %2282 = tensor.empty() : tensor<1x1536xf32>
    %2283 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_1089, %2281 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%2282 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_1090 = tensor.expand_shape %2283 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_1091 = tensor.collapse_shape %2280 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2284 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1091, %arg373 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_1092 = tensor.expand_shape %arg372 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %2285 = tensor.empty() : tensor<1x256xf32>
    %2286 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_1092, %2284 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%2285 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_1093 = tensor.expand_shape %2286 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_1094 = tensor.collapse_shape %2280 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2287 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1094, %arg375 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_1095 = tensor.expand_shape %arg374 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %2288 = tensor.empty() : tensor<1x256xf32>
    %2289 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_1095, %2287 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%2288 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_1096 = tensor.expand_shape %2289 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_1097 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_1098 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %2290 = tensor.empty() : tensor<1x12x1x128xf32>
    %2291 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_1090, %expanded_1097 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%2290 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_1099 = tensor.extract_slice %expanded_1090[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_1100 = tensor.extract_slice %expanded_1090[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %2292 = tensor.empty() : tensor<1x12x1x64xf32>
    %2293 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_1100 : tensor<1x12x1x64xf32>) outs(%2292 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %2294 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_1101 = tensor.insert_slice %2293 into %2294[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_1102 = tensor.insert_slice %extracted_slice_1099 into %inserted_slice_1101[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %2295 = tensor.empty() : tensor<1x12x1x128xf32>
    %2296 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_1102, %expanded_1098 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%2295 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %2297 = tensor.empty() : tensor<1x12x1x128xf32>
    %2298 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%2291, %2296 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%2297 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %2299 = tensor.empty() : tensor<1x2x1x128xf32>
    %2300 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_1093, %expanded_1097 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%2299 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_1103 = tensor.extract_slice %expanded_1093[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_1104 = tensor.extract_slice %expanded_1093[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %2301 = tensor.empty() : tensor<1x2x1x64xf32>
    %2302 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_1104 : tensor<1x2x1x64xf32>) outs(%2301 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %2303 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_1105 = tensor.insert_slice %2302 into %2303[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_1106 = tensor.insert_slice %extracted_slice_1103 into %inserted_slice_1105[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %2304 = tensor.empty() : tensor<1x2x1x128xf32>
    %2305 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_1106, %expanded_1098 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%2304 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %2306 = tensor.empty() : tensor<1x2x1x128xf32>
    %2307 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%2300, %2305 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%2306 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %2308 = bufferization.to_buffer %arg376 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_1107 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %2309 = tensor.empty() : tensor<1x2x1x128xi64>
    %2310 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_1107, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%2309 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %2311 = bufferization.to_buffer %2310 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %2312 = bufferization.to_buffer %2307 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %2312[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %2311[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %2308[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %2313 = bufferization.to_tensor %2308 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %2314 = bufferization.to_buffer %arg377 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_1108 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %2315 = tensor.empty() : tensor<1x2x1x128xi64>
    %2316 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_1108, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%2315 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %2317 = bufferization.to_buffer %2316 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %2318 = bufferization.to_buffer %expanded_1096 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %2318[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %2317[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %2314[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %2319 = bufferization.to_tensor %2314 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_1109 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %2320 = tensor.empty() : tensor<1x1x1x1024xf32>
    %2321 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_1109, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%2320 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %2322 = bufferization.to_buffer %2298 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %2323 = bufferization.to_buffer %2321 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_1110 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_1111 = memref.alloc() : memref<1x12x1xf32>
    %alloc_1112 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_1112[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %2322[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %2308[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %2323[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %2314[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_1112[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_1112[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_1111[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_1112[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_1110[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %2324 = bufferization.to_tensor %alloc_1110 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_1113 = tensor.collapse_shape %2324 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %2325 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1113, %arg378 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_1114 = tensor.expand_shape %2325 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %2326 = tensor.empty() : tensor<1x1x1536xf32>
    %2327 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2266, %expanded_1114 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%2326 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %2328 = tensor.empty() : tensor<1x1x1536xf32>
    %2329 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2327 : tensor<1x1x1536xf32>) outs(%2328 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %2330 = tensor.empty() : tensor<1x1xf32>
    %cst_1115 = arith.constant 0.000000e+00 : f32
    %2331 = linalg.fill ins(%cst_1115 : f32) outs(%2330 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_1116 = linalg.reduce ins(%2329 : tensor<1x1x1536xf32>) outs(%2331 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_1117 = tensor.expand_shape %reduced_1116 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %2332 = tensor.empty() : tensor<1x1x1xf32>
    %2333 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1117, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%2332 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2334 = tensor.empty() : tensor<1x1x1xf32>
    %2335 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2333, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%2334 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2336 = tensor.empty() : tensor<1x1x1xf32>
    %2337 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2335 : tensor<1x1x1xf32>) outs(%2336 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2338 = tensor.empty() : tensor<1x1x1536xf32>
    %2339 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2327, %2337 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%2338 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_1118 = tensor.expand_shape %arg379 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %2340 = tensor.empty() : tensor<1x1x1536xf32>
    %2341 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1118, %2339 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%2340 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_1119 = tensor.collapse_shape %2341 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2342 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1119, %arg380 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_1120 = tensor.expand_shape %2342 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %2343 = tensor.empty() : tensor<1x1x8960xf32>
    %2344 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1120 : tensor<1x1x8960xf32>) outs(%2343 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %2345 = tensor.empty() : tensor<1x1x8960xf32>
    %2346 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1120, %2344 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%2345 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_1121 = tensor.collapse_shape %2341 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2347 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1121, %arg381 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_1122 = tensor.expand_shape %2347 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %2348 = tensor.empty() : tensor<1x1x8960xf32>
    %2349 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2346, %expanded_1122 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%2348 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_1123 = tensor.collapse_shape %2349 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %2350 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1123, %arg382 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_1124 = tensor.expand_shape %2350 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %2351 = tensor.empty() : tensor<1x1x1536xf32>
    %2352 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2327, %expanded_1124 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%2351 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %2353 = tensor.empty() : tensor<1x1x1536xf32>
    %2354 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2352 : tensor<1x1x1536xf32>) outs(%2353 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %2355 = tensor.empty() : tensor<1x1xf32>
    %cst_1125 = arith.constant 0.000000e+00 : f32
    %2356 = linalg.fill ins(%cst_1125 : f32) outs(%2355 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_1126 = linalg.reduce ins(%2354 : tensor<1x1x1536xf32>) outs(%2356 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_1127 = tensor.expand_shape %reduced_1126 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %2357 = tensor.empty() : tensor<1x1x1xf32>
    %2358 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1127, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%2357 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2359 = tensor.empty() : tensor<1x1x1xf32>
    %2360 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2358, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%2359 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2361 = tensor.empty() : tensor<1x1x1xf32>
    %2362 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2360 : tensor<1x1x1xf32>) outs(%2361 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2363 = tensor.empty() : tensor<1x1x1536xf32>
    %2364 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2352, %2362 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%2363 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_1128 = tensor.expand_shape %arg383 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %2365 = tensor.empty() : tensor<1x1x1536xf32>
    %2366 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1128, %2364 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%2365 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_1129 = tensor.collapse_shape %2366 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2367 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1129, %arg385 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_1130 = tensor.expand_shape %arg384 [[0, 1]] output_shape [1, 1536] : tensor<1536xf32> into tensor<1x1536xf32>
    %2368 = tensor.empty() : tensor<1x1536xf32>
    %2369 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_1130, %2367 : tensor<1x1536xf32>, tensor<1x1536xf32>) outs(%2368 : tensor<1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1536xf32>
    %expanded_1131 = tensor.expand_shape %2369 [[0], [1, 2, 3]] output_shape [1, 12, 1, 128] : tensor<1x1536xf32> into tensor<1x12x1x128xf32>
    %collapsed_1132 = tensor.collapse_shape %2366 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2370 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1132, %arg387 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_1133 = tensor.expand_shape %arg386 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %2371 = tensor.empty() : tensor<1x256xf32>
    %2372 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_1133, %2370 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%2371 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_1134 = tensor.expand_shape %2372 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %collapsed_1135 = tensor.collapse_shape %2366 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2373 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1135, %arg389 : tensor<1x1536xf32>, tensor<1536x256xf32>) outs(%cst_11 : tensor<1x256xf32>) -> tensor<1x256xf32>
    %expanded_1136 = tensor.expand_shape %arg388 [[0, 1]] output_shape [1, 256] : tensor<256xf32> into tensor<1x256xf32>
    %2374 = tensor.empty() : tensor<1x256xf32>
    %2375 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%expanded_1136, %2373 : tensor<1x256xf32>, tensor<1x256xf32>) outs(%2374 : tensor<1x256xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x256xf32>
    %expanded_1137 = tensor.expand_shape %2375 [[0], [1, 2, 3]] output_shape [1, 2, 1, 128] : tensor<1x256xf32> into tensor<1x2x1x128xf32>
    %expanded_1138 = tensor.expand_shape %29 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %expanded_1139 = tensor.expand_shape %30 [[0], [1, 2], [3]] output_shape [1, 1, 1, 128] : tensor<1x1x128xf32> into tensor<1x1x1x128xf32>
    %2376 = tensor.empty() : tensor<1x12x1x128xf32>
    %2377 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_1131, %expanded_1138 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%2376 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %extracted_slice_1140 = tensor.extract_slice %expanded_1131[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %extracted_slice_1141 = tensor.extract_slice %expanded_1131[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x128xf32> to tensor<1x12x1x64xf32>
    %2378 = tensor.empty() : tensor<1x12x1x64xf32>
    %2379 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_1141 : tensor<1x12x1x64xf32>) outs(%2378 : tensor<1x12x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x64xf32>
    %2380 = tensor.empty() : tensor<1x12x1x128xf32>
    %inserted_slice_1142 = tensor.insert_slice %2379 into %2380[0, 0, 0, 0] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %inserted_slice_1143 = tensor.insert_slice %extracted_slice_1140 into %inserted_slice_1142[0, 0, 0, 64] [1, 12, 1, 64] [1, 1, 1, 1] : tensor<1x12x1x64xf32> into tensor<1x12x1x128xf32>
    %2381 = tensor.empty() : tensor<1x12x1x128xf32>
    %2382 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_1143, %expanded_1139 : tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) outs(%2381 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %2383 = tensor.empty() : tensor<1x12x1x128xf32>
    %2384 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%2377, %2382 : tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) outs(%2383 : tensor<1x12x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x12x1x128xf32>
    %2385 = tensor.empty() : tensor<1x2x1x128xf32>
    %2386 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_1134, %expanded_1138 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%2385 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %extracted_slice_1144 = tensor.extract_slice %expanded_1134[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %extracted_slice_1145 = tensor.extract_slice %expanded_1134[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x128xf32> to tensor<1x2x1x64xf32>
    %2387 = tensor.empty() : tensor<1x2x1x64xf32>
    %2388 = linalg.generic {indexing_maps = [#map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_1145 : tensor<1x2x1x64xf32>) outs(%2387 : tensor<1x2x1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = arith.negf %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x64xf32>
    %2389 = tensor.empty() : tensor<1x2x1x128xf32>
    %inserted_slice_1146 = tensor.insert_slice %2388 into %2389[0, 0, 0, 0] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %inserted_slice_1147 = tensor.insert_slice %extracted_slice_1144 into %inserted_slice_1146[0, 0, 0, 64] [1, 2, 1, 64] [1, 1, 1, 1] : tensor<1x2x1x64xf32> into tensor<1x2x1x128xf32>
    %2390 = tensor.empty() : tensor<1x2x1x128xf32>
    %2391 = linalg.generic {indexing_maps = [#map6, #map8, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%inserted_slice_1147, %expanded_1139 : tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) outs(%2390 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %2392 = tensor.empty() : tensor<1x2x1x128xf32>
    %2393 = linalg.generic {indexing_maps = [#map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%2386, %2391 : tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) outs(%2392 : tensor<1x2x1x128xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x2x1x128xf32>
    %2394 = bufferization.to_buffer %arg390 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_1148 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %2395 = tensor.empty() : tensor<1x2x1x128xi64>
    %2396 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_1148, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%2395 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %2397 = bufferization.to_buffer %2396 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %2398 = bufferization.to_buffer %2393 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %2398[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %2397[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %2394[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %2399 = bufferization.to_tensor %2394 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %2400 = bufferization.to_buffer %arg391 : tensor<1x2x1024x128xf32> to memref<1x2x1024x128xf32>
    %expanded_1149 = tensor.expand_shape %arg3 [[0, 1, 2, 3]] output_shape [1, 1, 1, 1] : tensor<1xi64> into tensor<1x1x1x1xi64>
    %2401 = tensor.empty() : tensor<1x2x1x128xi64>
    %2402 = linalg.generic {indexing_maps = [#map9, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_1149, %cst_10 : tensor<1x1x1x1xi64>, tensor<1x2x1x128xi64>) outs(%2401 : tensor<1x2x1x128xi64>) {
    ^bb0(%in: i64, %in_1172: i64, %out: i64):
      %2454 = arith.addi %in, %in_1172 : i64
      linalg.yield %2454 : i64
    } -> tensor<1x2x1x128xi64>
    %2403 = bufferization.to_buffer %2402 : tensor<1x2x1x128xi64> to memref<1x2x1x128xi64>
    %2404 = bufferization.to_buffer %expanded_1137 : tensor<1x2x1x128xf32> to memref<1x2x1x128xf32>
    scf.for %arg399 = %c0 to %c1 step %c1 {
      scf.for %arg400 = %c0 to %c2 step %c1 {
        scf.for %arg401 = %c0 to %c1 step %c1 {
          scf.for %arg402 = %c0 to %c128 step %c1 {
            %2454 = memref.load %2404[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xf32>
            %2455 = memref.load %2403[%arg399, %arg400, %arg401, %arg402] : memref<1x2x1x128xi64>
            %2456 = arith.index_cast %2455 : i64 to index
            memref.store %2454, %2400[%arg399, %arg400, %2456, %arg402] : memref<1x2x1024x128xf32>
          }
        }
      }
    }
    %2405 = bufferization.to_tensor %2400 restrict : memref<1x2x1024x128xf32> to tensor<1x2x1024x128xf32>
    %expanded_1150 = tensor.expand_shape %22 [[0, 1, 2], [3]] output_shape [1, 1, 1, 1024] : tensor<1x1024xi1> into tensor<1x1x1x1024xi1>
    %2406 = tensor.empty() : tensor<1x1x1x1024xf32>
    %2407 = linalg.generic {indexing_maps = [#map6, #map6, #map6, #map6], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%expanded_1150, %cst_1, %cst_0 : tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) outs(%2406 : tensor<1x1x1x1024xf32>) {
    ^bb0(%in: i1, %in_1172: f32, %in_1173: f32, %out: f32):
      %2454 = arith.select %in, %in_1172, %in_1173 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1x1024xf32>
    %2408 = bufferization.to_buffer %2384 : tensor<1x12x1x128xf32> to memref<1x12x1x128xf32>
    %2409 = bufferization.to_buffer %2407 : tensor<1x1x1x1024xf32> to memref<1x1x1x1024xf32>
    %alloc_1151 = memref.alloc() : memref<1x12x1x128xf32>
    %alloc_1152 = memref.alloc() : memref<1x12x1xf32>
    %alloc_1153 = memref.alloc() : memref<128xf32>
    affine.for %arg399 = 0 to 1 {
      affine.for %arg400 = 0 to 12 {
        %2454 = arith.divsi %arg400, %c6 : index
        affine.for %arg401 = 0 to 1 {
          affine.for %arg402 = 0 to 128 {
            memref.store %cst_9, %alloc_1153[%arg402] : memref<128xf32>
          }
          %2455:2 = affine.for %arg402 = 0 to 1024 iter_args(%arg403 = %cst_6, %arg404 = %cst_9) -> (f32, f32) {
            %2456 = affine.for %arg405 = 0 to 128 step 16 iter_args(%arg406 = %cst) -> (vector<16xf32>) {
              %2471 = vector.load %2408[%arg399, %arg400, %arg401, %arg405] : memref<1x12x1x128xf32>, vector<16xf32>
              %2472 = vector.load %2394[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>, vector<16xf32>
              %2473 = vector.fma %2471, %2472, %arg406 : vector<16xf32>
              affine.yield %2473 : vector<16xf32>
            }
            %2457 = vector.reduction <add>, %2456 : vector<16xf32> into f32
            %2458 = arith.mulf %2457, %cst_7 : f32
            %2459 = memref.load %2409[%arg399, %c0, %arg401, %arg402] : memref<1x1x1x1024xf32>
            %2460 = arith.addf %2458, %2459 : f32
            %2461 = arith.cmpf ogt, %2460, %arg403 : f32
            %2462 = arith.select %2461, %2460, %arg403 : f32
            %2463 = arith.subf %arg403, %2460 : f32
            %2464 = math.exp %2463 : f32
            %2465 = arith.mulf %2464, %arg404 : f32
            %2466 = arith.addf %2465, %cst_8 : f32
            %2467 = arith.subf %2460, %arg403 : f32
            %2468 = math.exp %2467 : f32
            %2469 = arith.addf %arg404, %2468 : f32
            %2470 = arith.select %2461, %2466, %2469 : f32
            affine.for %arg405 = 0 to 128 {
              %2471 = memref.load %2400[%arg399, %2454, %arg402, %arg405] : memref<1x2x1024x128xf32>
              %2472 = memref.load %alloc_1153[%arg405] : memref<128xf32>
              %2473 = arith.mulf %2472, %2464 : f32
              %2474 = arith.addf %2473, %2471 : f32
              %2475 = arith.mulf %2468, %2471 : f32
              %2476 = arith.addf %2475, %2472 : f32
              %2477 = arith.select %2461, %2474, %2476 : f32
              memref.store %2477, %alloc_1153[%arg405] : memref<128xf32>
            }
            affine.yield %2462, %2470 : f32, f32
          }
          memref.store %2455#1, %alloc_1152[%arg399, %arg400, %arg401] : memref<1x12x1xf32>
          affine.for %arg402 = 0 to 128 {
            %2456 = memref.load %alloc_1153[%arg402] : memref<128xf32>
            %2457 = arith.divf %2456, %2455#1 : f32
            memref.store %2457, %alloc_1151[%arg399, %arg400, %arg401, %arg402] : memref<1x12x1x128xf32>
          }
        }
      }
    }
    %2410 = bufferization.to_tensor %alloc_1151 restrict : memref<1x12x1x128xf32> to tensor<1x12x1x128xf32>
    %collapsed_1154 = tensor.collapse_shape %2410 [[0], [1, 2, 3]] : tensor<1x12x1x128xf32> into tensor<1x1536xf32>
    %2411 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1154, %arg392 : tensor<1x1536xf32>, tensor<1536x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_1155 = tensor.expand_shape %2411 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %2412 = tensor.empty() : tensor<1x1x1536xf32>
    %2413 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2352, %expanded_1155 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%2412 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %2414 = tensor.empty() : tensor<1x1x1536xf32>
    %2415 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2413 : tensor<1x1x1536xf32>) outs(%2414 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %2416 = tensor.empty() : tensor<1x1xf32>
    %cst_1156 = arith.constant 0.000000e+00 : f32
    %2417 = linalg.fill ins(%cst_1156 : f32) outs(%2416 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_1157 = linalg.reduce ins(%2415 : tensor<1x1x1536xf32>) outs(%2417 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_1158 = tensor.expand_shape %reduced_1157 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %2418 = tensor.empty() : tensor<1x1x1xf32>
    %2419 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1158, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%2418 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2420 = tensor.empty() : tensor<1x1x1xf32>
    %2421 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2419, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%2420 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2422 = tensor.empty() : tensor<1x1x1xf32>
    %2423 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2421 : tensor<1x1x1xf32>) outs(%2422 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2424 = tensor.empty() : tensor<1x1x1536xf32>
    %2425 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2413, %2423 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%2424 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_1159 = tensor.expand_shape %arg393 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %2426 = tensor.empty() : tensor<1x1x1536xf32>
    %2427 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1159, %2425 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%2426 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_1160 = tensor.collapse_shape %2427 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2428 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1160, %arg394 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_1161 = tensor.expand_shape %2428 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %2429 = tensor.empty() : tensor<1x1x8960xf32>
    %2430 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1161 : tensor<1x1x8960xf32>) outs(%2429 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %out: f32):
      %cst_1172 = arith.constant 1.000000e+00 : f32
      %2454 = arith.negf %in : f32
      %2455 = math.exp %2454 : f32
      %2456 = arith.addf %2455, %cst_1172 : f32
      %2457 = arith.divf %cst_1172, %2456 : f32
      linalg.yield %2457 : f32
    } -> tensor<1x1x8960xf32>
    %2431 = tensor.empty() : tensor<1x1x8960xf32>
    %2432 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1161, %2430 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%2431 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_1162 = tensor.collapse_shape %2427 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2433 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1162, %arg395 : tensor<1x1536xf32>, tensor<1536x8960xf32>) outs(%cst_5 : tensor<1x8960xf32>) -> tensor<1x8960xf32>
    %expanded_1163 = tensor.expand_shape %2433 [[0, 1], [2]] output_shape [1, 1, 8960] : tensor<1x8960xf32> into tensor<1x1x8960xf32>
    %2434 = tensor.empty() : tensor<1x1x8960xf32>
    %2435 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2432, %expanded_1163 : tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) outs(%2434 : tensor<1x1x8960xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x8960xf32>
    %collapsed_1164 = tensor.collapse_shape %2435 [[0, 1], [2]] : tensor<1x1x8960xf32> into tensor<1x8960xf32>
    %2436 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1164, %arg396 : tensor<1x8960xf32>, tensor<8960x1536xf32>) outs(%cst_12 : tensor<1x1536xf32>) -> tensor<1x1536xf32>
    %expanded_1165 = tensor.expand_shape %2436 [[0, 1], [2]] output_shape [1, 1, 1536] : tensor<1x1536xf32> into tensor<1x1x1536xf32>
    %2437 = tensor.empty() : tensor<1x1x1536xf32>
    %2438 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2413, %expanded_1165 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%2437 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %2439 = tensor.empty() : tensor<1x1x1536xf32>
    %2440 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2438 : tensor<1x1x1536xf32>) outs(%2439 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.fpowi %in, %c2_i32 : f32, i32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %2441 = tensor.empty() : tensor<1x1xf32>
    %cst_1166 = arith.constant 0.000000e+00 : f32
    %2442 = linalg.fill ins(%cst_1166 : f32) outs(%2441 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %reduced_1167 = linalg.reduce ins(%2440 : tensor<1x1x1536xf32>) outs(%2442 : tensor<1x1xf32>) dimensions = [2]
      (%in: f32, %init: f32) {
        %2454 = arith.addf %in, %init : f32
        linalg.yield %2454 : f32
      }
    %expanded_1168 = tensor.expand_shape %reduced_1167 [[0], [1, 2]] output_shape [1, 1, 1] : tensor<1x1xf32> into tensor<1x1x1xf32>
    %2443 = tensor.empty() : tensor<1x1x1xf32>
    %2444 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1168, %cst_2 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%2443 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2445 = tensor.empty() : tensor<1x1x1xf32>
    %2446 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2444, %cst_13 : tensor<1x1x1xf32>, tensor<1x1x1xf32>) outs(%2445 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.addf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2447 = tensor.empty() : tensor<1x1x1xf32>
    %2448 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2446 : tensor<1x1x1xf32>) outs(%2447 : tensor<1x1x1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %2454 = math.rsqrt %in : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1xf32>
    %2449 = tensor.empty() : tensor<1x1x1536xf32>
    %2450 = linalg.generic {indexing_maps = [#map2, #map7, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2438, %2448 : tensor<1x1x1536xf32>, tensor<1x1x1xf32>) outs(%2449 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %expanded_1169 = tensor.expand_shape %arg397 [[0, 1, 2]] output_shape [1, 1, 1536] : tensor<1536xf32> into tensor<1x1x1536xf32>
    %2451 = tensor.empty() : tensor<1x1x1536xf32>
    %2452 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%expanded_1169, %2450 : tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) outs(%2451 : tensor<1x1x1536xf32>) {
    ^bb0(%in: f32, %in_1172: f32, %out: f32):
      %2454 = arith.mulf %in, %in_1172 : f32
      linalg.yield %2454 : f32
    } -> tensor<1x1x1536xf32>
    %collapsed_1170 = tensor.collapse_shape %2452 [[0, 1], [2]] : tensor<1x1x1536xf32> into tensor<1x1536xf32>
    %2453 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%collapsed_1170, %arg398 : tensor<1x1536xf32>, tensor<1536x151936xf32>) outs(%cst_4 : tensor<1x151936xf32>) -> tensor<1x151936xf32>
    %expanded_1171 = tensor.expand_shape %2453 [[0, 1], [2]] output_shape [1, 1, 151936] : tensor<1x151936xf32> into tensor<1x1x151936xf32>
    return %77, %83, %163, %169, %249, %255, %335, %341, %421, %427, %507, %513, %593, %599, %679, %685, %765, %771, %851, %857, %937, %943, %1023, %1029, %1109, %1115, %1195, %1201, %1281, %1287, %1367, %1373, %1453, %1459, %1539, %1545, %1625, %1631, %1711, %1717, %1797, %1803, %1883, %1889, %1969, %1975, %2055, %2061, %2141, %2147, %2227, %2233, %2313, %2319, %2399, %2405, %expanded_1171 : tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x2x1024x128xf32>, tensor<1x1x151936xf32>
  }
}
